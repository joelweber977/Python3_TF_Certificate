{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:25.266193Z",
     "iopub.status.busy": "2021-08-31T21:47:25.26551Z",
     "iopub.status.idle": "2021-08-31T21:47:25.297301Z",
     "shell.execute_reply": "2021-08-31T21:47:25.295911Z",
     "shell.execute_reply.started": "2021-08-31T21:47:25.26614Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:12.685206Z",
     "iopub.status.idle": "2021-08-31T21:47:12.685672Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataFrame in module pandas.core.frame:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame, pandas.core.arraylike.OpsMixin)\n",
      " |  DataFrame(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None)\n",
      " |  \n",
      " |  Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      " |  \n",
      " |  Data structure also contains labeled axes (rows and columns).\n",
      " |  Arithmetic operations align on both row and column labels. Can be\n",
      " |  thought of as a dict-like container for Series objects. The primary\n",
      " |  pandas data structure.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
      " |      data is a dict, column order follows insertion-order.\n",
      " |  \n",
      " |      .. versionchanged:: 0.25.0\n",
      " |         If data is a list of dicts, column order follows insertion-order.\n",
      " |  \n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to RangeIndex if\n",
      " |      no indexing information part of input data and no index provided.\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame when data does not have them,\n",
      " |      defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
      " |      will perform column selection instead.\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer.\n",
      " |  copy : bool or None, default None\n",
      " |      Copy data from inputs.\n",
      " |      For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
      " |      or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
      " |  \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.from_records : Constructor from tuples, also record arrays.\n",
      " |  DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
      " |  read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |  read_table : Read general delimited file into DataFrame.\n",
      " |  read_clipboard : Read text from clipboard into DataFrame.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Constructing DataFrame from a dictionary.\n",
      " |  \n",
      " |  >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |  >>> df = pd.DataFrame(data=d)\n",
      " |  >>> df\n",
      " |     col1  col2\n",
      " |  0     1     3\n",
      " |  1     2     4\n",
      " |  \n",
      " |  Notice that the inferred dtype is int64.\n",
      " |  \n",
      " |  >>> df.dtypes\n",
      " |  col1    int64\n",
      " |  col2    int64\n",
      " |  dtype: object\n",
      " |  \n",
      " |  To enforce a single dtype:\n",
      " |  \n",
      " |  >>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
      " |  >>> df.dtypes\n",
      " |  col1    int8\n",
      " |  col2    int8\n",
      " |  dtype: object\n",
      " |  \n",
      " |  Constructing DataFrame from numpy ndarray:\n",
      " |  \n",
      " |  >>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
      " |  ...                    columns=['a', 'b', 'c'])\n",
      " |  >>> df2\n",
      " |     a  b  c\n",
      " |  0  1  2  3\n",
      " |  1  4  5  6\n",
      " |  2  7  8  9\n",
      " |  \n",
      " |  Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
      " |  \n",
      " |  >>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
      " |  ...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
      " |  >>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
      " |  ...\n",
      " |  >>> df3\n",
      " |     c  a\n",
      " |  0  3  1\n",
      " |  1  6  4\n",
      " |  2  9  7\n",
      " |  \n",
      " |  Constructing DataFrame from dataclass:\n",
      " |  \n",
      " |  >>> from dataclasses import make_dataclass\n",
      " |  >>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
      " |  >>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
      " |     x  y\n",
      " |  0  0  0\n",
      " |  1  0  3\n",
      " |  2  2  3\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __divmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __init__(self, data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |      Returns length of info axis, but here we use the index.\n",
      " |  \n",
      " |  __matmul__(self, other: 'AnyArrayLike | FrameOrSeriesUnion') -> 'FrameOrSeriesUnion'\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __rdivmod__(self, other) -> 'tuple[DataFrame, DataFrame]'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular DataFrame.\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `radd`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, axis: 'Axis' = 0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      The aggregation operations are always performed over an axis, either the\n",
      " |      index (default) or the column axis. This behavior is different from\n",
      " |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      " |      `var`), where the default is to compute the aggregation of the flattened\n",
      " |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      " |      ``numpy.mean(arr_2d, axis=0)``.\n",
      " |      \n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Perform any type of operations.\n",
      " |      DataFrame.transform : Perform transformation type operations.\n",
      " |      core.groupby.GroupBy : Perform operations over groups.\n",
      " |      core.resample.Resampler : Perform operations over resampled bins.\n",
      " |      core.window.Rolling : Perform operations over rolling window.\n",
      " |      core.window.Expanding : Perform operations over expanding window.\n",
      " |      core.window.ExponentialMovingWindow : Perform operation over exponential weighted\n",
      " |          window.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2, 3],\n",
      " |      ...                    [4, 5, 6],\n",
      " |      ...                    [7, 8, 9],\n",
      " |      ...                    [np.nan, np.nan, np.nan]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Aggregate these functions over the rows.\n",
      " |      \n",
      " |      >>> df.agg(['sum', 'min'])\n",
      " |              A     B     C\n",
      " |      sum  12.0  15.0  18.0\n",
      " |      min   1.0   2.0   3.0\n",
      " |      \n",
      " |      Different aggregations per column.\n",
      " |      \n",
      " |      >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      " |              A    B\n",
      " |      sum  12.0  NaN\n",
      " |      min   1.0  2.0\n",
      " |      max   NaN  8.0\n",
      " |      \n",
      " |      Aggregate different functions over the columns and rename the index of the resulting\n",
      " |      DataFrame.\n",
      " |      \n",
      " |      >>> df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean))\n",
      " |           A    B    C\n",
      " |      x  7.0  NaN  NaN\n",
      " |      y  NaN  2.0  NaN\n",
      " |      z  NaN  NaN  6.0\n",
      " |      \n",
      " |      Aggregate over the columns.\n",
      " |      \n",
      " |      >>> df.agg(\"mean\", axis=\"columns\")\n",
      " |      0    2.0\n",
      " |      1    5.0\n",
      " |      2    8.0\n",
      " |      3    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  align(self, other, join: 'str' = 'outer', axis: 'Axis | None' = None, level: 'Level | None' = None, copy: 'bool' = True, fill_value=None, method: 'str | None' = None, limit=None, fill_axis: 'Axis' = 0, broadcast_axis: 'Axis | None' = None) -> 'DataFrame'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |      \n",
      " |      Join method is specified for each axis Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |      \n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      fill_axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |      broadcast_axis : {0 or 'index', 1 or 'columns'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (DataFrame, type of other)\n",
      " |          Aligned objects.\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([], dtype=\"float64\").all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there is at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If level is specified, then, DataFrame is returned; otherwise, Series\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([], dtype=\"float64\").any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, other, ignore_index: 'bool' = False, verify_integrity: 'bool' = False, sort: 'bool' = False) -> 'DataFrame'\n",
      " |      Append rows of `other` to the end of caller, returning a new object.\n",
      " |      \n",
      " |      Columns in `other` that are not in the caller are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      verify_integrity : bool, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      sort : bool, default False\n",
      " |          Sort columns if the columns of `self` and `other` are not aligned.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Changed to not sort by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame consisting of the rows of caller and the rows of `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      concat : General function to concatenate DataFrame or Series objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in\n",
      " |      the DataFrame's index, the order of the columns in the resulting\n",
      " |      DataFrame will be unchanged.\n",
      " |      \n",
      " |      Iteratively appending rows to a DataFrame can be more computationally\n",
      " |      intensive than a single concatenate. A better solution is to append\n",
      " |      those rows to a list and then concatenate the list with the original\n",
      " |      DataFrame all at once.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      x  1  2\n",
      " |      y  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y'])\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      x  1  2\n",
      " |      y  3  4\n",
      " |      x  5  6\n",
      " |      y  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |      \n",
      " |      The following, while not recommended methods for generating DataFrames,\n",
      " |      show two ways to generate a DataFrame from multiple data sources.\n",
      " |      \n",
      " |      Less efficient:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(columns=['A'])\n",
      " |      >>> for i in range(5):\n",
      " |      ...     df = df.append({'A': i}, ignore_index=True)\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |      \n",
      " |      More efficient:\n",
      " |      \n",
      " |      >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
      " |      ...           ignore_index=True)\n",
      " |         A\n",
      " |      0  0\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      4  4\n",
      " |  \n",
      " |  apply(self, func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type=None, args=(), **kwargs)\n",
      " |      Apply a function along an axis of the DataFrame.\n",
      " |      \n",
      " |      Objects passed to the function are Series objects whose index is\n",
      " |      either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      " |      (``axis=1``). By default (``result_type=None``), the final return type\n",
      " |      is inferred from the return type of the applied function. Otherwise,\n",
      " |      it depends on the `result_type` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column or row.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the function is applied:\n",
      " |      \n",
      " |          * 0 or 'index': apply function to each column.\n",
      " |          * 1 or 'columns': apply function to each row.\n",
      " |      \n",
      " |      raw : bool, default False\n",
      " |          Determines if row or column is passed as a Series or ndarray object:\n",
      " |      \n",
      " |          * ``False`` : passes each row or column as a Series to the\n",
      " |            function.\n",
      " |          * ``True`` : the passed function will receive ndarray objects\n",
      " |            instead.\n",
      " |            If you are just applying a NumPy reduction function this will\n",
      " |            achieve much better performance.\n",
      " |      \n",
      " |      result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      " |          These only act when ``axis=1`` (columns):\n",
      " |      \n",
      " |          * 'expand' : list-like results will be turned into columns.\n",
      " |          * 'reduce' : returns a Series if possible rather than expanding\n",
      " |            list-like results. This is the opposite of 'expand'.\n",
      " |          * 'broadcast' : results will be broadcast to the original shape\n",
      " |            of the DataFrame, the original index and columns will be\n",
      " |            retained.\n",
      " |      \n",
      " |          The default behaviour (None) depends on the return value of the\n",
      " |          applied function: list-like results will be returned as a Series\n",
      " |          of those. However if the apply function returns a Series these\n",
      " |          are expanded to columns.\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to `func` in addition to the\n",
      " |          array/series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Result of applying ``func`` along the given axis of the\n",
      " |          DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations.\n",
      " |      DataFrame.aggregate: Only perform aggregating type operations.\n",
      " |      DataFrame.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  4  9\n",
      " |      1  4  9\n",
      " |      2  4  9\n",
      " |      \n",
      " |      Using a numpy universal function (in this case the same as\n",
      " |      ``np.sqrt(df)``):\n",
      " |      \n",
      " |      >>> df.apply(np.sqrt)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  2.0  3.0\n",
      " |      2  2.0  3.0\n",
      " |      \n",
      " |      Using a reducing function on either axis\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=0)\n",
      " |      A    12\n",
      " |      B    27\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.apply(np.sum, axis=1)\n",
      " |      0    13\n",
      " |      1    13\n",
      " |      2    13\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Returning a list-like will result in a Series\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1)\n",
      " |      0    [1, 2]\n",
      " |      1    [1, 2]\n",
      " |      2    [1, 2]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Passing ``result_type='expand'`` will expand list-like results\n",
      " |      to columns of a Dataframe\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      " |         0  1\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |      \n",
      " |      Returning a Series inside the function is similar to passing\n",
      " |      ``result_type='expand'``. The resulting column names\n",
      " |      will be the Series index.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      " |         foo  bar\n",
      " |      0    1    2\n",
      " |      1    1    2\n",
      " |      2    1    2\n",
      " |      \n",
      " |      Passing ``result_type='broadcast'`` will ensure the same shape\n",
      " |      result, whether list-like or scalar is returned by the function,\n",
      " |      and broadcast it along the axis. The resulting column names will\n",
      " |      be the originals.\n",
      " |      \n",
      " |      >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  1  2\n",
      " |      2  1  2\n",
      " |  \n",
      " |  applymap(self, func: 'PythonFuncType', na_action: 'str | None' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |      \n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If ‘ignore’, propagate NaN values, without passing them to func.\n",
      " |      \n",
      " |          .. versionadded:: 1.2\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |      \n",
      " |      Like Series.map, NA values can be ignored:\n",
      " |      \n",
      " |      >>> df_copy = df.copy()\n",
      " |      >>> df_copy.iloc[0, 0] = pd.NA\n",
      " |      >>> df_copy.applymap(lambda x: len(str(x)), na_action='ignore')\n",
      " |            0  1\n",
      " |      0  <NA>  4\n",
      " |      1     5  5\n",
      " |      \n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |      \n",
      " |      >>> df.applymap(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |      \n",
      " |      But it's better to avoid applymap in that case.\n",
      " |      \n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |  \n",
      " |  asfreq(self, freq: 'Frequency', method=None, how: 'str | None' = None, normalize: 'bool' = False, fill_value=None) -> 'DataFrame'\n",
      " |      Convert time series to specified frequency.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency.\n",
      " |      \n",
      " |      If the index of this DataFrame is a :class:`~pandas.PeriodIndex`, the new index\n",
      " |      is the result of transforming the original index with\n",
      " |      :meth:`PeriodIndex.asfreq <pandas.PeriodIndex.asfreq>` (so the original index\n",
      " |      will map one-to-one to the new index).\n",
      " |      \n",
      " |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,\n",
      " |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and\n",
      " |      last entries in the original index (see :func:`pandas.date_range`). The\n",
      " |      values corresponding to any timesteps in the new index which were not present\n",
      " |      in the original index will be null (``NaN``), unless a method for filling\n",
      " |      such unknowns is provided (see the ``method`` parameter below).\n",
      " |      \n",
      " |      The :meth:`resample` method is more appropriate if an operation on each group of\n",
      " |      timesteps (such as an aggregate) is necessary to represent the data at the new\n",
      " |      frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |          Frequency DateOffset or string.\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame object reindexed to the specified frequency.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s': series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a DataFrame.\n",
      " |      \n",
      " |      Returns a new object with all original columns in addition to new ones.\n",
      " |      Existing columns that are re-assigned will be overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict of {str: callable or Series}\n",
      " |          The column names are keywords. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. The callable must not\n",
      " |          change input DataFrame (though pandas doesn't check it).\n",
      " |          If the values are not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Assigning multiple columns within the same ``assign`` is possible.\n",
      " |      Later items in '\\*\\*kwargs' may refer to newly created or modified\n",
      " |      columns in 'df'; items are computed and assigned into 'df' in order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
      " |      ...                   index=['Portland', 'Berkeley'])\n",
      " |      >>> df\n",
      " |                temp_c\n",
      " |      Portland    17.0\n",
      " |      Berkeley    25.0\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      Alternatively, the same behavior can be achieved by directly\n",
      " |      referencing an existing Series or sequence:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n",
      " |                temp_c  temp_f\n",
      " |      Portland    17.0    62.6\n",
      " |      Berkeley    25.0    77.0\n",
      " |      \n",
      " |      You can create multiple columns within the same assign where one\n",
      " |      of the columns depends on another one defined within the same assign:\n",
      " |      \n",
      " |      >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
      " |      ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n",
      " |                temp_c  temp_f  temp_k\n",
      " |      Portland    17.0    62.6  290.15\n",
      " |      Berkeley    25.0    77.0  298.15\n",
      " |  \n",
      " |  bfill(self: 'DataFrame', axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from DataFrame columns.\n",
      " |      \n",
      " |      Make a box-and-whisker plot from DataFrame columns, optionally grouped\n",
      " |      by some other columns. A box plot is a method for graphically depicting\n",
      " |      groups of numerical data through their quartiles.\n",
      " |      The box extends from the Q1 to Q3 quartile values of the data,\n",
      " |      with a line at the median (Q2). The whiskers extend from the edges\n",
      " |      of box to show the range of the data. By default, they extend no more than\n",
      " |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest\n",
      " |      data point within that interval. Outliers are plotted as separate dots.\n",
      " |      \n",
      " |      For further details see\n",
      " |      Wikipedia's entry for `boxplot <https://en.wikipedia.org/wiki/Box_plot>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or list of str, optional\n",
      " |          Column name or list of names, or vector.\n",
      " |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.\n",
      " |      by : str or array-like, optional\n",
      " |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.\n",
      " |          One box-plot will be done per value of columns in `by`.\n",
      " |      ax : object of class matplotlib.axes.Axes, optional\n",
      " |          The matplotlib axes to be used by boxplot.\n",
      " |      fontsize : float or str\n",
      " |          Tick label font size in points or as a string (e.g., `large`).\n",
      " |      rot : int or float, default 0\n",
      " |          The rotation angle of labels (in degrees)\n",
      " |          with respect to the screen coordinate system.\n",
      " |      grid : bool, default True\n",
      " |          Setting this to True will show the grid.\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |          The size of the figure to create in matplotlib.\n",
      " |      layout : tuple (rows, columns), optional\n",
      " |          For example, (3, 5) will display the subplots\n",
      " |          using 3 columns and 5 rows, starting from the top-left.\n",
      " |      return_type : {'axes', 'dict', 'both'} or None, default 'axes'\n",
      " |          The kind of object to return. The default is ``axes``.\n",
      " |      \n",
      " |          * 'axes' returns the matplotlib axes the boxplot is drawn on.\n",
      " |          * 'dict' returns a dictionary whose values are the matplotlib\n",
      " |            Lines of the boxplot.\n",
      " |          * 'both' returns a namedtuple with the axes and dict.\n",
      " |          * when grouping with ``by``, a Series mapping columns to\n",
      " |            ``return_type`` is returned.\n",
      " |      \n",
      " |            If ``return_type`` is `None`, a NumPy array\n",
      " |            of axes with the same shape as ``layout`` is returned.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :func:`matplotlib.pyplot.boxplot`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result\n",
      " |          See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.plot.hist: Make a histogram.\n",
      " |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The return type depends on the `return_type` parameter:\n",
      " |      \n",
      " |      * 'axes' : object of class matplotlib.axes.Axes\n",
      " |      * 'dict' : dict of matplotlib.lines.Line2D objects\n",
      " |      * 'both' : a namedtuple with structure (ax, lines)\n",
      " |      \n",
      " |      For data grouped with ``by``, return a Series of the above or a numpy\n",
      " |      array:\n",
      " |      \n",
      " |      * :class:`~pandas.Series`\n",
      " |      * :class:`~numpy.array` (for ``return_type = None``)\n",
      " |      \n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Boxplots can be created for every column in the dataframe\n",
      " |      by ``df.boxplot()`` or indicating the columns to be used:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> np.random.seed(1234)\n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 4),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3', 'Col4'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2', 'Col3'])\n",
      " |      \n",
      " |      Boxplots of variables distributions grouped by the values of a third\n",
      " |      variable can be created using the option ``by``. For instance:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 2),\n",
      " |          ...                   columns=['Col1', 'Col2'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> boxplot = df.boxplot(by='X')\n",
      " |      \n",
      " |      A list of strings (i.e. ``['X', 'Y']``) can be passed to boxplot\n",
      " |      in order to group the data by combination of the variables in the x-axis:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame(np.random.randn(10, 3),\n",
      " |          ...                   columns=['Col1', 'Col2', 'Col3'])\n",
      " |          >>> df['X'] = pd.Series(['A', 'A', 'A', 'A', 'A',\n",
      " |          ...                      'B', 'B', 'B', 'B', 'B'])\n",
      " |          >>> df['Y'] = pd.Series(['A', 'B', 'A', 'B', 'A',\n",
      " |          ...                      'B', 'A', 'B', 'A', 'B'])\n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by=['X', 'Y'])\n",
      " |      \n",
      " |      The layout of boxplot can be adjusted giving a tuple to ``layout``:\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      layout=(2, 1))\n",
      " |      \n",
      " |      Additional formatting can be done to the boxplot, like suppressing the grid\n",
      " |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)\n",
      " |      or changing the fontsize (i.e. ``fontsize=15``):\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(grid=False, rot=45, fontsize=15)\n",
      " |      \n",
      " |      The parameter ``return_type`` can be used to select the type of element\n",
      " |      returned by `boxplot`.  When ``return_type='axes'`` is selected,\n",
      " |      the matplotlib axes on which the boxplot is drawn are returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'matplotlib.axes._subplots.AxesSubplot'>\n",
      " |      \n",
      " |      When grouping with ``by``, a Series mapping columns to ``return_type``\n",
      " |      is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type='axes')\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'pandas.core.series.Series'>\n",
      " |      \n",
      " |      If ``return_type`` is `None`, a NumPy array of axes with the same shape\n",
      " |      as ``layout`` is returned:\n",
      " |      \n",
      " |          >>> boxplot = df.boxplot(column=['Col1', 'Col2'], by='X',\n",
      " |          ...                      return_type=None)\n",
      " |          >>> type(boxplot)\n",
      " |          <class 'numpy.ndarray'>\n",
      " |  \n",
      " |  clip(self: 'DataFrame', lower=None, upper=None, axis: 'Axis | None' = None, inplace: 'bool' = False, *args, **kwargs) -> 'DataFrame | None'\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array-like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      upper : float or array-like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it. A missing\n",
      " |          threshold (e.g `NA`) will not clip the value.\n",
      " |      axis : int or str axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.clip : Trim values at input threshold in series.\n",
      " |      DataFrame.clip : Trim values at input threshold in dataframe.\n",
      " |      numpy.clip : Clip (limit) the values in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |      \n",
      " |      Clips using specific lower threshold per column element, with missing values:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, np.NaN, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2.0\n",
      " |      1   -4.0\n",
      " |      2    NaN\n",
      " |      3    6.0\n",
      " |      4    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> df.clip(t, axis=0)\n",
      " |      col_0  col_1\n",
      " |      0      9      2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  combine(self, other: 'DataFrame', func, fill_value=None, overwrite: 'bool' = True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another DataFrame.\n",
      " |      \n",
      " |      Combines a DataFrame with `other` DataFrame using `func`\n",
      " |      to element-wise combine columns. The row and column indexes of the\n",
      " |      resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          The DataFrame to merge column-wise.\n",
      " |      func : function\n",
      " |          Function that takes two series as inputs and return a Series or a\n",
      " |          scalar. Used to merge the two dataframes column by columns.\n",
      " |      fill_value : scalar value, default None\n",
      " |          The value to fill NaNs with prior to passing any column to the\n",
      " |          merge func.\n",
      " |      overwrite : bool, default True\n",
      " |          If True, columns in `self` that do not exist in `other` will be\n",
      " |          overwritten with NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Combination of the provided DataFrames.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine_first : Combine two DataFrame objects and default to\n",
      " |          non-null values in frame calling the method.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Combine using a simple function that chooses the smaller column.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |         A  B\n",
      " |      0  0  3\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Example using a true element-wise combine function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, np.minimum)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  0  3\n",
      " |      \n",
      " |      Using `fill_value` fills Nones prior to passing the column to the\n",
      " |      merge function.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |         A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  4.0\n",
      " |      \n",
      " |      However, if the same element in both dataframes is None, that None\n",
      " |      is preserved\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\n",
      " |      >>> df1.combine(df2, take_smaller, fill_value=-5)\n",
      " |          A    B\n",
      " |      0  0 -5.0\n",
      " |      1  0  3.0\n",
      " |      \n",
      " |      Example that demonstrates the use of `overwrite` and behavior when\n",
      " |      the axis differ between the dataframes.\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\n",
      " |      >>> df1.combine(df2, take_smaller)\n",
      " |           A    B     C\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      >>> df1.combine(df2, take_smaller, overwrite=False)\n",
      " |           A    B     C\n",
      " |      0  0.0  NaN   NaN\n",
      " |      1  0.0  3.0 -10.0\n",
      " |      2  NaN  3.0   1.0\n",
      " |      \n",
      " |      Demonstrating the preference of the passed in dataframe.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\n",
      " |      >>> df2.combine(df1, take_smaller)\n",
      " |         A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 NaN\n",
      " |      2  NaN  3.0 NaN\n",
      " |      \n",
      " |      >>> df2.combine(df1, take_smaller, overwrite=False)\n",
      " |           A    B   C\n",
      " |      0  0.0  NaN NaN\n",
      " |      1  0.0  3.0 1.0\n",
      " |      2  NaN  3.0 1.0\n",
      " |  \n",
      " |  combine_first(self, other: 'DataFrame') -> 'DataFrame'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |      \n",
      " |      Combine two DataFrame objects by filling null values in one DataFrame\n",
      " |      with non-null values from other DataFrame. The row and column indexes\n",
      " |      of the resulting DataFrame will be the union of the two.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Provided DataFrame to use to fill null values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of combining the provided DataFrame with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.combine : Perform series-wise operation on two DataFrames\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\n",
      " |      >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B\n",
      " |      0  1.0  3.0\n",
      " |      1  0.0  4.0\n",
      " |      \n",
      " |      Null values still persist if the location of that null value\n",
      " |      does not exist in `other`\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\n",
      " |      >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\n",
      " |      >>> df1.combine_first(df2)\n",
      " |           A    B    C\n",
      " |      0  NaN  4.0  NaN\n",
      " |      1  0.0  3.0  1.0\n",
      " |      2  NaN  3.0  1.0\n",
      " |  \n",
      " |  compare(self, other: 'DataFrame', align_axis: 'Axis' = 1, keep_shape: 'bool' = False, keep_equal: 'bool' = False) -> 'DataFrame'\n",
      " |      Compare to another DataFrame and show the differences.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |          Object to compare with.\n",
      " |      \n",
      " |      align_axis : {0 or 'index', 1 or 'columns'}, default 1\n",
      " |          Determine which axis to align the comparison on.\n",
      " |      \n",
      " |          * 0, or 'index' : Resulting differences are stacked vertically\n",
      " |              with rows drawn alternately from self and other.\n",
      " |          * 1, or 'columns' : Resulting differences are aligned horizontally\n",
      " |              with columns drawn alternately from self and other.\n",
      " |      \n",
      " |      keep_shape : bool, default False\n",
      " |          If true, all rows and columns are kept.\n",
      " |          Otherwise, only the ones with different values are kept.\n",
      " |      \n",
      " |      keep_equal : bool, default False\n",
      " |          If true, the result keeps values that are equal.\n",
      " |          Otherwise, equal values are shown as NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame that shows the differences stacked side by side.\n",
      " |      \n",
      " |          The resulting index will be a MultiIndex with 'self' and 'other'\n",
      " |          stacked alternately at the inner level.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the two DataFrames don't have identical labels or shape.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.compare : Compare with another Series and show differences.\n",
      " |      DataFrame.equals : Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Matching NaNs will not appear as a difference.\n",
      " |      \n",
      " |      Can only compare identically-labeled\n",
      " |      (i.e. same shape, identical row and column labels) DataFrames\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\n",
      " |      ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\n",
      " |      ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\n",
      " |      ...     },\n",
      " |      ...     columns=[\"col1\", \"col2\", \"col3\"],\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        col1  col2  col3\n",
      " |      0    a   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   3.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      >>> df2 = df.copy()\n",
      " |      >>> df2.loc[0, 'col1'] = 'c'\n",
      " |      >>> df2.loc[2, 'col3'] = 4.0\n",
      " |      >>> df2\n",
      " |        col1  col2  col3\n",
      " |      0    c   1.0   1.0\n",
      " |      1    a   2.0   2.0\n",
      " |      2    b   3.0   4.0\n",
      " |      3    b   NaN   4.0\n",
      " |      4    a   5.0   5.0\n",
      " |      \n",
      " |      Align the differences on columns\n",
      " |      \n",
      " |      >>> df.compare(df2)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  NaN   NaN\n",
      " |      2  NaN   NaN  3.0   4.0\n",
      " |      \n",
      " |      Stack the differences on rows\n",
      " |      \n",
      " |      >>> df.compare(df2, align_axis=0)\n",
      " |              col1  col3\n",
      " |      0 self     a   NaN\n",
      " |        other    c   NaN\n",
      " |      2 self   NaN   3.0\n",
      " |        other  NaN   4.0\n",
      " |      \n",
      " |      Keep the equal values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_equal=True)\n",
      " |        col1       col3\n",
      " |        self other self other\n",
      " |      0    a     c  1.0   1.0\n",
      " |      2    b     b  3.0   4.0\n",
      " |      \n",
      " |      Keep all original rows and columns\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  NaN   NaN  NaN   NaN\n",
      " |      1  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      2  NaN   NaN  NaN   NaN  3.0   4.0\n",
      " |      3  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      4  NaN   NaN  NaN   NaN  NaN   NaN\n",
      " |      \n",
      " |      Keep all original rows and columns and also all original values\n",
      " |      \n",
      " |      >>> df.compare(df2, keep_shape=True, keep_equal=True)\n",
      " |        col1       col2       col3\n",
      " |        self other self other self other\n",
      " |      0    a     c  1.0   1.0  1.0   1.0\n",
      " |      1    a     a  2.0   2.0  2.0   2.0\n",
      " |      2    b     b  3.0   3.0  3.0   4.0\n",
      " |      3    b     b  NaN   NaN  4.0   4.0\n",
      " |      4    a     a  5.0   5.0  5.0   5.0\n",
      " |  \n",
      " |  corr(self, method: 'str | Callable[[np.ndarray, np.ndarray], float]' = 'pearson', min_periods: 'int' = 1) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float. Note that the returned matrix from corr\n",
      " |              will have 1 along the diagonals and will be symmetric\n",
      " |              regardless of the callable's behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Correlation matrix.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.corr(method=histogram_intersection)\n",
      " |            dogs  cats\n",
      " |      dogs   1.0   0.3\n",
      " |      cats   0.3   1.0\n",
      " |  \n",
      " |  corrwith(self, other, axis: 'Axis' = 0, drop=False, method='pearson') -> 'Series'\n",
      " |      Compute pairwise correlation.\n",
      " |      \n",
      " |      Pairwise correlation is computed between rows or columns of\n",
      " |      DataFrame with rows or columns of Series or DataFrame. DataFrames\n",
      " |      are first aligned along both axes before computing the\n",
      " |      correlations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series\n",
      " |          Object with which to compute correlations.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for\n",
      " |          row-wise.\n",
      " |      drop : bool, default False\n",
      " |          Drop missing indices from result.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method of correlation:\n",
      " |      \n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |          * callable: callable with input two 1d ndarrays\n",
      " |              and returning a float.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Pairwise correlations.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |  \n",
      " |  count(self, axis: 'Axis' = 0, level: 'Level | None' = None, numeric_only: 'bool' = False)\n",
      " |      Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending\n",
      " |      on `pandas.options.mode.use_inf_as_na`) are considered NA.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          If 0 or 'index' counts are generated for each column.\n",
      " |          If 1 or 'columns' counts are generated for each row.\n",
      " |      level : int or str, optional\n",
      " |          If the axis is a `MultiIndex` (hierarchical), count along a\n",
      " |          particular `level`, collapsing into a `DataFrame`.\n",
      " |          A `str` specifies the level name.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          For each column/row the number of non-NA/null entries.\n",
      " |          If `level` is specified returns a `DataFrame`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      DataFrame.shape: Number of DataFrame rows and columns (including NA\n",
      " |          elements).\n",
      " |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA\n",
      " |          elements.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Constructing DataFrame from a dictionary:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"Person\":\n",
      " |      ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\n",
      " |      ...                    \"Age\": [24., np.nan, 21., 33, 26],\n",
      " |      ...                    \"Single\": [False, True, True, True, False]})\n",
      " |      >>> df\n",
      " |         Person   Age  Single\n",
      " |      0    John  24.0   False\n",
      " |      1    Myla   NaN    True\n",
      " |      2   Lewis  21.0    True\n",
      " |      3    John  33.0    True\n",
      " |      4    Myla  26.0   False\n",
      " |      \n",
      " |      Notice the uncounted NA values:\n",
      " |      \n",
      " |      >>> df.count()\n",
      " |      Person    5\n",
      " |      Age       4\n",
      " |      Single    5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Counts for each **row**:\n",
      " |      \n",
      " |      >>> df.count(axis='columns')\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cov(self, min_periods: 'int | None' = None, ddof: 'int | None' = 1) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |      \n",
      " |      Compute the pairwise covariance among the series of a DataFrame.\n",
      " |      The returned data frame is the `covariance matrix\n",
      " |      <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\n",
      " |      of the DataFrame.\n",
      " |      \n",
      " |      Both NA and null values are automatically excluded from the\n",
      " |      calculation. (See the note below about bias from missing values.)\n",
      " |      A threshold can be set for the minimum number of\n",
      " |      observations for each value created. Comparisons with observations\n",
      " |      below this threshold will be returned as ``NaN``.\n",
      " |      \n",
      " |      This method is generally used for the analysis of time series data to\n",
      " |      understand the relationship between different measures\n",
      " |      across time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The covariance matrix of the series of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.cov : Compute covariance with another Series.\n",
      " |      core.window.ExponentialMovingWindow.cov: Exponential weighted sample covariance.\n",
      " |      core.window.Expanding.cov : Expanding sample covariance.\n",
      " |      core.window.Rolling.cov : Rolling sample covariance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-ddof.\n",
      " |      \n",
      " |      For DataFrames that have Series that are missing data (assuming that\n",
      " |      data is `missing at random\n",
      " |      <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\n",
      " |      the returned covariance matrix will be an unbiased estimate\n",
      " |      of the variance and covariance between the member Series.\n",
      " |      \n",
      " |      However, for many applications this estimate may not be acceptable\n",
      " |      because the estimate covariance matrix is not guaranteed to be positive\n",
      " |      semi-definite. This could lead to estimate correlations having\n",
      " |      absolute values which are greater than one, and/or a non-invertible\n",
      " |      covariance matrix. See `Estimation of covariance matrices\n",
      " |      <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\n",
      " |      matrices>`__ for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df.cov()\n",
      " |                dogs      cats\n",
      " |      dogs  0.666667 -1.000000\n",
      " |      cats -1.000000  1.666667\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(1000, 5),\n",
      " |      ...                   columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |      >>> df.cov()\n",
      " |                a         b         c         d         e\n",
      " |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144\n",
      " |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826\n",
      " |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\n",
      " |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\n",
      " |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795\n",
      " |      \n",
      " |      **Minimum number of periods**\n",
      " |      \n",
      " |      This method also supports an optional ``min_periods`` keyword\n",
      " |      that specifies the required minimum number of non-NA observations for\n",
      " |      each column pair in order to have a valid result:\n",
      " |      \n",
      " |      >>> np.random.seed(42)\n",
      " |      >>> df = pd.DataFrame(np.random.randn(20, 3),\n",
      " |      ...                   columns=['a', 'b', 'c'])\n",
      " |      >>> df.loc[df.index[:5], 'a'] = np.nan\n",
      " |      >>> df.loc[df.index[5:10], 'b'] = np.nan\n",
      " |      >>> df.cov(min_periods=12)\n",
      " |                a         b         c\n",
      " |      a  0.316741       NaN -0.150812\n",
      " |      b       NaN  1.248003  0.191417\n",
      " |      c -0.150812  0.191417  0.895202\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative maximum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.max : Return the maximum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative minimum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.min : Return the minimum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative product of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.prod : Return the product over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return cumulative sum of Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      DataFrame.sum : Return the sum over\n",
      " |          DataFrame axis.\n",
      " |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.\n",
      " |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.\n",
      " |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.\n",
      " |      DataFrame.cumprod : Return cumulative product over DataFrame axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods: 'int' = 1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Dataframe element compared with another\n",
      " |      element in the Dataframe (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Take difference over rows (0) or columns (1).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataframe\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Dataframe.pct_change: Percent change over given number of periods.\n",
      " |      Dataframe.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      Series.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in Dataframe,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'b': [1, 1, 2, 3, 5, 8],\n",
      " |      ...                    'c': [1, 4, 9, 16, 25, 36]})\n",
      " |      >>> df\n",
      " |         a  b   c\n",
      " |      0  1  1   1\n",
      " |      1  2  1   4\n",
      " |      2  3  2   9\n",
      " |      3  4  3  16\n",
      " |      4  5  5  25\n",
      " |      5  6  8  36\n",
      " |      \n",
      " |      >>> df.diff()\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  1.0  0.0   3.0\n",
      " |      2  1.0  1.0   5.0\n",
      " |      3  1.0  1.0   7.0\n",
      " |      4  1.0  2.0   9.0\n",
      " |      5  1.0  3.0  11.0\n",
      " |      \n",
      " |      Difference with previous column\n",
      " |      \n",
      " |      >>> df.diff(axis=1)\n",
      " |          a  b   c\n",
      " |      0 NaN  0   0\n",
      " |      1 NaN -1   3\n",
      " |      2 NaN -1   7\n",
      " |      3 NaN -1  13\n",
      " |      4 NaN  0  20\n",
      " |      5 NaN  2  28\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> df.diff(periods=3)\n",
      " |           a    b     c\n",
      " |      0  NaN  NaN   NaN\n",
      " |      1  NaN  NaN   NaN\n",
      " |      2  NaN  NaN   NaN\n",
      " |      3  3.0  2.0  15.0\n",
      " |      4  3.0  4.0  21.0\n",
      " |      5  3.0  6.0  27.0\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> df.diff(periods=-1)\n",
      " |           a    b     c\n",
      " |      0 -1.0  0.0  -3.0\n",
      " |      1 -1.0 -1.0  -5.0\n",
      " |      2 -1.0 -1.0  -7.0\n",
      " |      3 -1.0 -2.0  -9.0\n",
      " |      4 -1.0 -3.0 -11.0\n",
      " |      5  NaN  NaN   NaN\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\n",
      " |      >>> df.diff()\n",
      " |             a\n",
      " |      0    NaN\n",
      " |      1  255.0\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  dot(self, other: 'AnyArrayLike | FrameOrSeriesUnion') -> 'FrameOrSeriesUnion'\n",
      " |      Compute the matrix multiplication between the DataFrame and other.\n",
      " |      \n",
      " |      This method computes the matrix product between the DataFrame and the\n",
      " |      values of an other Series, DataFrame or a numpy array.\n",
      " |      \n",
      " |      It can also be called using ``self @ other`` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If other is a Series, return the matrix product between self and\n",
      " |          other as a Series. If other is a DataFrame or a numpy.array, return\n",
      " |          the matrix product of self and other in a DataFrame of a np.array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dot: Similar method for Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dimensions of DataFrame and other must be compatible in order to\n",
      " |      compute the matrix multiplication. In addition, the column names of\n",
      " |      DataFrame and the index of other must contain the same values, as they\n",
      " |      will be aligned prior to the multiplication.\n",
      " |      \n",
      " |      The dot method for Series computes the inner product, instead of the\n",
      " |      matrix product here.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Here we multiply a DataFrame with a Series.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\n",
      " |      >>> s = pd.Series([1, 1, 2, 1])\n",
      " |      >>> df.dot(s)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Here we multiply a DataFrame with another DataFrame.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(other)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note that the dot method give the same result as @\n",
      " |      \n",
      " |      >>> df @ other\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      The dot method works also if other is an np.array.\n",
      " |      \n",
      " |      >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\n",
      " |      >>> df.dot(arr)\n",
      " |          0   1\n",
      " |      0   1   4\n",
      " |      1   2   2\n",
      " |      \n",
      " |      Note how shuffling of the objects does not change the result.\n",
      " |      \n",
      " |      >>> s2 = s.reindex([1, 0, 2, 3])\n",
      " |      >>> df.dot(s2)\n",
      " |      0    -4\n",
      " |      1     5\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  drop(self, labels=None, axis: 'Axis' = 0, index=None, columns=None, level: 'Level | None' = None, inplace: 'bool' = False, errors: 'str' = 'raise')\n",
      " |      Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Remove rows or columns by specifying label names and corresponding\n",
      " |      axis, or by specifying directly index or column names. When using a\n",
      " |      multi-index, labels on different levels can be removed by specifying\n",
      " |      the level. See the `user guide <advanced.shown_levels>`\n",
      " |      for more information about the now unused levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index or column labels to drop.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Whether to drop labels from the index (0 or 'index') or\n",
      " |          columns (1 or 'columns').\n",
      " |      index : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=0``\n",
      " |          is equivalent to ``index=labels``).\n",
      " |      columns : single label or list-like\n",
      " |          Alternative to specifying axis (``labels, axis=1``\n",
      " |          is equivalent to ``columns=labels``).\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level from which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If False, return a copy. Otherwise, do operation\n",
      " |          inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are\n",
      " |          dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame without the removed index or column labels or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Label-location based indexer for selection by label.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      " |          removed, optionally only considering certain columns.\n",
      " |      Series.drop : Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      " |      ...                   columns=['A', 'B', 'C', 'D'])\n",
      " |      >>> df\n",
      " |         A  B   C   D\n",
      " |      0  0  1   2   3\n",
      " |      1  4  5   6   7\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns\n",
      " |      \n",
      " |      >>> df.drop(['B', 'C'], axis=1)\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      >>> df.drop(columns=['B', 'C'])\n",
      " |         A   D\n",
      " |      0  0   3\n",
      " |      1  4   7\n",
      " |      2  8  11\n",
      " |      \n",
      " |      Drop a row by index\n",
      " |      \n",
      " |      >>> df.drop([0, 1])\n",
      " |         A  B   C   D\n",
      " |      2  8  9  10  11\n",
      " |      \n",
      " |      Drop columns and/or rows of MultiIndex DataFrame\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      " |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      " |      ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      " |      ...                         [1, 0.8], [0.3, 0.2]])\n",
      " |      >>> df\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |              length  1.5     1.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |              length  1.5     0.8\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |              length  0.3     0.2\n",
      " |      \n",
      " |      >>> df.drop(index='cow', columns='small')\n",
      " |                      big\n",
      " |      lama    speed   45.0\n",
      " |              weight  200.0\n",
      " |              length  1.5\n",
      " |      falcon  speed   320.0\n",
      " |              weight  1.0\n",
      " |              length  0.3\n",
      " |      \n",
      " |      >>> df.drop(index='length', level=1)\n",
      " |                      big     small\n",
      " |      lama    speed   45.0    30.0\n",
      " |              weight  200.0   100.0\n",
      " |      cow     speed   30.0    20.0\n",
      " |              weight  250.0   150.0\n",
      " |      falcon  speed   320.0   250.0\n",
      " |              weight  1.0     0.8\n",
      " |  \n",
      " |  drop_duplicates(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: \"Literal['first'] | Literal['last'] | Literal[False]\" = 'first', inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'DataFrame | None'\n",
      " |      Return DataFrame with duplicate rows removed.\n",
      " |      \n",
      " |      Considering certain columns is optional. Indexes, including time indexes\n",
      " |      are ignored.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to keep.\n",
      " |          - ``first`` : Drop duplicates except for the first occurrence.\n",
      " |          - ``last`` : Drop duplicates except for the last occurrence.\n",
      " |          - False : Drop all duplicates.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to drop duplicates in place or to return a copy.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with duplicates removed or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.value_counts: Count unique combinations of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, it removes duplicate rows based on all columns.\n",
      " |      \n",
      " |      >>> df.drop_duplicates()\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      To remove duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand'])\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      \n",
      " |      To remove duplicates and keep last occurrences, use ``keep``.\n",
      " |      \n",
      " |      >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\n",
      " |          brand style  rating\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      4  Indomie  pack     5.0\n",
      " |  \n",
      " |  dropna(self, axis: 'Axis' = 0, how: 'str' = 'any', thresh=None, subset=None, inplace: 'bool' = False)\n",
      " |      Remove missing values.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine if rows or columns which contain missing values are\n",
      " |          removed.\n",
      " |      \n",
      " |          * 0, or 'index' : Drop rows which contain missing values.\n",
      " |          * 1, or 'columns' : Drop columns which contain missing value.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             Pass tuple or list to drop on multiple axes.\n",
      " |             Only a single axis is allowed.\n",
      " |      \n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          Determine if row or column is removed from DataFrame, when we have\n",
      " |          at least one NA or all NA.\n",
      " |      \n",
      " |          * 'any' : If any NA values are present, drop that row or column.\n",
      " |          * 'all' : If all values are NA, drop that row or column.\n",
      " |      \n",
      " |      thresh : int, optional\n",
      " |          Require that many non-NA values.\n",
      " |      subset : array-like, optional\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with NA entries dropped from it or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isna: Indicate missing values.\n",
      " |      DataFrame.notna : Indicate existing (non-missing) values.\n",
      " |      DataFrame.fillna : Replace missing values.\n",
      " |      Series.dropna : Drop missing values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      " |      ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      " |      ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      " |      ...                             pd.NaT]})\n",
      " |      >>> df\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Drop the rows where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna()\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |      \n",
      " |      Drop the columns where at least one element is missing.\n",
      " |      \n",
      " |      >>> df.dropna(axis='columns')\n",
      " |             name\n",
      " |      0    Alfred\n",
      " |      1    Batman\n",
      " |      2  Catwoman\n",
      " |      \n",
      " |      Drop the rows where all elements are missing.\n",
      " |      \n",
      " |      >>> df.dropna(how='all')\n",
      " |             name        toy       born\n",
      " |      0    Alfred        NaN        NaT\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep only the rows with at least 2 non-NA values.\n",
      " |      \n",
      " |      >>> df.dropna(thresh=2)\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Define in which columns to look for missing values.\n",
      " |      \n",
      " |      >>> df.dropna(subset=['name', 'toy'])\n",
      " |             name        toy       born\n",
      " |      1    Batman  Batmobile 1940-04-25\n",
      " |      2  Catwoman   Bullwhip        NaT\n",
      " |      \n",
      " |      Keep the DataFrame with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> df.dropna(inplace=True)\n",
      " |      >>> df\n",
      " |           name        toy       born\n",
      " |      1  Batman  Batmobile 1940-04-25\n",
      " |  \n",
      " |  duplicated(self, subset: 'Hashable | Sequence[Hashable] | None' = None, keep: \"Literal['first'] | Literal['last'] | Literal[False]\" = 'first') -> 'Series'\n",
      " |      Return boolean Series denoting duplicate rows.\n",
      " |      \n",
      " |      Considering certain columns is optional.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns.\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Determines which duplicates (if any) to mark.\n",
      " |      \n",
      " |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
      " |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
      " |          - False : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Boolean series for each duplicated rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on index.\n",
      " |      Series.duplicated : Equivalent method on Series.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing ramen rating.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n",
      " |      ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n",
      " |      ...     'rating': [4, 4, 3.5, 15, 5]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          brand style  rating\n",
      " |      0  Yum Yum   cup     4.0\n",
      " |      1  Yum Yum   cup     4.0\n",
      " |      2  Indomie   cup     3.5\n",
      " |      3  Indomie  pack    15.0\n",
      " |      4  Indomie  pack     5.0\n",
      " |      \n",
      " |      By default, for each set of duplicated values, the first occurrence\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated()\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting ``keep`` on False, all duplicates are True.\n",
      " |      \n",
      " |      >>> df.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      To find duplicates on specific column(s), use ``subset``.\n",
      " |      \n",
      " |      >>> df.duplicated(subset=['brand'])\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      3     True\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  eval(self, expr: 'str', inplace: 'bool' = False, **kwargs)\n",
      " |      Evaluate a string describing operations on DataFrame columns.\n",
      " |      \n",
      " |      Operates on columns only, not specific rows or elements.  This allows\n",
      " |      `eval` to run arbitrary code, which can make you vulnerable to code\n",
      " |      injection if you pass user input to this function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The expression string to evaluate.\n",
      " |      inplace : bool, default False\n",
      " |          If the expression contains an assignment, whether to perform the\n",
      " |          operation inplace and mutate the existing DataFrame. Otherwise,\n",
      " |          a new DataFrame is returned.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray, scalar, pandas object, or None\n",
      " |          The result of the evaluation or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.query : Evaluates a boolean expression to query the columns\n",
      " |          of a frame.\n",
      " |      DataFrame.assign : Can evaluate an expression or function to create new\n",
      " |          values for a column.\n",
      " |      eval : Evaluate a Python expression as a string using various\n",
      " |          backends.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      >>> df.eval('A + B')\n",
      " |      0    11\n",
      " |      1    10\n",
      " |      2     9\n",
      " |      3     8\n",
      " |      4     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Assignment is allowed though by default the original DataFrame is not\n",
      " |      modified.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B')\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      >>> df\n",
      " |         A   B\n",
      " |      0  1  10\n",
      " |      1  2   8\n",
      " |      2  3   6\n",
      " |      3  4   4\n",
      " |      4  5   2\n",
      " |      \n",
      " |      Use ``inplace=True`` to modify the original DataFrame.\n",
      " |      \n",
      " |      >>> df.eval('C = A + B', inplace=True)\n",
      " |      >>> df\n",
      " |         A   B   C\n",
      " |      0  1  10  11\n",
      " |      1  2   8  10\n",
      " |      2  3   6   9\n",
      " |      3  4   4   8\n",
      " |      4  5   2   7\n",
      " |      \n",
      " |      Multiple columns can be assigned to using multi-line expressions:\n",
      " |      \n",
      " |      >>> df.eval(\n",
      " |      ...     '''\n",
      " |      ... C = A + B\n",
      " |      ... D = A - B\n",
      " |      ... '''\n",
      " |      ... )\n",
      " |         A   B   C  D\n",
      " |      0  1  10  11 -9\n",
      " |      1  2   8  10 -6\n",
      " |      2  3   6   9 -3\n",
      " |      3  4   4   8  0\n",
      " |      4  5   2   7  3\n",
      " |  \n",
      " |  explode(self, column: 'str | tuple | list[str | tuple]', ignore_index: 'bool' = False) -> 'DataFrame'\n",
      " |      Transform each element of a list-like to a row, replicating index values.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      column : str or tuple or list thereof\n",
      " |          Column(s) to explode.\n",
      " |          For multiple columns, specify a non-empty list with each element\n",
      " |          be str or tuple, and all specified columns their list-like data\n",
      " |          on same row of the frame must have matching length.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |              Multi-column explode\n",
      " |      \n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Exploded lists to rows of the subset columns;\n",
      " |          index will be duplicated for these rows.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError :\n",
      " |          * If columns of the frame are not unique.\n",
      " |          * If specified columns to explode is empty list.\n",
      " |          * If specified columns to explode have not matching count of\n",
      " |            elements rowwise in the frame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\n",
      " |          index labels.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      Series.explode : Explode a DataFrame from list-like columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples, sets,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged, and empty list-likes will\n",
      " |      result in a np.nan for that row. In addition, the ordering of rows in the\n",
      " |      output will be non-deterministic when exploding sets.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\n",
      " |      ...                    'B': 1,\n",
      " |      ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\n",
      " |      >>> df\n",
      " |                 A  B          C\n",
      " |      0  [0, 1, 2]  1  [a, b, c]\n",
      " |      1        foo  1        NaN\n",
      " |      2         []  1         []\n",
      " |      3     [3, 4]  1     [d, e]\n",
      " |      \n",
      " |      Single-column explode.\n",
      " |      \n",
      " |      >>> df.explode('A')\n",
      " |           A  B          C\n",
      " |      0    0  1  [a, b, c]\n",
      " |      0    1  1  [a, b, c]\n",
      " |      0    2  1  [a, b, c]\n",
      " |      1  foo  1        NaN\n",
      " |      2  NaN  1         []\n",
      " |      3    3  1     [d, e]\n",
      " |      3    4  1     [d, e]\n",
      " |      \n",
      " |      Multi-column explode.\n",
      " |      \n",
      " |      >>> df.explode(list('AC'))\n",
      " |           A  B    C\n",
      " |      0    0  1    a\n",
      " |      0    1  1    b\n",
      " |      0    2  1    c\n",
      " |      1  foo  1  NaN\n",
      " |      2  NaN  1  NaN\n",
      " |      3    3  1    d\n",
      " |      3    4  1    e\n",
      " |  \n",
      " |  ffill(self: 'DataFrame', axis: 'None | Axis' = None, inplace: 'bool' = False, limit: 'None | int' = None, downcast=None) -> 'DataFrame | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  fillna(self, value: 'object | ArrayLike | None' = None, method: 'FillnaOptions | None' = None, axis: 'Axis | None' = None, inplace: 'bool' = False, limit=None, downcast=None) -> 'DataFrame | None'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Axis along which to fill missing values.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method=\"ffill\")\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |      \n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rfloordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  groupby(self, by=None, axis: 'Axis' = 0, level: 'Level | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool | lib.NoDefault' = <no_default>, observed: 'bool' = False, dropna: 'bool' = True) -> 'DataFrameGroupBy'\n",
      " |      Group DataFrame using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is to determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1).\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply, add group keys to index to identify pieces.\n",
      " |      squeeze : bool, default False\n",
      " |          Reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |      \n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      dropna : bool, default True\n",
      " |          If True, and if group keys contain NA values, NA values together\n",
      " |          with row/column will be dropped.\n",
      " |          If False, NA values will also be treated as the key in groups\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrameGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`__ for more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
      " |      ...                               'Parrot', 'Parrot'],\n",
      " |      ...                    'Max Speed': [380., 370., 24., 26.]})\n",
      " |      >>> df\n",
      " |         Animal  Max Speed\n",
      " |      0  Falcon      380.0\n",
      " |      1  Falcon      370.0\n",
      " |      2  Parrot       24.0\n",
      " |      3  Parrot       26.0\n",
      " |      >>> df.groupby(['Animal']).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      375.0\n",
      " |      Parrot       25.0\n",
      " |      \n",
      " |      **Hierarchical Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                      Max Speed\n",
      " |      Animal Type\n",
      " |      Falcon Captive      390.0\n",
      " |             Wild         350.0\n",
      " |      Parrot Captive       30.0\n",
      " |             Wild          20.0\n",
      " |      >>> df.groupby(level=0).mean()\n",
      " |              Max Speed\n",
      " |      Animal\n",
      " |      Falcon      370.0\n",
      " |      Parrot       25.0\n",
      " |      >>> df.groupby(level=\"Type\").mean()\n",
      " |               Max Speed\n",
      " |      Type\n",
      " |      Captive      210.0\n",
      " |      Wild         185.0\n",
      " |      \n",
      " |      We can also choose to include NA in group keys or not by setting\n",
      " |      `dropna` parameter, the default setting is `True`:\n",
      " |      \n",
      " |      >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"]).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      \n",
      " |      >>> df.groupby(by=[\"b\"], dropna=False).sum()\n",
      " |          a   c\n",
      " |      b\n",
      " |      1.0 2   3\n",
      " |      2.0 2   5\n",
      " |      NaN 1   4\n",
      " |      \n",
      " |      >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\n",
      " |      >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\").sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      \n",
      " |      >>> df.groupby(by=\"a\", dropna=False).sum()\n",
      " |          b     c\n",
      " |      a\n",
      " |      a   13.0   13.0\n",
      " |      b   12.3  123.0\n",
      " |      NaN 12.3   33.0\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  hist = hist_frame(data: 'DataFrame', column: 'IndexLabel' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the DataFrame's columns.\n",
      " |      \n",
      " |      A `histogram`_ is a representation of the distribution of data.\n",
      " |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in\n",
      " |      the DataFrame, resulting in one histogram per column.\n",
      " |      \n",
      " |      .. _histogram: https://en.wikipedia.org/wiki/Histogram\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          The pandas object holding the data.\n",
      " |      column : str or sequence, optional\n",
      " |          If passed, will be used to limit data to a subset of columns.\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels. For example, a value of 90 displays the\n",
      " |          x labels rotated 90 degrees clockwise.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels. For example, a value of 90 displays the\n",
      " |          y labels rotated 90 degrees clockwise.\n",
      " |      ax : Matplotlib axes object, default None\n",
      " |          The axes to plot the histogram on.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case subplots=True, share x axis and set some x axis labels to\n",
      " |          invisible; defaults to True if ax is None otherwise False if an ax\n",
      " |          is passed in.\n",
      " |          Note that passing in both an ax and sharex=True will alter all x axis\n",
      " |          labels for all subplots in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case subplots=True, share y axis and set some y axis labels to\n",
      " |          invisible.\n",
      " |      figsize : tuple, optional\n",
      " |          The size in inches of the figure to create. Uses the value in\n",
      " |          `matplotlib.rcParams` by default.\n",
      " |      layout : tuple, optional\n",
      " |          Tuple of (rows, columns) for the layout of the histograms.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      \n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          All other plotting keyword arguments to be passed to\n",
      " |          :meth:`matplotlib.pyplot.hist`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot or numpy.ndarray of them\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      This example draws a histogram based on the length and width of\n",
      " |      some animals, displayed in three bins\n",
      " |      \n",
      " |      .. plot::\n",
      " |          :context: close-figs\n",
      " |      \n",
      " |          >>> df = pd.DataFrame({\n",
      " |          ...     'length': [1.5, 0.5, 1.2, 0.9, 3],\n",
      " |          ...     'width': [0.7, 0.2, 0.15, 0.2, 1.1]\n",
      " |          ...     }, index=['pig', 'rabbit', 'duck', 'chicken', 'horse'])\n",
      " |          >>> hist = df.hist(bins=3)\n",
      " |  \n",
      " |  idxmax(self, axis: 'Axis' = 0, skipna: 'bool' = True) -> 'Series'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of maxima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax : Return index of the maximum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the maximum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmax()\n",
      " |      consumption     Wheat Products\n",
      " |      co2_emissions             Beef\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the maximum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmax(axis=\"columns\")\n",
      " |      Pork              co2_emissions\n",
      " |      Wheat Products     consumption\n",
      " |      Beef              co2_emissions\n",
      " |      dtype: object\n",
      " |  \n",
      " |  idxmin(self, axis: 'Axis' = 0, skipna: 'bool' = True) -> 'Series'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      \n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Indexes of minima along the specified axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If the row/column is empty\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin : Return index of the minimum element.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider a dataset containing food consumption in Argentina.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48],\n",
      " |      ...                    'co2_emissions': [37.2, 19.66, 1712]},\n",
      " |      ...                    index=['Pork', 'Wheat Products', 'Beef'])\n",
      " |      \n",
      " |      >>> df\n",
      " |                      consumption  co2_emissions\n",
      " |      Pork                  10.51         37.20\n",
      " |      Wheat Products       103.11         19.66\n",
      " |      Beef                  55.48       1712.00\n",
      " |      \n",
      " |      By default, it returns the index for the minimum value in each column.\n",
      " |      \n",
      " |      >>> df.idxmin()\n",
      " |      consumption                Pork\n",
      " |      co2_emissions    Wheat Products\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To return the index for the minimum value in each row, use ``axis=\"columns\"``.\n",
      " |      \n",
      " |      >>> df.idxmin(axis=\"columns\")\n",
      " |      Pork                consumption\n",
      " |      Wheat Products    co2_emissions\n",
      " |      Beef                consumption\n",
      " |      dtype: object\n",
      " |  \n",
      " |  info(self, verbose: 'bool | None' = None, buf: 'IO[str] | None' = None, max_cols: 'int | None' = None, memory_usage: 'bool | str | None' = None, show_counts: 'bool | None' = None, null_counts: 'bool | None' = None) -> 'None'\n",
      " |      Print a concise summary of a DataFrame.\n",
      " |      \n",
      " |      This method prints information about a DataFrame including\n",
      " |      the index dtype and columns, non-null values and memory usage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |          DataFrame to print information about.\n",
      " |      verbose : bool, optional\n",
      " |          Whether to print the full summary. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is followed.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      max_cols : int, optional\n",
      " |          When to switch from the verbose to the truncated output. If the\n",
      " |          DataFrame has more than `max_cols` columns, the truncated output\n",
      " |          is used. By default, the setting in\n",
      " |          ``pandas.options.display.max_info_columns`` is used.\n",
      " |      memory_usage : bool, str, optional\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including the index) should be displayed. By default,\n",
      " |          this follows the ``pandas.options.display.memory_usage`` setting.\n",
      " |      \n",
      " |          True always show memory usage. False never shows memory usage.\n",
      " |          A value of 'deep' is equivalent to \"True with deep introspection\".\n",
      " |          Memory usage is shown in human-readable units (base-2\n",
      " |          representation). Without deep introspection a memory estimation is\n",
      " |          made based in column dtype and number of rows assuming values\n",
      " |          consume the same memory amount for corresponding dtypes. With deep\n",
      " |          memory introspection, a real memory usage calculation is performed\n",
      " |          at the cost of computational resources.\n",
      " |      show_counts : bool, optional\n",
      " |          Whether to show the non-null counts. By default, this is shown\n",
      " |          only if the DataFrame is smaller than\n",
      " |          ``pandas.options.display.max_info_rows`` and\n",
      " |          ``pandas.options.display.max_info_columns``. A value of True always\n",
      " |          shows the counts, and False never shows the counts.\n",
      " |      null_counts : bool, optional\n",
      " |          .. deprecated:: 1.2.0\n",
      " |              Use show_counts instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          This method prints a summary of a DataFrame and returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.describe: Generate descriptive statistics of DataFrame\n",
      " |          columns.\n",
      " |      DataFrame.memory_usage: Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> int_values = [1, 2, 3, 4, 5]\n",
      " |      >>> text_values = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
      " |      >>> float_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
      " |      >>> df = pd.DataFrame({\"int_col\": int_values, \"text_col\": text_values,\n",
      " |      ...                   \"float_col\": float_values})\n",
      " |      >>> df\n",
      " |          int_col text_col  float_col\n",
      " |      0        1    alpha       0.00\n",
      " |      1        2     beta       0.25\n",
      " |      2        3    gamma       0.50\n",
      " |      3        4    delta       0.75\n",
      " |      4        5  epsilon       1.00\n",
      " |      \n",
      " |      Prints information of all columns:\n",
      " |      \n",
      " |      >>> df.info(verbose=True)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column     Non-Null Count  Dtype\n",
      " |      ---  ------     --------------  -----\n",
      " |       0   int_col    5 non-null      int64\n",
      " |       1   text_col   5 non-null      object\n",
      " |       2   float_col  5 non-null      float64\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Prints a summary of columns count and its dtypes but not per column\n",
      " |      information:\n",
      " |      \n",
      " |      >>> df.info(verbose=False)\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 5 entries, 0 to 4\n",
      " |      Columns: 3 entries, int_col to float_col\n",
      " |      dtypes: float64(1), int64(1), object(1)\n",
      " |      memory usage: 248.0+ bytes\n",
      " |      \n",
      " |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get\n",
      " |      buffer content and writes to a text file:\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> buffer = io.StringIO()\n",
      " |      >>> df.info(buf=buffer)\n",
      " |      >>> s = buffer.getvalue()\n",
      " |      >>> with open(\"df_info.txt\", \"w\",\n",
      " |      ...           encoding=\"utf-8\") as f:  # doctest: +SKIP\n",
      " |      ...     f.write(s)\n",
      " |      260\n",
      " |      \n",
      " |      The `memory_usage` parameter allows deep introspection mode, specially\n",
      " |      useful for big DataFrames and fine-tune memory optimization:\n",
      " |      \n",
      " |      >>> random_strings_array = np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'column_1': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_2': np.random.choice(['a', 'b', 'c'], 10 ** 6),\n",
      " |      ...     'column_3': np.random.choice(['a', 'b', 'c'], 10 ** 6)\n",
      " |      ... })\n",
      " |      >>> df.info()\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 22.9+ MB\n",
      " |      \n",
      " |      >>> df.info(memory_usage='deep')\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      RangeIndex: 1000000 entries, 0 to 999999\n",
      " |      Data columns (total 3 columns):\n",
      " |       #   Column    Non-Null Count    Dtype\n",
      " |      ---  ------    --------------    -----\n",
      " |       0   column_1  1000000 non-null  object\n",
      " |       1   column_2  1000000 non-null  object\n",
      " |       2   column_3  1000000 non-null  object\n",
      " |      dtypes: object(3)\n",
      " |      memory usage: 165.9 MB\n",
      " |  \n",
      " |  insert(self, loc, column, value, allow_duplicates: 'bool' = False) -> 'None'\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      Raises a ValueError if `column` is already contained in the DataFrame,\n",
      " |      unless `allow_duplicates` is set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Insertion index. Must verify 0 <= loc <= len(columns).\n",
      " |      column : str, number, or hashable object\n",
      " |          Label of the inserted column.\n",
      " |      value : int, Series, or array-like\n",
      " |      allow_duplicates : bool, optional\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.insert : Insert new item by index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      >>> df.insert(1, \"newcol\", [99, 99])\n",
      " |      >>> df\n",
      " |         col1  newcol  col2\n",
      " |      0     1      99     3\n",
      " |      1     2      99     4\n",
      " |      >>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\n",
      " |      >>> df\n",
      " |         col1  col1  newcol  col2\n",
      " |      0   100     1      99     3\n",
      " |      1   100     2      99     4\n",
      " |      \n",
      " |      Notice that pandas uses index alignment in case of `value` from type `Series`:\n",
      " |      \n",
      " |      >>> df.insert(0, \"col0\", pd.Series([5, 6], index=[1, 2]))\n",
      " |      >>> df\n",
      " |         col0  col1  col1  newcol  col2\n",
      " |      0   NaN   100     1      99     3\n",
      " |      1   5.0   100     2      99     4\n",
      " |  \n",
      " |  interpolate(self: 'DataFrame', method: 'str' = 'linear', axis: 'Axis' = 0, limit: 'int | None' = None, inplace: 'bool' = False, limit_direction: 'str | None' = None, limit_area: 'str | None' = None, downcast: 'str | None' = None, **kwargs) -> 'DataFrame | None'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      \n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |      \n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |      \n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |              raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |                  method is 'backfill' or 'bfill'.\n",
      " |              raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |                  method is 'pad' or 'ffill'.\n",
      " |      \n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |      and `SciPy tutorial\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  isin(self, values) -> 'DataFrame'\n",
      " |      Whether each element in the DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dict\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dict, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame of booleans showing whether each element in the DataFrame\n",
      " |          is contained in values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq: Equality test for DataFrame.\n",
      " |      Series.isin: Equivalent method on Series.\n",
      " |      Series.str.contains: Test if pattern or regex is contained within a\n",
      " |          string of a Series or Index.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
      " |      ...                   index=['falcon', 'dog'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      \n",
      " |      When ``values`` is a list check whether every value in the DataFrame\n",
      " |      is present in the list (which animals have 0 or 2 legs or wings)\n",
      " |      \n",
      " |      >>> df.isin([0, 2])\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a dict, we can pass values to check for each\n",
      " |      column separately:\n",
      " |      \n",
      " |      >>> df.isin({'num_wings': [0, 3]})\n",
      " |              num_legs  num_wings\n",
      " |      falcon     False      False\n",
      " |      dog        False       True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame the index and column must\n",
      " |      match. Note that 'falcon' does not match based on the number of legs\n",
      " |      in df2.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'num_legs': [8, 2], 'num_wings': [0, 2]},\n",
      " |      ...                      index=['spider', 'falcon'])\n",
      " |      >>> df.isin(other)\n",
      " |              num_legs  num_wings\n",
      " |      falcon      True       True\n",
      " |      dog        False      False\n",
      " |  \n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isnull : Alias of isna.\n",
      " |      DataFrame.notna : Boolean inverse of isna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iteritems(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Iterates over the DataFrame columns, returning a tuple with\n",
      " |      the column name and the content as a Series.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      label : object\n",
      " |          The column names for the DataFrame being iterated over.\n",
      " |      content : Series\n",
      " |          The column entries belonging to each label, as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as\n",
      " |          (index, Series) pairs.\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\n",
      " |          of the values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\n",
      " |      ...                   'population': [1864, 22000, 80000]},\n",
      " |      ...                   index=['panda', 'polar', 'koala'])\n",
      " |      >>> df\n",
      " |              species   population\n",
      " |      panda   bear      1864\n",
      " |      polar   bear      22000\n",
      " |      koala   marsupial 80000\n",
      " |      >>> for label, content in df.items():\n",
      " |      ...     print(f'label: {label}')\n",
      " |      ...     print(f'content: {content}', sep='\\n')\n",
      " |      ...\n",
      " |      label: species\n",
      " |      content:\n",
      " |      panda         bear\n",
      " |      polar         bear\n",
      " |      koala    marsupial\n",
      " |      Name: species, dtype: object\n",
      " |      label: population\n",
      " |      content:\n",
      " |      panda     1864\n",
      " |      polar    22000\n",
      " |      koala    80000\n",
      " |      Name: population, dtype: int64\n",
      " |  \n",
      " |  iterrows(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      index : label or tuple of label\n",
      " |          The index of the row. A tuple for a `MultiIndex`.\n",
      " |      data : Series\n",
      " |          The data of the row as a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      1. Because ``iterrows`` returns a Series for each row,\n",
      " |         it does **not** preserve dtypes across the rows (dtypes are\n",
      " |         preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |         >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\n",
      " |         >>> row = next(df.iterrows())[1]\n",
      " |         >>> row\n",
      " |         int      1.0\n",
      " |         float    1.5\n",
      " |         Name: 0, dtype: float64\n",
      " |         >>> print(row['int'].dtype)\n",
      " |         float64\n",
      " |         >>> print(df['int'].dtype)\n",
      " |         int64\n",
      " |      \n",
      " |         To preserve dtypes while iterating over the rows, it is better\n",
      " |         to use :meth:`itertuples` which returns namedtuples of the values\n",
      " |         and which is generally faster than ``iterrows``.\n",
      " |      \n",
      " |      2. You should **never modify** something you are iterating over.\n",
      " |         This is not guaranteed to work in all cases. Depending on the\n",
      " |         data types, the iterator returns a copy and not a view, and writing\n",
      " |         to it will have no effect.\n",
      " |  \n",
      " |  itertuples(self, index: 'bool' = True, name: 'str | None' = 'Pandas') -> 'Iterable[tuple[Any, ...]]'\n",
      " |      Iterate over DataFrame rows as namedtuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          If True, return the index as the first element of the tuple.\n",
      " |      name : str or None, default \"Pandas\"\n",
      " |          The name of the returned namedtuples or None to return regular\n",
      " |          tuples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          An object to iterate over namedtuples for each row in the\n",
      " |          DataFrame with the first field possibly being the index and\n",
      " |          following fields being the column values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\n",
      " |          pairs.\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The column names will be renamed to positional names if they are\n",
      " |      invalid Python identifiers, repeated, or start with an underscore.\n",
      " |      On python versions < 3.7 regular tuples are returned for DataFrames\n",
      " |      with a large number of columns (>254).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\n",
      " |      ...                   index=['dog', 'hawk'])\n",
      " |      >>> df\n",
      " |            num_legs  num_wings\n",
      " |      dog          4          0\n",
      " |      hawk         2          2\n",
      " |      >>> for row in df.itertuples():\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Pandas(Index='hawk', num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      By setting the `index` parameter to False we can remove the index\n",
      " |      as the first element of the tuple:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(index=False):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Pandas(num_legs=4, num_wings=0)\n",
      " |      Pandas(num_legs=2, num_wings=2)\n",
      " |      \n",
      " |      With the `name` parameter set we set a custom name for the yielded\n",
      " |      namedtuples:\n",
      " |      \n",
      " |      >>> for row in df.itertuples(name='Animal'):\n",
      " |      ...     print(row)\n",
      " |      ...\n",
      " |      Animal(Index='dog', num_legs=4, num_wings=0)\n",
      " |      Animal(Index='hawk', num_legs=2, num_wings=2)\n",
      " |  \n",
      " |  join(self, other: 'FrameOrSeriesUnion', on: 'IndexLabel | None' = None, how: 'str' = 'left', lsuffix: 'str' = '', rsuffix: 'str' = '', sort: 'bool' = False) -> 'DataFrame'\n",
      " |      Join columns of another DataFrame.\n",
      " |      \n",
      " |      Join columns with `other` DataFrame either on index or on a key\n",
      " |      column. Efficiently join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series, or list of DataFrame\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame.\n",
      " |      on : str, list of str, or array-like, optional\n",
      " |          Column or index level name(s) in the caller to join on the index\n",
      " |          in `other`, otherwise joins index-on-index. If multiple\n",
      " |          values given, the `other` DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if it is not already contained in\n",
      " |          the calling DataFrame. Like an Excel VLOOKUP operation.\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'left'\n",
      " |          How to handle the operation of the two objects.\n",
      " |      \n",
      " |          * left: use calling frame's index (or column if on is specified)\n",
      " |          * right: use `other`'s index.\n",
      " |          * outer: form union of calling frame's index (or column if on is\n",
      " |            specified) with `other`'s index, and sort it.\n",
      " |            lexicographically.\n",
      " |          * inner: form intersection of calling frame's index (or column if\n",
      " |            on is specified) with `other`'s index, preserving the order\n",
      " |            of the calling's one.\n",
      " |      lsuffix : str, default ''\n",
      " |          Suffix to use from left frame's overlapping columns.\n",
      " |      rsuffix : str, default ''\n",
      " |          Suffix to use from right frame's overlapping columns.\n",
      " |      sort : bool, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          the order of the join key depends on the join type (how keyword).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A dataframe containing columns from both the caller and `other`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\n",
      " |      passing a list of `DataFrame` objects.\n",
      " |      \n",
      " |      Support for specifying index levels as the `on` parameter was added\n",
      " |      in version 0.23.0.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
      " |      ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
      " |      \n",
      " |      >>> df\n",
      " |        key   A\n",
      " |      0  K0  A0\n",
      " |      1  K1  A1\n",
      " |      2  K2  A2\n",
      " |      3  K3  A3\n",
      " |      4  K4  A4\n",
      " |      5  K5  A5\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
      " |      ...                       'B': ['B0', 'B1', 'B2']})\n",
      " |      \n",
      " |      >>> other\n",
      " |        key   B\n",
      " |      0  K0  B0\n",
      " |      1  K1  B1\n",
      " |      2  K2  B2\n",
      " |      \n",
      " |      Join DataFrames using their indexes.\n",
      " |      \n",
      " |      >>> df.join(other, lsuffix='_caller', rsuffix='_other')\n",
      " |        key_caller   A key_other    B\n",
      " |      0         K0  A0        K0   B0\n",
      " |      1         K1  A1        K1   B1\n",
      " |      2         K2  A2        K2   B2\n",
      " |      3         K3  A3       NaN  NaN\n",
      " |      4         K4  A4       NaN  NaN\n",
      " |      5         K5  A5       NaN  NaN\n",
      " |      \n",
      " |      If we want to join using the key columns, we need to set key to be\n",
      " |      the index in both `df` and `other`. The joined DataFrame will have\n",
      " |      key as its index.\n",
      " |      \n",
      " |      >>> df.set_index('key').join(other.set_index('key'))\n",
      " |            A    B\n",
      " |      key\n",
      " |      K0   A0   B0\n",
      " |      K1   A1   B1\n",
      " |      K2   A2   B2\n",
      " |      K3   A3  NaN\n",
      " |      K4   A4  NaN\n",
      " |      K5   A5  NaN\n",
      " |      \n",
      " |      Another option to join using the key columns is to use the `on`\n",
      " |      parameter. DataFrame.join always uses `other`'s index but we can use\n",
      " |      any column in `df`. This method preserves the original DataFrame's\n",
      " |      index in the result.\n",
      " |      \n",
      " |      >>> df.join(other.set_index('key'), on='key')\n",
      " |        key   A    B\n",
      " |      0  K0  A0   B0\n",
      " |      1  K1  A1   B1\n",
      " |      2  K2  A2   B2\n",
      " |      3  K3  A3  NaN\n",
      " |      4  K4  A4  NaN\n",
      " |      5  K5  A5  NaN\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  lookup(self, row_labels: 'Sequence[IndexLabel]', col_labels: 'Sequence[IndexLabel]') -> 'np.ndarray'\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          DataFrame.lookup is deprecated,\n",
      " |          use DataFrame.melt and DataFrame.loc instead.\n",
      " |          For further details see\n",
      " |          :ref:`Looking up values by index/column labels <indexing.lookup>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup.\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The found values.\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Get Less than of dataframe and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default None\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=<no_default>)\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level: 'Level | None' = None, ignore_index: 'bool' = True) -> 'DataFrame'\n",
      " |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
      " |      \n",
      " |      This function is useful to massage a DataFrame into a format where one\n",
      " |      or more columns are identifier variables (`id_vars`), while all other\n",
      " |      columns, considered measured variables (`value_vars`), are \"unpivoted\" to\n",
      " |      the row axis, leaving just two non-identifier columns, 'variable' and\n",
      " |      'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      id_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to use as identifier variables.\n",
      " |      value_vars : tuple, list, or ndarray, optional\n",
      " |          Column(s) to unpivot. If not specified, uses all columns that\n",
      " |          are not set as `id_vars`.\n",
      " |      var_name : scalar\n",
      " |          Name to use for the 'variable' column. If None it uses\n",
      " |          ``frame.columns.name`` or 'variable'.\n",
      " |      value_name : scalar, default 'value'\n",
      " |          Name to use for the 'value' column.\n",
      " |      col_level : int or str, optional\n",
      " |          If columns are a MultiIndex then use this level to melt.\n",
      " |      ignore_index : bool, default True\n",
      " |          If True, original index is ignored. If False, the original index is retained.\n",
      " |          Index labels will be repeated as necessary.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unpivoted DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      melt : Identical method.\n",
      " |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      DataFrame.pivot : Return reshaped DataFrame organized\n",
      " |          by given index / column values.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |              columns to long format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n",
      " |      ...                    'B': {0: 1, 1: 3, 2: 5},\n",
      " |      ...                    'C': {0: 2, 1: 4, 2: 6}})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      3  a        C      2\n",
      " |      4  b        C      4\n",
      " |      5  c        C      6\n",
      " |      \n",
      " |      The names of 'variable' and 'value' columns can be customized:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B'],\n",
      " |      ...         var_name='myVarname', value_name='myValname')\n",
      " |         A myVarname  myValname\n",
      " |      0  a         B          1\n",
      " |      1  b         B          3\n",
      " |      2  c         B          5\n",
      " |      \n",
      " |      Original index values can be kept around:\n",
      " |      \n",
      " |      >>> df.melt(id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      0  a        C      2\n",
      " |      1  b        C      4\n",
      " |      2  c        C      6\n",
      " |      \n",
      " |      If you have multi-index columns:\n",
      " |      \n",
      " |      >>> df.columns = [list('ABC'), list('DEF')]\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |         D  E  F\n",
      " |      0  a  1  2\n",
      " |      1  b  3  4\n",
      " |      2  c  5  6\n",
      " |      \n",
      " |      >>> df.melt(col_level=0, id_vars=['A'], value_vars=['B'])\n",
      " |         A variable  value\n",
      " |      0  a        B      1\n",
      " |      1  b        B      3\n",
      " |      2  c        B      5\n",
      " |      \n",
      " |      >>> df.melt(id_vars=[('A', 'D')], value_vars=[('B', 'E')])\n",
      " |        (A, D) variable_0 variable_1  value\n",
      " |      0      a          B          E      1\n",
      " |      1      b          B          E      3\n",
      " |      2      c          B          E      5\n",
      " |  \n",
      " |  memory_usage(self, index: 'bool' = True, deep: 'bool' = False) -> 'Series'\n",
      " |      Return the memory usage of each column in bytes.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and elements of `object` dtype.\n",
      " |      \n",
      " |      This value is displayed in `DataFrame.info` by default. This can be\n",
      " |      suppressed by setting ``pandas.options.display.memory_usage`` to False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the DataFrame's\n",
      " |          index in returned Series. If ``index=True``, the memory usage of\n",
      " |          the index is the first item in the output.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series whose index is the original column names and whose values\n",
      " |          is the memory usage of each column in bytes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an\n",
      " |          ndarray.\n",
      " |      Series.memory_usage : Bytes consumed by a Series.\n",
      " |      Categorical : Memory-efficient array for string values with\n",
      " |          many repeated values.\n",
      " |      DataFrame.info : Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\n",
      " |      >>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))\n",
      " |      ...              for t in dtypes])\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df.head()\n",
      " |         int64  float64            complex128  object  bool\n",
      " |      0      1      1.0              1.0+0.0j       1  True\n",
      " |      1      1      1.0              1.0+0.0j       1  True\n",
      " |      2      1      1.0              1.0+0.0j       1  True\n",
      " |      3      1      1.0              1.0+0.0j       1  True\n",
      " |      4      1      1.0              1.0+0.0j       1  True\n",
      " |      \n",
      " |      >>> df.memory_usage()\n",
      " |      Index           128\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.memory_usage(index=False)\n",
      " |      int64         40000\n",
      " |      float64       40000\n",
      " |      complex128    80000\n",
      " |      object        40000\n",
      " |      bool           5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The memory footprint of `object` dtype columns is ignored by default:\n",
      " |      \n",
      " |      >>> df.memory_usage(deep=True)\n",
      " |      Index            128\n",
      " |      int64          40000\n",
      " |      float64        40000\n",
      " |      complex128     80000\n",
      " |      object        180000\n",
      " |      bool            5000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a Categorical for efficient storage of an object-dtype column with\n",
      " |      many repeated values.\n",
      " |      \n",
      " |      >>> df['object'].astype('category').memory_usage(deep=True)\n",
      " |      5244\n",
      " |  \n",
      " |  merge(self, right: 'FrameOrSeriesUnion', how: 'str' = 'inner', on: 'IndexLabel | None' = None, left_on: 'IndexLabel | None' = None, right_on: 'IndexLabel | None' = None, left_index: 'bool' = False, right_index: 'bool' = False, sort: 'bool' = False, suffixes: 'Suffixes' = ('_x', '_y'), copy: 'bool' = True, indicator: 'bool' = False, validate: 'str | None' = None) -> 'DataFrame'\n",
      " |      Merge DataFrame or named Series objects with a database-style join.\n",
      " |      \n",
      " |      A named Series object is treated as a DataFrame with a single named column.\n",
      " |      \n",
      " |      The join is done on columns or indexes. If joining columns on\n",
      " |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      " |      on indexes or indexes on a column or columns, the index will be passed on.\n",
      " |      When performing a cross merge, no column specifications to merge on are\n",
      " |      allowed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame or named Series\n",
      " |          Object to merge with.\n",
      " |      how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      " |          Type of merge to be performed.\n",
      " |      \n",
      " |          * left: use only keys from left frame, similar to a SQL left outer join;\n",
      " |            preserve key order.\n",
      " |          * right: use only keys from right frame, similar to a SQL right outer join;\n",
      " |            preserve key order.\n",
      " |          * outer: use union of keys from both frames, similar to a SQL full outer\n",
      " |            join; sort keys lexicographically.\n",
      " |          * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      " |            join; preserve the order of the left keys.\n",
      " |          * cross: creates the cartesian product from both frames, preserves the order\n",
      " |            of the left keys.\n",
      " |      \n",
      " |            .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      on : label or list\n",
      " |          Column or index level names to join on. These must be found in both\n",
      " |          DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      " |          to the intersection of the columns in both DataFrames.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the left DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the left DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      right_on : label or list, or array-like\n",
      " |          Column or index level names to join on in the right DataFrame. Can also\n",
      " |          be an array or list of arrays of the length of the right DataFrame.\n",
      " |          These arrays are treated as if they are columns.\n",
      " |      left_index : bool, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels.\n",
      " |      right_index : bool, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index.\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |      suffixes : list-like, default is (\"_x\", \"_y\")\n",
      " |          A length-2 sequence where each element is optionally a string\n",
      " |          indicating the suffix to add to overlapping column names in\n",
      " |          `left` and `right` respectively. Pass a value of `None` instead\n",
      " |          of a string to indicate that the column name from `left` or\n",
      " |          `right` should be left as-is, with no suffix. At least one of the\n",
      " |          values must not be None.\n",
      " |      copy : bool, default True\n",
      " |          If False, avoid copy if possible.\n",
      " |      indicator : bool or str, default False\n",
      " |          If True, adds a column to the output DataFrame called \"_merge\" with\n",
      " |          information on the source of each row. The column can be given a different\n",
      " |          name by providing a string argument. The column will have a Categorical\n",
      " |          type with the value of \"left_only\" for observations whose merge key only\n",
      " |          appears in the left DataFrame, \"right_only\" for observations\n",
      " |          whose merge key only appears in the right DataFrame, and \"both\"\n",
      " |          if the observation's merge key is found in both DataFrames.\n",
      " |      \n",
      " |      validate : str, optional\n",
      " |          If specified, checks if merge is of specified type.\n",
      " |      \n",
      " |          * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      " |            left and right datasets.\n",
      " |          * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      " |            dataset.\n",
      " |          * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      " |            dataset.\n",
      " |          * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame of the two merged objects.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_ordered : Merge with optional filling/interpolation.\n",
      " |      merge_asof : Merge on nearest keys.\n",
      " |      DataFrame.join : Similar method using indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Support for specifying index levels as the `on`, `left_on`, and\n",
      " |      `right_on` parameters was added in version 0.23.0\n",
      " |      Support for merging named Series objects was added in version 0.24.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [1, 2, 3, 5]})\n",
      " |      >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      " |      ...                     'value': [5, 6, 7, 8]})\n",
      " |      >>> df1\n",
      " |          lkey value\n",
      " |      0   foo      1\n",
      " |      1   bar      2\n",
      " |      2   baz      3\n",
      " |      3   foo      5\n",
      " |      >>> df2\n",
      " |          rkey value\n",
      " |      0   foo      5\n",
      " |      1   bar      6\n",
      " |      2   baz      7\n",
      " |      3   foo      8\n",
      " |      \n",
      " |      Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      " |      the default suffixes, _x and _y, appended.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      " |        lkey  value_x rkey  value_y\n",
      " |      0  foo        1  foo        5\n",
      " |      1  foo        1  foo        8\n",
      " |      2  foo        5  foo        5\n",
      " |      3  foo        5  foo        8\n",
      " |      4  bar        2  bar        6\n",
      " |      5  baz        3  baz        7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      " |      appended to any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      " |      ...           suffixes=('_left', '_right'))\n",
      " |        lkey  value_left rkey  value_right\n",
      " |      0  foo           1  foo            5\n",
      " |      1  foo           1  foo            8\n",
      " |      2  foo           5  foo            5\n",
      " |      3  foo           5  foo            8\n",
      " |      4  bar           2  bar            6\n",
      " |      5  baz           3  baz            7\n",
      " |      \n",
      " |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      " |      any overlapping columns.\n",
      " |      \n",
      " |      >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: columns overlap but no suffix specified:\n",
      " |          Index(['value'], dtype='object')\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      " |      >>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      " |      >>> df1\n",
      " |            a  b\n",
      " |      0   foo  1\n",
      " |      1   bar  2\n",
      " |      >>> df2\n",
      " |            a  c\n",
      " |      0   foo  3\n",
      " |      1   baz  4\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='inner', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='left', on='a')\n",
      " |            a  b  c\n",
      " |      0   foo  1  3.0\n",
      " |      1   bar  2  NaN\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      " |      >>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      " |      >>> df1\n",
      " |          left\n",
      " |      0   foo\n",
      " |      1   bar\n",
      " |      >>> df2\n",
      " |          right\n",
      " |      0   7\n",
      " |      1   8\n",
      " |      \n",
      " |      >>> df1.merge(df2, how='cross')\n",
      " |         left  right\n",
      " |      0   foo      7\n",
      " |      1   foo      8\n",
      " |      2   bar      7\n",
      " |      3   bar      8\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |      \n",
      " |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  mode(self, axis: 'Axis' = 0, numeric_only: 'bool' = False, dropna: 'bool' = True) -> 'DataFrame'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |      \n",
      " |      The mode of a set of values is the value that appears most often.\n",
      " |      It can be multiple values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to iterate over while searching for the mode:\n",
      " |      \n",
      " |          * 0 or 'index' : get mode of each column\n",
      " |          * 1 or 'columns' : get mode of each row.\n",
      " |      \n",
      " |      numeric_only : bool, default False\n",
      " |          If True, only apply to numeric columns.\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The modes of each column or row.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mode : Return the highest frequency value in a Series.\n",
      " |      Series.value_counts : Return the counts of values in a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 2, 2),\n",
      " |      ...                    ('mammal', 4, np.nan),\n",
      " |      ...                    ('arthropod', 8, 0),\n",
      " |      ...                    ('bird', 2, np.nan)],\n",
      " |      ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\n",
      " |      ...                   columns=('species', 'legs', 'wings'))\n",
      " |      >>> df\n",
      " |                 species  legs  wings\n",
      " |      falcon        bird     2    2.0\n",
      " |      horse       mammal     4    NaN\n",
      " |      spider   arthropod     8    0.0\n",
      " |      ostrich       bird     2    NaN\n",
      " |      \n",
      " |      By default, missing values are not considered, and the mode of wings\n",
      " |      are both 0 and 2. Because the resulting DataFrame has two rows,\n",
      " |      the second row of ``species`` and ``legs`` contains ``NaN``.\n",
      " |      \n",
      " |      >>> df.mode()\n",
      " |        species  legs  wings\n",
      " |      0    bird   2.0    0.0\n",
      " |      1     NaN   NaN    2.0\n",
      " |      \n",
      " |      Setting ``dropna=False`` ``NaN`` values are considered and they can be\n",
      " |      the mode (like for wings).\n",
      " |      \n",
      " |      >>> df.mode(dropna=False)\n",
      " |        species  legs  wings\n",
      " |      0    bird     2    NaN\n",
      " |      \n",
      " |      Setting ``numeric_only=True``, only the mode of numeric columns is\n",
      " |      computed, and columns of other types are ignored.\n",
      " |      \n",
      " |      >>> df.mode(numeric_only=True)\n",
      " |         legs  wings\n",
      " |      0   2.0    0.0\n",
      " |      1   NaN    2.0\n",
      " |      \n",
      " |      To compute the mode over columns and not rows, use the axis parameter:\n",
      " |      \n",
      " |      >>> df.mode(axis='columns', numeric_only=True)\n",
      " |                 0    1\n",
      " |      falcon   2.0  NaN\n",
      " |      horse    4.0  NaN\n",
      " |      spider   0.0  8.0\n",
      " |      ostrich  2.0  NaN\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rmul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison\n",
      " |      operators.\n",
      " |      \n",
      " |      Equivalent to `==`, `!=`, `<=`, `<`, `>=`, `>` with support to choose axis\n",
      " |      (rows or columns) and level for comparison.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 'columns'\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns').\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the passed\n",
      " |          MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame of bool\n",
      " |          Result of the comparison.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.eq : Compare DataFrames for equality elementwise.\n",
      " |      DataFrame.ne : Compare DataFrames for inequality elementwise.\n",
      " |      DataFrame.le : Compare DataFrames for less than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.lt : Compare DataFrames for strictly less than\n",
      " |          inequality elementwise.\n",
      " |      DataFrame.ge : Compare DataFrames for greater than inequality\n",
      " |          or equality elementwise.\n",
      " |      DataFrame.gt : Compare DataFrames for strictly greater than\n",
      " |          inequality elementwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      `NaN` values are considered different (i.e. `NaN` != `NaN`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'cost': [250, 150, 100],\n",
      " |      ...                    'revenue': [100, 250, 300]},\n",
      " |      ...                   index=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |         cost  revenue\n",
      " |      A   250      100\n",
      " |      B   150      250\n",
      " |      C   100      300\n",
      " |      \n",
      " |      Comparison with a scalar, using either the operator or method:\n",
      " |      \n",
      " |      >>> df == 100\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      >>> df.eq(100)\n",
      " |          cost  revenue\n",
      " |      A  False     True\n",
      " |      B  False    False\n",
      " |      C   True    False\n",
      " |      \n",
      " |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned\n",
      " |      with the index of `other` and broadcast:\n",
      " |      \n",
      " |      >>> df != pd.Series([100, 250], index=[\"cost\", \"revenue\"])\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B   True    False\n",
      " |      C  False     True\n",
      " |      \n",
      " |      Use the method to control the broadcast axis:\n",
      " |      \n",
      " |      >>> df.ne(pd.Series([100, 300], index=[\"A\", \"D\"]), axis='index')\n",
      " |         cost  revenue\n",
      " |      A  True    False\n",
      " |      B  True     True\n",
      " |      C  True     True\n",
      " |      D  True     True\n",
      " |      \n",
      " |      When comparing to an arbitrary sequence, the number of columns must\n",
      " |      match the number elements in `other`:\n",
      " |      \n",
      " |      >>> df == [250, 100]\n",
      " |          cost  revenue\n",
      " |      A   True     True\n",
      " |      B  False    False\n",
      " |      C  False    False\n",
      " |      \n",
      " |      Use the method to control the axis:\n",
      " |      \n",
      " |      >>> df.eq([250, 250, 100], axis='index')\n",
      " |          cost  revenue\n",
      " |      A   True    False\n",
      " |      B  False     True\n",
      " |      C   True    False\n",
      " |      \n",
      " |      Compare to a DataFrame of different shape.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'revenue': [300, 250, 100, 150]},\n",
      " |      ...                      index=['A', 'B', 'C', 'D'])\n",
      " |      >>> other\n",
      " |         revenue\n",
      " |      A      300\n",
      " |      B      250\n",
      " |      C      100\n",
      " |      D      150\n",
      " |      \n",
      " |      >>> df.gt(other)\n",
      " |          cost  revenue\n",
      " |      A  False    False\n",
      " |      B  False    False\n",
      " |      C  False     True\n",
      " |      D  False    False\n",
      " |      \n",
      " |      Compare to a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'cost': [250, 150, 100, 150, 300, 220],\n",
      " |      ...                              'revenue': [100, 250, 300, 200, 175, 225]},\n",
      " |      ...                             index=[['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2'],\n",
      " |      ...                                    ['A', 'B', 'C', 'A', 'B', 'C']])\n",
      " |      >>> df_multindex\n",
      " |            cost  revenue\n",
      " |      Q1 A   250      100\n",
      " |         B   150      250\n",
      " |         C   100      300\n",
      " |      Q2 A   150      200\n",
      " |         B   300      175\n",
      " |         C   220      225\n",
      " |      \n",
      " |      >>> df.le(df_multindex, level=1)\n",
      " |             cost  revenue\n",
      " |      Q1 A   True     True\n",
      " |         B   True     True\n",
      " |         C   True     True\n",
      " |      Q2 A  False     True\n",
      " |         B   True    False\n",
      " |         C   True    False\n",
      " |  \n",
      " |  nlargest(self, n, columns, keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the largest values in `columns`, in\n",
      " |      descending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=False).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of rows to return.\n",
      " |      columns : label or list of labels\n",
      " |          Column label(s) to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - `first` : prioritize the first occurrence(s)\n",
      " |          - `last` : prioritize the last occurrence(s)\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |                      selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The first `n` rows ordered by the given columns in descending\n",
      " |          order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\n",
      " |          ascending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function cannot be used with all column types. For example, when\n",
      " |      specifying columns with `object` or `category` dtypes, ``TypeError`` is\n",
      " |      raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 11300,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru          11300      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nlargest`` to select the three\n",
      " |      rows having the largest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Malta       434000    12011      MT\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='last')\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nlargest(3, 'population', keep='all')\n",
      " |                population      GDP alpha-2\n",
      " |      France      65000000  2583560      FR\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      \n",
      " |      To order by the largest values in column \"population\" and then \"GDP\",\n",
      " |      we can specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nlargest(3, ['population', 'GDP'])\n",
      " |              population      GDP alpha-2\n",
      " |      France    65000000  2583560      FR\n",
      " |      Italy     59000000  1937894      IT\n",
      " |      Brunei      434000    12128      BN\n",
      " |  \n",
      " |  notna(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self) -> 'DataFrame'\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Mask of bool values for each element in DataFrame that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.notnull : Alias of notna.\n",
      " |      DataFrame.isna : Boolean inverse of notna.\n",
      " |      DataFrame.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
      " |      ...                    born=[pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                          pd.Timestamp('1940-04-25')],\n",
      " |      ...                    name=['Alfred', 'Batman', ''],\n",
      " |      ...                    toy=[None, 'Batmobile', 'Joker']))\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n, columns, keep: 'str' = 'first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |      \n",
      " |      Return the first `n` rows with the smallest values in `columns`, in\n",
      " |      ascending order. The columns that are not specified are returned as\n",
      " |      well, but not used for ordering.\n",
      " |      \n",
      " |      This method is equivalent to\n",
      " |      ``df.sort_values(columns, ascending=True).head(n)``, but more\n",
      " |      performant.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of items to retrieve.\n",
      " |      columns : list or str\n",
      " |          Column name or names to order by.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          Where there are duplicate values:\n",
      " |      \n",
      " |          - ``first`` : take the first occurrence.\n",
      " |          - ``last`` : take the last occurrence.\n",
      " |          - ``all`` : do not drop any duplicates, even it means\n",
      " |            selecting more than `n` items.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\n",
      " |          descending order.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values.\n",
      " |      DataFrame.head : Return the first `n` rows without re-ordering.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\n",
      " |      ...                                   434000, 434000, 337000, 337000,\n",
      " |      ...                                   11300, 11300],\n",
      " |      ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\n",
      " |      ...                            17036, 182, 38, 311],\n",
      " |      ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\n",
      " |      ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\n",
      " |      ...                   index=[\"Italy\", \"France\", \"Malta\",\n",
      " |      ...                          \"Maldives\", \"Brunei\", \"Iceland\",\n",
      " |      ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\n",
      " |      >>> df\n",
      " |                population      GDP alpha-2\n",
      " |      Italy       59000000  1937894      IT\n",
      " |      France      65000000  2583560      FR\n",
      " |      Malta         434000    12011      MT\n",
      " |      Maldives      434000     4520      MV\n",
      " |      Brunei        434000    12128      BN\n",
      " |      Iceland       337000    17036      IS\n",
      " |      Nauru         337000      182      NR\n",
      " |      Tuvalu         11300       38      TV\n",
      " |      Anguilla       11300      311      AI\n",
      " |      \n",
      " |      In the following example, we will use ``nsmallest`` to select the\n",
      " |      three rows having the smallest values in column \"population\".\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      \n",
      " |      When using ``keep='last'``, ties are resolved in reverse order:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='last')\n",
      " |                population  GDP alpha-2\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Nauru         337000  182      NR\n",
      " |      \n",
      " |      When using ``keep='all'``, all duplicate items are maintained:\n",
      " |      \n",
      " |      >>> df.nsmallest(3, 'population', keep='all')\n",
      " |                population    GDP alpha-2\n",
      " |      Tuvalu         11300     38      TV\n",
      " |      Anguilla       11300    311      AI\n",
      " |      Iceland       337000  17036      IS\n",
      " |      Nauru         337000    182      NR\n",
      " |      \n",
      " |      To order by the smallest values in column \"population\" and then \"GDP\", we can\n",
      " |      specify multiple columns like in the next example.\n",
      " |      \n",
      " |      >>> df.nsmallest(3, ['population', 'GDP'])\n",
      " |                population  GDP alpha-2\n",
      " |      Tuvalu         11300   38      TV\n",
      " |      Anguilla       11300  311      AI\n",
      " |      Nauru         337000  182      NR\n",
      " |  \n",
      " |  nunique(self, axis: 'Axis' = 0, dropna: 'bool' = True) -> 'Series'\n",
      " |      Count number of distinct elements in specified axis.\n",
      " |      \n",
      " |      Return Series with number of distinct elements. Can ignore NaN\n",
      " |      values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\n",
      " |          column-wise.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the counts.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nunique: Method nunique for Series.\n",
      " |      DataFrame.count: Count non-NA cells for each column or row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\n",
      " |      >>> df.nunique()\n",
      " |      A    3\n",
      " |      B    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.nunique(axis=1)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pivot(self, index=None, columns=None, values=None) -> 'DataFrame'\n",
      " |      Return reshaped DataFrame organized by given index / column values.\n",
      " |      \n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from specified `index` / `columns` to form axes of the\n",
      " |      resulting DataFrame. This function does not support data\n",
      " |      aggregation, multiple values will result in a MultiIndex in the\n",
      " |      columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : str or object or a list of str, optional\n",
      " |          Column to use to make new frame's index. If None, uses\n",
      " |          existing index.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of index names.\n",
      " |      \n",
      " |      columns : str or object or a list of str\n",
      " |          Column to use to make new frame's columns.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |             Also accept list of columns names.\n",
      " |      \n",
      " |      values : str, object or a list of the previous, optional\n",
      " |          Column(s) to use for populating new frame's values. If not\n",
      " |          specified, all remaining columns will be used and the result will\n",
      " |          have hierarchically indexed columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Returns reshaped DataFrame.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError:\n",
      " |          When there are any `index`, `columns` combinations with multiple\n",
      " |          values. `DataFrame.pivot_table` when you need to aggregate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot_table : Generalization of pivot that can handle\n",
      " |          duplicate values for one index/column pair.\n",
      " |      DataFrame.unstack : Pivot based on the index values instead of a\n",
      " |          column.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n",
      " |      ...                            'two'],\n",
      " |      ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
      " |      ...                    'baz': [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\n",
      " |      >>> df\n",
      " |          foo   bar  baz  zoo\n",
      " |      0   one   A    1    x\n",
      " |      1   one   B    2    y\n",
      " |      2   one   C    3    z\n",
      " |      3   two   A    4    q\n",
      " |      4   two   B    5    w\n",
      " |      5   two   C    6    t\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar')['baz']\n",
      " |      bar  A   B   C\n",
      " |      foo\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\n",
      " |            baz       zoo\n",
      " |      bar   A  B  C   A  B  C\n",
      " |      foo\n",
      " |      one   1  2  3   x  y  z\n",
      " |      two   4  5  6   q  w  t\n",
      " |      \n",
      " |      You could also assign a list of column names or a list of index names.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...        \"lev1\": [1, 1, 1, 2, 2, 2],\n",
      " |      ...        \"lev2\": [1, 1, 2, 1, 1, 2],\n",
      " |      ...        \"lev3\": [1, 2, 1, 2, 1, 2],\n",
      " |      ...        \"lev4\": [1, 2, 3, 4, 5, 6],\n",
      " |      ...        \"values\": [0, 1, 2, 3, 4, 5]})\n",
      " |      >>> df\n",
      " |          lev1 lev2 lev3 lev4 values\n",
      " |      0   1    1    1    1    0\n",
      " |      1   1    1    2    2    1\n",
      " |      2   1    2    1    3    2\n",
      " |      3   2    1    2    4    3\n",
      " |      4   2    1    1    5    4\n",
      " |      5   2    2    2    6    5\n",
      " |      \n",
      " |      >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"],values=\"values\")\n",
      " |      lev2    1         2\n",
      " |      lev3    1    2    1    2\n",
      " |      lev1\n",
      " |      1     0.0  1.0  2.0  NaN\n",
      " |      2     4.0  3.0  NaN  5.0\n",
      " |      \n",
      " |      >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n",
      " |            lev3    1    2\n",
      " |      lev1  lev2\n",
      " |         1     1  0.0  1.0\n",
      " |               2  2.0  NaN\n",
      " |         2     1  4.0  3.0\n",
      " |               2  NaN  5.0\n",
      " |      \n",
      " |      A ValueError is raised if there are any duplicates.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\n",
      " |      ...                    \"bar\": ['A', 'A', 'B', 'C'],\n",
      " |      ...                    \"baz\": [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         foo bar  baz\n",
      " |      0  one   A    1\n",
      " |      1  one   A    2\n",
      " |      2  two   B    3\n",
      " |      3  two   C    4\n",
      " |      \n",
      " |      Notice that the first two rows are the same for our `index`\n",
      " |      and `columns` arguments.\n",
      " |      \n",
      " |      >>> df.pivot(index='foo', columns='bar', values='baz')\n",
      " |      Traceback (most recent call last):\n",
      " |         ...\n",
      " |      ValueError: Index contains duplicate entries, cannot reshape\n",
      " |  \n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame.\n",
      " |      \n",
      " |      The levels in the pivot table will be stored in MultiIndex objects\n",
      " |      (hierarchical indexes) on the index and columns of the result DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : column to aggregate, optional\n",
      " |      index : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table index.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      columns : column, Grouper, array, or list of the previous\n",
      " |          If an array is passed, it must be the same length as the data. The\n",
      " |          list can contain any of the other types (except list).\n",
      " |          Keys to group by on the pivot table column.  If an array is passed,\n",
      " |          it is being used as the same manner as column values.\n",
      " |      aggfunc : function, list of functions, dict, default numpy.mean\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names\n",
      " |          (inferred from the function objects themselves)\n",
      " |          If dict is passed, the key is column to aggregate and value\n",
      " |          is function or list of functions.\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with (in the resulting pivot table,\n",
      " |          after aggregation).\n",
      " |      margins : bool, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals).\n",
      " |      dropna : bool, default True\n",
      " |          Do not include columns whose entries are all NaN.\n",
      " |      margins_name : str, default 'All'\n",
      " |          Name of the row / column that will contain the totals\n",
      " |          when margins is True.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      sort : bool, default True\n",
      " |          Specifies if the result should be sorted.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          An Excel style pivot table.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot without aggregation that can handle\n",
      " |          non-numeric data.\n",
      " |      DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      " |          optionally leaving identifiers set.\n",
      " |      wide_to_long : Wide panel to long format. Less flexible but more\n",
      " |          user-friendly than melt.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      " |      ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      " |      ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      " |      ...                          \"one\", \"one\", \"two\", \"two\"],\n",
      " |      ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      " |      ...                          \"small\", \"large\", \"small\", \"small\",\n",
      " |      ...                          \"large\"],\n",
      " |      ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      " |      ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      " |      >>> df\n",
      " |           A    B      C  D  E\n",
      " |      0  foo  one  small  1  2\n",
      " |      1  foo  one  large  2  4\n",
      " |      2  foo  one  large  2  5\n",
      " |      3  foo  two  small  3  5\n",
      " |      4  foo  two  small  3  6\n",
      " |      5  bar  one  large  4  6\n",
      " |      6  bar  one  small  5  8\n",
      " |      7  bar  two  small  6  9\n",
      " |      8  bar  two  large  7  9\n",
      " |      \n",
      " |      This first example aggregates values by taking the sum.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one    4.0    5.0\n",
      " |          two    7.0    6.0\n",
      " |      foo one    4.0    1.0\n",
      " |          two    NaN    6.0\n",
      " |      \n",
      " |      We can also fill missing values using the `fill_value` parameter.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      " |      >>> table\n",
      " |      C        large  small\n",
      " |      A   B\n",
      " |      bar one      4      5\n",
      " |          two      7      6\n",
      " |      foo one      4      1\n",
      " |          two      0      6\n",
      " |      \n",
      " |      The next example aggregates by taking the mean across multiple columns.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': np.mean})\n",
      " |      >>> table\n",
      " |                      D         E\n",
      " |      A   C\n",
      " |      bar large  5.500000  7.500000\n",
      " |          small  5.500000  8.500000\n",
      " |      foo large  2.000000  4.500000\n",
      " |          small  2.333333  4.333333\n",
      " |      \n",
      " |      We can also calculate multiple types of aggregations for any given\n",
      " |      value column.\n",
      " |      \n",
      " |      >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      " |      ...                     aggfunc={'D': np.mean,\n",
      " |      ...                              'E': [min, max, np.mean]})\n",
      " |      >>> table\n",
      " |                      D    E\n",
      " |                  mean  max      mean  min\n",
      " |      A   C\n",
      " |      bar large  5.500000  9.0  7.500000  6.0\n",
      " |          small  5.500000  9.0  8.500000  8.0\n",
      " |      foo large  2.000000  5.0  4.500000  4.0\n",
      " |          small  2.333333  6.0  4.333333  2.0\n",
      " |  \n",
      " |  pop(self, item: 'Hashable') -> 'Series'\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : label\n",
      " |          Label of column to be popped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rpow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, axis: 'Axis' = 0, numeric_only: 'bool' = True, interpolation: 'str' = 'linear')\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0, 1, 'index', 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default True\n",
      " |          If False, the quantile of datetime and timedelta data will be\n",
      " |          computed as well.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |      \n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |  \n",
      " |  query(self, expr: 'str', inplace: 'bool' = False, **kwargs)\n",
      " |      Query the columns of a DataFrame with a boolean expression.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : str\n",
      " |          The query string to evaluate.\n",
      " |      \n",
      " |          You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      \n",
      " |          You can refer to column names that are not valid Python variable names\n",
      " |          by surrounding them in backticks. Thus, column names containing spaces\n",
      " |          or punctuations (besides underscores) or starting with digits must be\n",
      " |          surrounded by backticks. (For example, a column named \"Area (cm^2)\" would\n",
      " |          be referenced as ```Area (cm^2)```). Column names which are Python keywords\n",
      " |          (like \"list\", \"for\", \"import\", etc) cannot be used.\n",
      " |      \n",
      " |          For example, if one of your columns is called ``a a`` and you want\n",
      " |          to sum it with ``b``, your query should be ```a a` + b``.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Backtick quoting introduced.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |              Expanding functionality of backtick quoting for more than only spaces.\n",
      " |      \n",
      " |      inplace : bool\n",
      " |          Whether the query should modify the data in place or return\n",
      " |          a modified copy.\n",
      " |      **kwargs\n",
      " |          See the documentation for :func:`eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame resulting from the provided query expression or\n",
      " |          None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      DataFrame.eval : Evaluate a string describing operations on\n",
      " |          DataFrame columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query. Please note that\n",
      " |      Python keywords may not be used as identifiers.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      *Backtick quoted variables*\n",
      " |      \n",
      " |      Backtick quoted variables are parsed as literal Python code and\n",
      " |      are converted internally to a Python valid identifier.\n",
      " |      This can lead to the following problems.\n",
      " |      \n",
      " |      During parsing a number of disallowed characters inside the backtick\n",
      " |      quoted string are replaced by strings that are allowed as a Python identifier.\n",
      " |      These characters include all operators in Python, the space character, the\n",
      " |      question mark, the exclamation mark, the dollar sign, and the euro sign.\n",
      " |      For other characters that fall outside the ASCII range (U+0001..U+007F)\n",
      " |      and those that are not further specified in PEP 3131,\n",
      " |      the query parser will raise an error.\n",
      " |      This excludes whitespace different than the space character,\n",
      " |      but also the hashtag (as it is used for comments) and the backtick\n",
      " |      itself (backtick can also not be escaped).\n",
      " |      \n",
      " |      In a special case, quotes that make a pair around a backtick can\n",
      " |      confuse the parser.\n",
      " |      For example, ```it's` > `that's``` will raise an error,\n",
      " |      as it forms a quoted string (``'s > `that'``) with a backtick inside.\n",
      " |      \n",
      " |      See also the Python documentation about lexical analysis\n",
      " |      (https://docs.python.org/3/reference/lexical_analysis.html)\n",
      " |      in combination with the source code in :mod:`pandas.core.computation.parsing`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(1, 6),\n",
      " |      ...                    'B': range(10, 0, -2),\n",
      " |      ...                    'C C': range(10, 5, -1)})\n",
      " |      >>> df\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      1  2   8    9\n",
      " |      2  3   6    8\n",
      " |      3  4   4    7\n",
      " |      4  5   2    6\n",
      " |      >>> df.query('A > B')\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.A > df.B]\n",
      " |         A  B  C C\n",
      " |      4  5  2    6\n",
      " |      \n",
      " |      For columns with spaces in their name, you can use backtick quoting.\n",
      " |      \n",
      " |      >>> df.query('B == `C C`')\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |      \n",
      " |      The previous expression is equivalent to\n",
      " |      \n",
      " |      >>> df[df.B == df['C C']]\n",
      " |         A   B  C C\n",
      " |      0  1  10   10\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Addition of dataframe and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `add`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n",
      " |      Conform Series/DataFrame to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      keywords for axes : array-like, optional\n",
      " |          New labels / index to conform to, should be specified using\n",
      " |          keywords. Preferably an Index object to avoid duplicating data.\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='ignore')\n",
      " |      Alter axes labels.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function\n",
      " |          Dict-like or function transformations to apply to\n",
      " |          that axis' values. Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index`` and\n",
      " |          ``columns``.\n",
      " |      index : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=0``\n",
      " |          is equivalent to ``index=mapper``).\n",
      " |      columns : dict-like or function\n",
      " |          Alternative to specifying axis (``mapper, axis=1``\n",
      " |          is equivalent to ``columns=mapper``).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to target with ``mapper``. Can be either the axis name\n",
      " |          ('index', 'columns') or number (0, 1). The default is 'index'.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame. If True then value of copy is\n",
      " |          ignored.\n",
      " |      level : int or level name, default None\n",
      " |          In case of a MultiIndex, only rename labels in the specified\n",
      " |          level.\n",
      " |      errors : {'ignore', 'raise'}, default 'ignore'\n",
      " |          If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\n",
      " |          or `columns` contains labels that are not present in the Index\n",
      " |          being transformed.\n",
      " |          If 'ignore', existing keys will be renamed and extra keys will be\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the renamed axis labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any of the labels is not found in the selected axis and\n",
      " |          \"errors='raise'\".\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.rename`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Rename columns using a mapping:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
      " |         a  c\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      Rename index using a mapping:\n",
      " |      \n",
      " |      >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
      " |         A  B\n",
      " |      x  1  4\n",
      " |      y  2  5\n",
      " |      z  3  6\n",
      " |      \n",
      " |      Cast index labels to a different type:\n",
      " |      \n",
      " |      >>> df.index\n",
      " |      RangeIndex(start=0, stop=3, step=1)\n",
      " |      >>> df.rename(index=str).index\n",
      " |      Index(['0', '1', '2'], dtype='object')\n",
      " |      \n",
      " |      >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: ['C'] not found in axis\n",
      " |      \n",
      " |      Using axis-style parameters:\n",
      " |      \n",
      " |      >>> df.rename(str.lower, axis='columns')\n",
      " |         a  b\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      >>> df.rename({1: 2, 2: 4}, axis='index')\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      2  2  5\n",
      " |      4  3  6\n",
      " |  \n",
      " |  reorder_levels(self, order: 'Sequence[Axis]', axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Rearrange index levels using input order. May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace: 'bool' = False, limit=None, regex: 'bool' = False, method: 'str' = 'pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the DataFrame are replaced with other values dynamically.\n",
      " |      \n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                  replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                  with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                  `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                  **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                  lists will be interpreted as regexs otherwise they will match\n",
      " |                  directly. This doesn't matter much for `value` since there\n",
      " |                  are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                  for different existing values. For example,\n",
      " |                  ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                  'y' with 'z'. To use a dict in this way the `value`\n",
      " |                  parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                  should be replaced in different columns. For example,\n",
      " |                  ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                  and the value 'z' in column 'b' and replaces these values\n",
      " |                  with whatever is specified in `value`. The `value` parameter\n",
      " |                  should not be ``None`` in this case. You can treat this as a\n",
      " |                  special case of passing two lists except that you are\n",
      " |                  specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                  ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                  'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                  parameter should be ``None`` to use a nested dict in this\n",
      " |                  way. You can nest regular expressions as well. Note that\n",
      " |                  column names (the top-level dictionary keys in a nested\n",
      " |                  dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                  compiled regular expression, or list, dict, ndarray or\n",
      " |                  Series of such elements. If `value` is also ``None`` then\n",
      " |                  this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          If True, performs operation inplace and returns None.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |              ``None``.\n",
      " |      \n",
      " |      TypeError\n",
      " |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |              ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |              into a regular expression or is a list, dict, ndarray, or\n",
      " |              Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |              the arguments to `to_replace` does not match the type of the\n",
      " |              value being replaced\n",
      " |      \n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |              `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NA values.\n",
      " |      DataFrame.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |          rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |          cannot provide, for example, a regular expression matching floating\n",
      " |          point numbers and expect the columns in your frame that have a\n",
      " |          numeric dtype to be matched. However, if those floating point\n",
      " |          numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |          and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |          key(s) in the dict are the to_replace part and\n",
      " |          value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |          A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |          A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |              A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |              A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |              A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |              A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  resample(self, rule, axis=0, closed: 'str | None' = None, label: 'str | None' = None, convention: 'str' = 'start', kind: 'str | None' = None, loffset=None, base: 'int | None' = None, on=None, level=None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'TimedeltaConvertibleTypes | None' = None) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time series.\n",
      " |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,\n",
      " |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like\n",
      " |      series/index to the ``on``/``level`` keyword parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this\n",
      " |          will default to 0, i.e. along the rows. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta, default None\n",
      " |          Adjust the resampled time labels.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              You should add the loffset to the `df.index` after the resample.\n",
      " |              See below.\n",
      " |      \n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0.\n",
      " |      \n",
      " |          .. deprecated:: 1.1.0\n",
      " |              The new arguments that you should use are 'offset' or 'origin'.\n",
      " |      \n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      origin : {'epoch', 'start', 'start_day', 'end', 'end_day'}, Timestamp\n",
      " |          or str, default 'start_day'\n",
      " |          The timestamp on which to adjust the grouping. The timezone of origin\n",
      " |          must match the timezone of the index.\n",
      " |          If a timestamp is not used, these values are also supported:\n",
      " |      \n",
      " |          - 'epoch': `origin` is 1970-01-01\n",
      " |          - 'start': `origin` is the first value of the timeseries\n",
      " |          - 'start_day': `origin` is the first day at midnight of the timeseries\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          - 'end': `origin` is the last value of the timeseries\n",
      " |          - 'end_day': `origin` is the ceiling midnight of the last day\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      offset : Timedelta or str, default is None\n",
      " |          An offset timedelta added to the origin.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.core.Resampler\n",
      " |          :class:`~pandas.core.Resampler` object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample : Resample a DataFrame.\n",
      " |      groupby : Group DataFrame by mapping, function, label, or list of labels.\n",
      " |      asfreq : Reindex a DataFrame with the given frequency without grouping.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`__\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(arraylike):\n",
      " |      ...     return np.sum(arraylike) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...      'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...       'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
      " |      >>> df2 = pd.DataFrame(\n",
      " |      ...     d2,\n",
      " |      ...     index=pd.MultiIndex.from_product(\n",
      " |      ...         [days, ['morning', 'afternoon']]\n",
      " |      ...     )\n",
      " |      ... )\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |      \n",
      " |      If you want to adjust the start of the bins based on a fixed timestamp:\n",
      " |      \n",
      " |      >>> start, end = '2000-10-01 23:30:00', '2000-10-02 00:30:00'\n",
      " |      >>> rng = pd.date_range(start, end, freq='7min')\n",
      " |      >>> ts = pd.Series(np.arange(len(rng)) * 3, index=rng)\n",
      " |      >>> ts\n",
      " |      2000-10-01 23:30:00     0\n",
      " |      2000-10-01 23:37:00     3\n",
      " |      2000-10-01 23:44:00     6\n",
      " |      2000-10-01 23:51:00     9\n",
      " |      2000-10-01 23:58:00    12\n",
      " |      2000-10-02 00:05:00    15\n",
      " |      2000-10-02 00:12:00    18\n",
      " |      2000-10-02 00:19:00    21\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 7T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min').sum()\n",
      " |      2000-10-01 23:14:00     0\n",
      " |      2000-10-01 23:31:00     9\n",
      " |      2000-10-01 23:48:00    21\n",
      " |      2000-10-02 00:05:00    54\n",
      " |      2000-10-02 00:22:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='epoch').sum()\n",
      " |      2000-10-01 23:18:00     0\n",
      " |      2000-10-01 23:35:00    18\n",
      " |      2000-10-01 23:52:00    27\n",
      " |      2000-10-02 00:09:00    39\n",
      " |      2000-10-02 00:26:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='2000-01-01').sum()\n",
      " |      2000-10-01 23:24:00     3\n",
      " |      2000-10-01 23:41:00    15\n",
      " |      2000-10-01 23:58:00    45\n",
      " |      2000-10-02 00:15:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to adjust the start of the bins with an `offset` Timedelta, the two\n",
      " |      following lines are equivalent:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='start').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='23h30min').sum()\n",
      " |      2000-10-01 23:30:00     9\n",
      " |      2000-10-01 23:47:00    21\n",
      " |      2000-10-02 00:04:00    54\n",
      " |      2000-10-02 00:21:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      If you want to take the largest Timestamp as the end of the bins:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end').sum()\n",
      " |      2000-10-01 23:35:00     0\n",
      " |      2000-10-01 23:52:00    18\n",
      " |      2000-10-02 00:09:00    27\n",
      " |      2000-10-02 00:26:00    63\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      In contrast with the `start_day`, you can use `end_day` to take the ceiling\n",
      " |      midnight of the largest Timestamp as the end of the bins and drop the bins\n",
      " |      not containing data:\n",
      " |      \n",
      " |      >>> ts.resample('17min', origin='end_day').sum()\n",
      " |      2000-10-01 23:38:00     3\n",
      " |      2000-10-01 23:55:00    15\n",
      " |      2000-10-02 00:12:00    45\n",
      " |      2000-10-02 00:29:00    45\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `base` argument, you can now use `offset`,\n",
      " |      in this example it is equivalent to have `base=2`:\n",
      " |      \n",
      " |      >>> ts.resample('17min', offset='2min').sum()\n",
      " |      2000-10-01 23:16:00     0\n",
      " |      2000-10-01 23:33:00     9\n",
      " |      2000-10-01 23:50:00    36\n",
      " |      2000-10-02 00:07:00    39\n",
      " |      2000-10-02 00:24:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |      \n",
      " |      To replace the use of the deprecated `loffset` argument:\n",
      " |      \n",
      " |      >>> from pandas.tseries.frequencies import to_offset\n",
      " |      >>> loffset = '19min'\n",
      " |      >>> ts_out = ts.resample('17min').sum()\n",
      " |      >>> ts_out.index = ts_out.index + to_offset(loffset)\n",
      " |      >>> ts_out\n",
      " |      2000-10-01 23:33:00     0\n",
      " |      2000-10-01 23:50:00     9\n",
      " |      2000-10-02 00:07:00    21\n",
      " |      2000-10-02 00:24:00    54\n",
      " |      2000-10-02 00:41:00    24\n",
      " |      Freq: 17T, dtype: int64\n",
      " |  \n",
      " |  reset_index(self, level: 'Hashable | Sequence[Hashable] | None' = None, drop: 'bool' = False, inplace: 'bool' = False, col_level: 'Hashable' = 0, col_fill: 'Hashable' = '') -> 'DataFrame | None'\n",
      " |      Reset the index, or a level of it.\n",
      " |      \n",
      " |      Reset the index of the DataFrame, and use the default one instead.\n",
      " |      If the DataFrame has a MultiIndex, this method can remove one or more\n",
      " |      levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default.\n",
      " |      drop : bool, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the DataFrame in place (do not create a new object).\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with the new index or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Opposite of reset_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('bird', 389.0),\n",
      " |      ...                    ('bird', 24.0),\n",
      " |      ...                    ('mammal', 80.5),\n",
      " |      ...                    ('mammal', np.nan)],\n",
      " |      ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\n",
      " |      ...                   columns=('class', 'max_speed'))\n",
      " |      >>> df\n",
      " |               class  max_speed\n",
      " |      falcon    bird      389.0\n",
      " |      parrot    bird       24.0\n",
      " |      lion    mammal       80.5\n",
      " |      monkey  mammal        NaN\n",
      " |      \n",
      " |      When we reset the index, the old index is added as a column, and a\n",
      " |      new sequential index is used:\n",
      " |      \n",
      " |      >>> df.reset_index()\n",
      " |          index   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      We can use the `drop` parameter to avoid the old index being added as\n",
      " |      a column:\n",
      " |      \n",
      " |      >>> df.reset_index(drop=True)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      1    bird       24.0\n",
      " |      2  mammal       80.5\n",
      " |      3  mammal        NaN\n",
      " |      \n",
      " |      You can also use `reset_index` with `MultiIndex`.\n",
      " |      \n",
      " |      >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\n",
      " |      ...                                    ('bird', 'parrot'),\n",
      " |      ...                                    ('mammal', 'lion'),\n",
      " |      ...                                    ('mammal', 'monkey')],\n",
      " |      ...                                   names=['class', 'name'])\n",
      " |      >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\n",
      " |      ...                                      ('species', 'type')])\n",
      " |      >>> df = pd.DataFrame([(389.0, 'fly'),\n",
      " |      ...                    ( 24.0, 'fly'),\n",
      " |      ...                    ( 80.5, 'run'),\n",
      " |      ...                    (np.nan, 'jump')],\n",
      " |      ...                   index=index,\n",
      " |      ...                   columns=columns)\n",
      " |      >>> df\n",
      " |                     speed species\n",
      " |                       max    type\n",
      " |      class  name\n",
      " |      bird   falcon  389.0     fly\n",
      " |             parrot   24.0     fly\n",
      " |      mammal lion     80.5     run\n",
      " |             monkey    NaN    jump\n",
      " |      \n",
      " |      If the index has multiple levels, we can reset a subset of them:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class')\n",
      " |               class  speed species\n",
      " |                        max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      If we are not dropping the index, by default, it is placed in the top\n",
      " |      level. We can place it in another level:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1)\n",
      " |                      speed species\n",
      " |               class    max    type\n",
      " |      name\n",
      " |      falcon    bird  389.0     fly\n",
      " |      parrot    bird   24.0     fly\n",
      " |      lion    mammal   80.5     run\n",
      " |      monkey  mammal    NaN    jump\n",
      " |      \n",
      " |      When the index is inserted under another level, we can specify under\n",
      " |      which one with the parameter `col_fill`:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='species')\n",
      " |                    species  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |      \n",
      " |      If we specify a nonexistent level for `col_fill`, it is created:\n",
      " |      \n",
      " |      >>> df.reset_index(level='class', col_level=1, col_fill='genus')\n",
      " |                      genus  speed species\n",
      " |                      class    max    type\n",
      " |      name\n",
      " |      falcon           bird  389.0     fly\n",
      " |      parrot           bird   24.0     fly\n",
      " |      lion           mammal   80.5     run\n",
      " |      monkey         mammal    NaN    jump\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `floordiv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mod`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `mul`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  round(self, decimals: 'int | dict[IndexLabel, int] | Series' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Round a DataFrame to a variable number of decimal places.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, dict, Series\n",
      " |          Number of decimal places to round each column to. If an int is\n",
      " |          given, round each column to the same number of places.\n",
      " |          Otherwise dict and Series round to variable numbers of places.\n",
      " |          Column names should be in the keys if `decimals` is a\n",
      " |          dict-like, or in the index if `decimals` is a Series. Any\n",
      " |          columns not included in `decimals` will be left as is. Elements\n",
      " |          of `decimals` which are not columns of the input will be\n",
      " |          ignored.\n",
      " |      *args\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame with the affected columns rounded to the specified\n",
      " |          number of decimal places.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round a numpy array to the given number of decimals.\n",
      " |      Series.round : Round a Series to the given number of decimals.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\n",
      " |      ...                   columns=['dogs', 'cats'])\n",
      " |      >>> df\n",
      " |          dogs  cats\n",
      " |      0  0.21  0.32\n",
      " |      1  0.01  0.67\n",
      " |      2  0.66  0.03\n",
      " |      3  0.21  0.18\n",
      " |      \n",
      " |      By providing an integer each column is rounded to the same number\n",
      " |      of decimal places\n",
      " |      \n",
      " |      >>> df.round(1)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.3\n",
      " |      1   0.0   0.7\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.2\n",
      " |      \n",
      " |      With a dict, the number of places for specific columns can be\n",
      " |      specified with the column names as key and the number of decimal\n",
      " |      places as value\n",
      " |      \n",
      " |      >>> df.round({'dogs': 1, 'cats': 0})\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |      \n",
      " |      Using a Series, the number of places for specific columns can be\n",
      " |      specified with the column names as index and the number of\n",
      " |      decimal places as value\n",
      " |      \n",
      " |      >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\n",
      " |      >>> df.round(decimals)\n",
      " |          dogs  cats\n",
      " |      0   0.2   0.0\n",
      " |      1   0.0   1.0\n",
      " |      2   0.7   0.0\n",
      " |      3   0.2   0.0\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `pow`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `sub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `truediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'DataFrame'\n",
      " |      Return a subset of the DataFrame's columns based on the column dtypes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : scalar or list-like\n",
      " |          A selection of dtypes or strings to be included/excluded. At least\n",
      " |          one of these parameters must be supplied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dtypes: Return Series with the data type of each column.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      " |      * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      " |        ``'datetime64'``\n",
      " |      * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      " |        ``'timedelta64'``\n",
      " |      * To select Pandas categorical dtypes, use ``'category'``\n",
      " |      * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
      " |        0.20.0) or ``'datetime64[ns, tz]'``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0       1   True  1.0\n",
      " |      1       2  False  2.0\n",
      " |      2       1   True  1.0\n",
      " |      3       2  False  2.0\n",
      " |      4       1   True  1.0\n",
      " |      5       2  False  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(include='bool')\n",
      " |         b\n",
      " |      0  True\n",
      " |      1  False\n",
      " |      2  True\n",
      " |      3  False\n",
      " |      4  True\n",
      " |      5  False\n",
      " |      \n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1.0\n",
      " |      1  2.0\n",
      " |      2  1.0\n",
      " |      3  2.0\n",
      " |      4  1.0\n",
      " |      5  2.0\n",
      " |      \n",
      " |      >>> df.select_dtypes(exclude=['int64'])\n",
      " |             b    c\n",
      " |      0   True  1.0\n",
      " |      1  False  2.0\n",
      " |      2   True  1.0\n",
      " |      3  False  2.0\n",
      " |      4   True  1.0\n",
      " |      5  False  2.0\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |  \n",
      " |  set_axis(self, labels, axis: 'Axis' = 0, inplace: 'bool' = False)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1 identifies the columns.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new DataFrame instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame or None\n",
      " |          An object of type DataFrame or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |              Change the row labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |                 A  B\n",
      " |              a  1  4\n",
      " |              b  2  5\n",
      " |              c  3  6\n",
      " |      \n",
      " |              Change the column labels.\n",
      " |      \n",
      " |              >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |                 I  II\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |      \n",
      " |              Now, update the labels inplace.\n",
      " |      \n",
      " |              >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |              >>> df\n",
      " |                 i  ii\n",
      " |              0  1   4\n",
      " |              1  2   5\n",
      " |              2  3   6\n",
      " |  \n",
      " |  set_index(self, keys, drop: 'bool' = True, append: 'bool' = False, inplace: 'bool' = False, verify_integrity: 'bool' = False)\n",
      " |      Set the DataFrame index using existing columns.\n",
      " |      \n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns or arrays (of the correct length). The index can replace the\n",
      " |      existing index or expand on it.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : label or array-like or list of labels/arrays\n",
      " |          This parameter can be either a single column key, a single array of\n",
      " |          the same length as the calling DataFrame, or a list containing an\n",
      " |          arbitrary combination of column keys and arrays. Here, \"array\"\n",
      " |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\n",
      " |          instances of :class:`~collections.abc.Iterator`.\n",
      " |      drop : bool, default True\n",
      " |          Delete columns to be used as the new index.\n",
      " |      append : bool, default False\n",
      " |          Whether to append columns to existing index.\n",
      " |      inplace : bool, default False\n",
      " |          If True, modifies the DataFrame in place (do not create a new object).\n",
      " |      verify_integrity : bool, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          Changed row labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index : Opposite of set_index.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
      " |      ...                    'year': [2012, 2014, 2013, 2014],\n",
      " |      ...                    'sale': [55, 40, 84, 31]})\n",
      " |      >>> df\n",
      " |         month  year  sale\n",
      " |      0      1  2012    55\n",
      " |      1      4  2014    40\n",
      " |      2      7  2013    84\n",
      " |      3     10  2014    31\n",
      " |      \n",
      " |      Set the index to become the 'month' column:\n",
      " |      \n",
      " |      >>> df.set_index('month')\n",
      " |             year  sale\n",
      " |      month\n",
      " |      1      2012    55\n",
      " |      4      2014    40\n",
      " |      7      2013    84\n",
      " |      10     2014    31\n",
      " |      \n",
      " |      Create a MultiIndex using columns 'year' and 'month':\n",
      " |      \n",
      " |      >>> df.set_index(['year', 'month'])\n",
      " |                  sale\n",
      " |      year  month\n",
      " |      2012  1     55\n",
      " |      2014  4     40\n",
      " |      2013  7     84\n",
      " |      2014  10    31\n",
      " |      \n",
      " |      Create a MultiIndex using an Index and a column:\n",
      " |      \n",
      " |      >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
      " |               month  sale\n",
      " |         year\n",
      " |      1  2012  1      55\n",
      " |      2  2014  4      40\n",
      " |      3  2013  7      84\n",
      " |      4  2014  10     31\n",
      " |      \n",
      " |      Create a MultiIndex using two Series:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> df.set_index([s, s**2])\n",
      " |            month  year  sale\n",
      " |      1 1       1  2012    55\n",
      " |      2 4       4  2014    40\n",
      " |      3 9       7  2013    84\n",
      " |      4 16     10  2014    31\n",
      " |  \n",
      " |  shift(self, periods=1, freq: 'Frequency | None' = None, axis: 'Axis' = 0, fill_value=<no_default>) -> 'DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`. `freq` can be inferred\n",
      " |      when specified as \"infer\" as long as either freq or inferred_freq\n",
      " |      attribute is set in the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |          If `freq` is specified as \"infer\" then it will be inferred from\n",
      " |          the freq or inferred_freq attributes of the index. If neither of\n",
      " |          those attributes exist, a ValueError is thrown.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      tshift : Shift the time index, using the index's frequency if\n",
      " |          available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
      " |      ...                    \"Col2\": [13, 23, 18, 33, 48],\n",
      " |      ...                    \"Col3\": [17, 27, 22, 37, 52]},\n",
      " |      ...                   index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
      " |      >>> df\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01    10    13    17\n",
      " |      2020-01-02    20    23    27\n",
      " |      2020-01-03    15    18    22\n",
      " |      2020-01-04    30    33    37\n",
      " |      2020-01-05    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN   NaN   NaN\n",
      " |      2020-01-02   NaN   NaN   NaN\n",
      " |      2020-01-03   NaN   NaN   NaN\n",
      " |      2020-01-04  10.0  13.0  17.0\n",
      " |      2020-01-05  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis=\"columns\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01   NaN    10    13\n",
      " |      2020-01-02   NaN    20    23\n",
      " |      2020-01-03   NaN    15    18\n",
      " |      2020-01-04   NaN    30    33\n",
      " |      2020-01-05   NaN    45    48\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-01     0     0     0\n",
      " |      2020-01-02     0     0     0\n",
      " |      2020-01-03     0     0     0\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"D\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |      \n",
      " |      >>> df.shift(periods=3, freq=\"infer\")\n",
      " |                  Col1  Col2  Col3\n",
      " |      2020-01-04    10    13    17\n",
      " |      2020-01-05    20    23    27\n",
      " |      2020-01-06    15    18    22\n",
      " |      2020-01-07    30    33    37\n",
      " |      2020-01-08    45    48    52\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis: 'Axis' = 0, level: 'Level | None' = None, ascending: 'bool | int | Sequence[bool | int]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', sort_remaining: 'bool' = True, ignore_index: 'bool' = False, key: 'IndexKeyFunc' = None)\n",
      " |      Sort object by labels (along an axis).\n",
      " |      \n",
      " |      Returns a new DataFrame sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original DataFrame and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis along which to sort.  The value 0 identifies the rows,\n",
      " |          and 1 identifies the columns.\n",
      " |      level : int or level name or list of ints or list of level names\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool or list-like of bools, default True\n",
      " |          Sort ascending vs. descending. When the index is a MultiIndex the\n",
      " |          sort direction can be controlled for each level individually.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex\n",
      " |          inputs, the key is applied *per level*.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          The original DataFrame sorted by the labels or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort Series by the index.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df.sort_index()\n",
      " |           A\n",
      " |      1    4\n",
      " |      29   2\n",
      " |      100  1\n",
      " |      150  5\n",
      " |      234  3\n",
      " |      \n",
      " |      By default, it sorts in ascending order, to sort in descending order,\n",
      " |      use ``ascending=False``\n",
      " |      \n",
      " |      >>> df.sort_index(ascending=False)\n",
      " |           A\n",
      " |      234  3\n",
      " |      150  5\n",
      " |      100  1\n",
      " |      29   2\n",
      " |      1    4\n",
      " |      \n",
      " |      A key function can be specified which is applied to the index before\n",
      " |      sorting. For a ``MultiIndex`` this is applied to each level separately.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\n",
      " |      >>> df.sort_index(key=lambda x: x.str.lower())\n",
      " |         a\n",
      " |      A  1\n",
      " |      b  2\n",
      " |      C  3\n",
      " |      d  4\n",
      " |  \n",
      " |  sort_values(self, by, axis: 'Axis' = 0, ascending=True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None)\n",
      " |      Sort by the values along either axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |              by : str or list of str\n",
      " |                  Name or list of names to sort by.\n",
      " |      \n",
      " |                  - if `axis` is 0 or `'index'` then `by` may contain index\n",
      " |                    levels and/or column labels.\n",
      " |                  - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      " |                    levels and/or index labels.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |           Axis to be sorted.\n",
      " |      ascending : bool or list of bool, default True\n",
      " |           Sort ascending vs. descending. Specify list for multiple sort\n",
      " |           orders.  If this is a list of bools, must match the length of\n",
      " |           the by.\n",
      " |      inplace : bool, default False\n",
      " |           If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      " |           Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |           information. `mergesort` and `stable` are the only stable algorithms. For\n",
      " |           DataFrames, this option is only applied when sorting on a single\n",
      " |           column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      " |           end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |           .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      key : callable, optional\n",
      " |          Apply the key function to the values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect a\n",
      " |          ``Series`` and return a Series with the same shape as the input.\n",
      " |          It will be applied to each column in `by` independently.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or None\n",
      " |          DataFrame with sorted values or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index : Sort a DataFrame by the index.\n",
      " |      Series.sort_values : Similar method for a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      " |      ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      " |      ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      " |      ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Sort by col1\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1'])\n",
      " |        col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort by multiple columns\n",
      " |      \n",
      " |      >>> df.sort_values(by=['col1', 'col2'])\n",
      " |        col1  col2  col3 col4\n",
      " |      1    A     1     1    B\n",
      " |      0    A     2     0    a\n",
      " |      2    B     9     9    c\n",
      " |      5    C     4     3    F\n",
      " |      4    D     7     2    e\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False)\n",
      " |        col1  col2  col3 col4\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      3  NaN     8     4    D\n",
      " |      \n",
      " |      Putting NAs first\n",
      " |      \n",
      " |      >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      " |        col1  col2  col3 col4\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      2    B     9     9    c\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      \n",
      " |      Sorting with a key function\n",
      " |      \n",
      " |      >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      " |         col1  col2  col3 col4\n",
      " |      0    A     2     0    a\n",
      " |      1    A     1     1    B\n",
      " |      2    B     9     9    c\n",
      " |      3  NaN     8     4    D\n",
      " |      4    D     7     2    e\n",
      " |      5    C     4     3    F\n",
      " |      \n",
      " |      Natural sort with the key argument,\n",
      " |      using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      " |      ...    \"value\": [10, 20, 30, 40, 50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      1  128hr     20\n",
      " |      2   72hr     30\n",
      " |      3   48hr     40\n",
      " |      4   96hr     50\n",
      " |      >>> from natsort import index_natsorted\n",
      " |      >>> df.sort_values(\n",
      " |      ...    by=\"time\",\n",
      " |      ...    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      " |      ... )\n",
      " |          time  value\n",
      " |      0    0hr     10\n",
      " |      3   48hr     40\n",
      " |      2   72hr     30\n",
      " |      4   96hr     50\n",
      " |      1  128hr     20\n",
      " |  \n",
      " |  stack(self, level: 'Level' = -1, dropna: 'bool' = True)\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |      \n",
      " |      Return a reshaped DataFrame or Series having a multi-level\n",
      " |      index with one or more new inner-most levels compared to the current\n",
      " |      DataFrame. The new inner-most levels are created by pivoting the\n",
      " |      columns of the current dataframe:\n",
      " |      \n",
      " |        - if the columns have a single level, the output is a Series;\n",
      " |        - if the columns have multiple levels, the new index\n",
      " |          level(s) is (are) taken from the prescribed level(s) and\n",
      " |          the output is a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, list, default -1\n",
      " |          Level(s) to stack from the column axis onto the index\n",
      " |          axis, defined as one index or label, or a list of indices\n",
      " |          or labels.\n",
      " |      dropna : bool, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with\n",
      " |          missing values. Stacking a column level onto the index\n",
      " |          axis can create combinations of index and column values\n",
      " |          that are missing from the original dataframe. See Examples\n",
      " |          section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Stacked dataframe or series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.unstack : Unstack prescribed level(s) from index axis\n",
      " |           onto column axis.\n",
      " |      DataFrame.pivot : Reshape dataframe from long format to wide\n",
      " |           format.\n",
      " |      DataFrame.pivot_table : Create a spreadsheet-style pivot table\n",
      " |           as a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The function is named by analogy with a collection of books\n",
      " |      being reorganized from being side by side on a horizontal\n",
      " |      position (the columns of the dataframe) to being stacked\n",
      " |      vertically on top of each other (in the index of the\n",
      " |      dataframe).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Single level columns**\n",
      " |      \n",
      " |      >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=['weight', 'height'])\n",
      " |      \n",
      " |      Stacking a dataframe with a single level column axis returns a Series:\n",
      " |      \n",
      " |      >>> df_single_level_cols\n",
      " |           weight height\n",
      " |      cat       0      1\n",
      " |      dog       2      3\n",
      " |      >>> df_single_level_cols.stack()\n",
      " |      cat  weight    0\n",
      " |           height    1\n",
      " |      dog  weight    2\n",
      " |           height    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Multi level columns: simple case**\n",
      " |      \n",
      " |      >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('weight', 'pounds')])\n",
      " |      >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol1)\n",
      " |      \n",
      " |      Stacking a dataframe with a multi-level column axis:\n",
      " |      \n",
      " |      >>> df_multi_level_cols1\n",
      " |           weight\n",
      " |               kg    pounds\n",
      " |      cat       1        2\n",
      " |      dog       2        4\n",
      " |      >>> df_multi_level_cols1.stack()\n",
      " |                  weight\n",
      " |      cat kg           1\n",
      " |          pounds       2\n",
      " |      dog kg           2\n",
      " |          pounds       4\n",
      " |      \n",
      " |      **Missing values**\n",
      " |      \n",
      " |      >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\n",
      " |      ...                                        ('height', 'm')])\n",
      " |      >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      It is common to have missing values when stacking a dataframe\n",
      " |      with multi-level columns, as the stacked dataframe typically\n",
      " |      has more values than the original dataframe. Missing values\n",
      " |      are filled with NaNs:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    1.0    2.0\n",
      " |      dog    3.0    4.0\n",
      " |      >>> df_multi_level_cols2.stack()\n",
      " |              height  weight\n",
      " |      cat kg     NaN     1.0\n",
      " |          m      2.0     NaN\n",
      " |      dog kg     NaN     3.0\n",
      " |          m      4.0     NaN\n",
      " |      \n",
      " |      **Prescribing the level(s) to be stacked**\n",
      " |      \n",
      " |      The first parameter controls which level or levels are stacked:\n",
      " |      \n",
      " |      >>> df_multi_level_cols2.stack(0)\n",
      " |                   kg    m\n",
      " |      cat height  NaN  2.0\n",
      " |          weight  1.0  NaN\n",
      " |      dog height  NaN  4.0\n",
      " |          weight  3.0  NaN\n",
      " |      >>> df_multi_level_cols2.stack([0, 1])\n",
      " |      cat  height  m     2.0\n",
      " |           weight  kg    1.0\n",
      " |      dog  height  m     4.0\n",
      " |           weight  kg    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **Dropping missing values**\n",
      " |      \n",
      " |      >>> df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],\n",
      " |      ...                                     index=['cat', 'dog'],\n",
      " |      ...                                     columns=multicol2)\n",
      " |      \n",
      " |      Note that rows where all values are missing are dropped by\n",
      " |      default but this behaviour can be controlled via the dropna\n",
      " |      keyword parameter:\n",
      " |      \n",
      " |      >>> df_multi_level_cols3\n",
      " |          weight height\n",
      " |              kg      m\n",
      " |      cat    NaN    1.0\n",
      " |      dog    2.0    3.0\n",
      " |      >>> df_multi_level_cols3.stack(dropna=False)\n",
      " |              height  weight\n",
      " |      cat kg     NaN     NaN\n",
      " |          m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |      >>> df_multi_level_cols3.stack(dropna=True)\n",
      " |              height  weight\n",
      " |      cat m      1.0     NaN\n",
      " |      dog kg     NaN     2.0\n",
      " |          m      3.0     NaN\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rsub`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |      \n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i: 'Axis' = -2, j: 'Axis' = -1, axis: 'Axis' = 0) -> 'DataFrame'\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |      \n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int or str\n",
      " |          Levels of the indices to be swapped. Can pass level name as string.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |                  The axis to swap levels on. 0 or 'index' for row-wise, 1 or\n",
      " |                  'columns' for column-wise.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with levels swapped in MultiIndex.\n",
      " |      \n",
      " |      Examples\n",
      " |              --------\n",
      " |              >>> df = pd.DataFrame(\n",
      " |              ...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\n",
      " |              ...     index=[\n",
      " |              ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\n",
      " |              ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\n",
      " |              ...         [\"January\", \"February\", \"March\", \"April\"],\n",
      " |              ...     ],\n",
      " |              ... )\n",
      " |              >>> df\n",
      " |                                                  Grade\n",
      " |              Final exam  History     January      A\n",
      " |                          Geography   February     B\n",
      " |              Coursework  History     March        A\n",
      " |                          Geography   April        C\n",
      " |      \n",
      " |              In the following example, we will swap the levels of the indices.\n",
      " |              Here, we will swap the levels column-wise, but levels can be swapped row-wise\n",
      " |              in a similar manner. Note that column-wise is the default behaviour.\n",
      " |              By not supplying any arguments for i and j, we swap the last and second to\n",
      " |              last indices.\n",
      " |      \n",
      " |              >>> df.swaplevel()\n",
      " |                                                  Grade\n",
      " |              Final exam  January     History         A\n",
      " |                          February    Geography       B\n",
      " |              Coursework  March       History         A\n",
      " |                          April       Geography       C\n",
      " |      \n",
      " |              By supplying one argument, we can choose which index to swap the last\n",
      " |              index with. We can for example swap the first index with the last one as\n",
      " |              follows.\n",
      " |      \n",
      " |              >>> df.swaplevel(0)\n",
      " |                                                  Grade\n",
      " |              January     History     Final exam      A\n",
      " |              February    Geography   Final exam      B\n",
      " |              March       History     Coursework      A\n",
      " |              April       Geography   Coursework      C\n",
      " |      \n",
      " |              We can also define explicitly which indices we want to swap by supplying values\n",
      " |              for both i and j. Here, we for example swap the first and second indices.\n",
      " |      \n",
      " |              >>> df.swaplevel(0, 1)\n",
      " |                                                  Grade\n",
      " |              History     Final exam  January         A\n",
      " |              Geography   Final exam  February        B\n",
      " |              History     Coursework  March           A\n",
      " |              Geography   Coursework  April           C\n",
      " |  \n",
      " |  to_dict(self, orient: 'str' = 'dict', into=<class 'dict'>)\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |      \n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.Mapping\n",
      " |          Return a collections.abc.Mapping object representing the DataFrame.\n",
      " |          The resulting transformation depends on the `orient` parameter.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |      \n",
      " |      You can specify the return orientation.\n",
      " |      \n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |      \n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |      \n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |      \n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |      \n",
      " |      You can also specify the mapping type.\n",
      " |      \n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |      \n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |      \n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |  \n",
      " |  to_feather(self, path: 'FilePathOrBuffer[AnyStr]', **kwargs) -> 'None'\n",
      " |      Write a DataFrame to the binary Feather format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str or file-like object\n",
      " |          If a string, it will be used as Root Directory path.\n",
      " |      **kwargs :\n",
      " |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.\n",
      " |          Starting with pyarrow 0.17, this includes the `compression`,\n",
      " |          `compression_level`, `chunksize` and `version` keywords.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |  \n",
      " |  to_gbq(self, destination_table: 'str', project_id: 'str | None' = None, chunksize: 'int | None' = None, reauth: 'bool' = False, if_exists: 'str' = 'fail', auth_local_webserver: 'bool' = False, table_schema: 'list[dict[str, str]] | None' = None, location: 'str | None' = None, progress_bar: 'bool' = True, credentials=None) -> 'None'\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      This function requires the `pandas-gbq package\n",
      " |      <https://pandas-gbq.readthedocs.io>`__.\n",
      " |      \n",
      " |      See the `How to authenticate with Google BigQuery\n",
      " |      <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\n",
      " |      guide for authentication instructions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      destination_table : str\n",
      " |          Name of table to be written, in the form ``dataset.tablename``.\n",
      " |      project_id : str, optional\n",
      " |          Google BigQuery Account project ID. Optional when available from\n",
      " |          the environment.\n",
      " |      chunksize : int, optional\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |          Set to ``None`` to load the whole dataframe at once.\n",
      " |      reauth : bool, default False\n",
      " |          Force Google BigQuery to re-authenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |      if_exists : str, default 'fail'\n",
      " |          Behavior when the destination table exists. Value can be one of:\n",
      " |      \n",
      " |          ``'fail'``\n",
      " |              If table exists raise pandas_gbq.gbq.TableCreationError.\n",
      " |          ``'replace'``\n",
      " |              If table exists, drop it, recreate it, and insert data.\n",
      " |          ``'append'``\n",
      " |              If table exists, insert data. Create if does not exist.\n",
      " |      auth_local_webserver : bool, default False\n",
      " |          Use the `local webserver flow`_ instead of the `console flow`_\n",
      " |          when getting user credentials.\n",
      " |      \n",
      " |          .. _local webserver flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\n",
      " |          .. _console flow:\n",
      " |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\n",
      " |      \n",
      " |          *New in version 0.2.0 of pandas-gbq*.\n",
      " |      table_schema : list of dicts, optional\n",
      " |          List of BigQuery table fields to which according DataFrame\n",
      " |          columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      " |          'STRING'},...]``. If schema is not provided, it will be\n",
      " |          generated according to dtypes of DataFrame columns. See\n",
      " |          BigQuery API documentation on available names of a field.\n",
      " |      \n",
      " |          *New in version 0.3.1 of pandas-gbq*.\n",
      " |      location : str, optional\n",
      " |          Location where the load job should run. See the `BigQuery locations\n",
      " |          documentation\n",
      " |          <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      " |          list of available locations. The location must match that of the\n",
      " |          target dataset.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      progress_bar : bool, default True\n",
      " |          Use the library `tqdm` to show the progress bar for the upload,\n",
      " |          chunk by chunk.\n",
      " |      \n",
      " |          *New in version 0.5.0 of pandas-gbq*.\n",
      " |      credentials : google.auth.credentials.Credentials, optional\n",
      " |          Credentials for accessing Google APIs. Use this parameter to\n",
      " |          override default credentials, such as to use Compute Engine\n",
      " |          :class:`google.auth.compute_engine.Credentials` or Service\n",
      " |          Account :class:`google.oauth2.service_account.Credentials`\n",
      " |          directly.\n",
      " |      \n",
      " |          *New in version 0.8.0 of pandas-gbq*.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas_gbq.to_gbq : This function in the pandas-gbq library.\n",
      " |      read_gbq : Read a DataFrame from Google BigQuery.\n",
      " |  \n",
      " |  to_html(self, buf: 'FilePathOrBuffer[str] | None' = None, columns: 'Sequence[str] | None' = None, col_space: 'ColspaceArgType | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'FormattersType | None' = None, float_format: 'FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool | str' = False, decimal: 'str' = '.', bold_rows: 'bool' = True, classes: 'str | list | tuple | None' = None, escape: 'bool' = True, notebook: 'bool' = False, border: 'int | None' = None, table_id: 'str | None' = None, render_links: 'bool' = False, encoding: 'str | None' = None)\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : str or int, list or dict of int or str, optional\n",
      " |          The minimum width of each column in CSS length units.  An int is assumed to be px units.\n",
      " |      \n",
      " |          .. versionadded:: 0.25.0\n",
      " |              Ability to use str.\n",
      " |      header : bool, optional\n",
      " |          Whether to print column labels, default True.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      bold_rows : bool, default True\n",
      " |          Make the row labels bold in the output.\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table.\n",
      " |      escape : bool, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.\n",
      " |      notebook : {True, False}, default False\n",
      " |          Whether the generated HTML is for IPython Notebook.\n",
      " |      border : int\n",
      " |          A ``border=border`` attribute is included in the opening\n",
      " |          `<table>` tag. Default ``pd.options.display.html.border``.\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      table_id : str, optional\n",
      " |          A css id is included in the opening `<table>` tag if specified.\n",
      " |      render_links : bool, default False\n",
      " |          Convert URLs to HTML links.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_string : Convert DataFrame to a string.\n",
      " |  \n",
      " |  to_markdown(self, buf: 'IO[str] | str | None' = None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions' = None, **kwargs) -> 'str | None'\n",
      " |      Print DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened, \"wt\" by default.\n",
      " |      index : bool, optional, default True\n",
      " |          Add index (row) labels.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate                 <https://pypi.org/project/tabulate>`_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          DataFrame in Markdown-friendly format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"elk\", \"pig\", \"dog\", \"quetzal\"], name=\"animal\")\n",
      " |      >>> print(s.to_markdown())\n",
      " |      |    | animal   |\n",
      " |      |---:|:---------|\n",
      " |      |  0 | elk      |\n",
      " |      |  1 | pig      |\n",
      " |      |  2 | dog      |\n",
      " |      |  3 | quetzal  |\n",
      " |      \n",
      " |      Output markdown with a tabulate option.\n",
      " |      \n",
      " |      >>> print(s.to_markdown(tablefmt=\"grid\"))\n",
      " |      +----+----------+\n",
      " |      |    | animal   |\n",
      " |      +====+==========+\n",
      " |      |  0 | elk      |\n",
      " |      +----+----------+\n",
      " |      |  1 | pig      |\n",
      " |      +----+----------+\n",
      " |      |  2 | dog      |\n",
      " |      +----+----------+\n",
      " |      |  3 | quetzal  |\n",
      " |      +----+----------+\n",
      " |  \n",
      " |  to_numpy(self, dtype: 'NpDtype | None' = None, copy: 'bool' = False, na_value=<no_default>) -> 'np.ndarray'\n",
      " |      Convert the DataFrame to a NumPy array.\n",
      " |      \n",
      " |      By default, the dtype of the returned array will be the common NumPy\n",
      " |      dtype of all types in the DataFrame. For example, if the dtypes are\n",
      " |      ``float16`` and ``float32``, the results dtype will be ``float32``.\n",
      " |      This may require copying data and coercing values, which may be\n",
      " |      expensive.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the dtypes of the DataFrame columns.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.to_numpy : Similar method for Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
      " |      array([[1, 3],\n",
      " |             [2, 4]])\n",
      " |      \n",
      " |      With heterogeneous data, the lowest common type will have to\n",
      " |      be used.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1. , 3. ],\n",
      " |             [2. , 4.5]])\n",
      " |      \n",
      " |      For a mix of numeric and non-numeric types, the output array will\n",
      " |      have object dtype.\n",
      " |      \n",
      " |      >>> df['C'] = pd.date_range('2000', periods=2)\n",
      " |      >>> df.to_numpy()\n",
      " |      array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\n",
      " |             [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\n",
      " |  \n",
      " |  to_parquet(self, path: 'FilePathOrBuffer | None' = None, engine: 'str' = 'auto', compression: 'str | None' = 'snappy', index: 'bool | None' = None, partition_cols: 'list[str] | None' = None, storage_options: 'StorageOptions' = None, **kwargs) -> 'bytes | None'\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str or file-like object, default None\n",
      " |          If a string, it will be used as Root Directory path\n",
      " |          when writing a partitioned dataset. By file-like object,\n",
      " |          we refer to objects with a write() method, such as a file handle\n",
      " |          (e.g. via builtin open function) or io.BytesIO. The engine\n",
      " |          fastparquet does not accept file-like objects. If path is None,\n",
      " |          a bytes object is returned.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : {'snappy', 'gzip', 'brotli', None}, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |      \n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |  \n",
      " |  to_period(self, freq: 'Frequency | None' = None, axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame'\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex.\n",
      " |      \n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default\n",
      " |          Frequency of the PeriodIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with PeriodIndex\n",
      " |  \n",
      " |  to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> 'np.recarray'\n",
      " |      Convert DataFrame to a NumPy record array.\n",
      " |      \n",
      " |      Index will be included as the first field of the record array if\n",
      " |      requested.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Include index in resulting record array, stored in 'index'\n",
      " |          field or using the index label, if set.\n",
      " |      column_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all columns. If\n",
      " |          a dictionary, a mapping of column names and indices (zero-indexed)\n",
      " |          to specific data types.\n",
      " |      index_dtypes : str, type, dict, default None\n",
      " |          If a string or type, the data type to store all index levels. If\n",
      " |          a dictionary, a mapping of index level names and indices\n",
      " |          (zero-indexed) to specific data types.\n",
      " |      \n",
      " |          This mapping is applied only if `index=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.recarray\n",
      " |          NumPy ndarray with the DataFrame labels as fields and each row\n",
      " |          of the DataFrame as entries.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records: Convert structured or record ndarray\n",
      " |          to DataFrame.\n",
      " |      numpy.recarray: An ndarray that allows field access using\n",
      " |          attributes, analogous to typed columns in a\n",
      " |          spreadsheet.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\n",
      " |      ...                   index=['a', 'b'])\n",
      " |      >>> df\n",
      " |         A     B\n",
      " |      a  1  0.50\n",
      " |      b  2  0.75\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      If the DataFrame index has no label then the recarray field name\n",
      " |      is set to 'index'. If the index has a label then this is used as the\n",
      " |      field name:\n",
      " |      \n",
      " |      >>> df.index = df.index.rename(\"I\")\n",
      " |      >>> df.to_records()\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      The index can be excluded from the record array:\n",
      " |      \n",
      " |      >>> df.to_records(index=False)\n",
      " |      rec.array([(1, 0.5 ), (2, 0.75)],\n",
      " |                dtype=[('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      Data types can be specified for the columns:\n",
      " |      \n",
      " |      >>> df.to_records(column_dtypes={\"A\": \"int32\"})\n",
      " |      rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\n",
      " |                dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\n",
      " |      \n",
      " |      As well as for the index:\n",
      " |      \n",
      " |      >>> df.to_records(index_dtypes=\"<S2\")\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\n",
      " |      \n",
      " |      >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\n",
      " |      >>> df.to_records(index_dtypes=index_dtypes)\n",
      " |      rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\n",
      " |                dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\n",
      " |  \n",
      " |  to_stata(self, path: 'FilePathOrBuffer', convert_dates: 'dict[Hashable, str] | None' = None, write_index: 'bool' = True, byteorder: 'str | None' = None, time_stamp: 'datetime.datetime | None' = None, data_label: 'str | None' = None, variable_labels: 'dict[Hashable, str] | None' = None, version: 'int | None' = 114, convert_strl: 'Sequence[Hashable] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |      \n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, buffer or path object\n",
      " |          String, path object (pathlib.Path or py._path.local.LocalPath) or\n",
      " |          object implementing a binary write() function. If using a buffer\n",
      " |          then the buffer will not be automatically closed after the file\n",
      " |          data has been written.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |          Previously this was \"fname\"\n",
      " |      \n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |      \n",
      " |          Version 119 should usually only be used when the number of\n",
      " |          variables exceeds the capacity of dta format 118. Exporting\n",
      " |          smaller datasets in format 119 may have unintended consequences,\n",
      " |          and, as of November 2020, Stata SE cannot read version 119 files.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |              Added support for formats 118 and 119.\n",
      " |      \n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output dta. If string, specifies\n",
      " |          compression mode. If dict, value at key 'method' specifies\n",
      " |          compression mode. Compression mode must be one of {'infer', 'gzip',\n",
      " |          'bz2', 'zip', 'xz', None}. If compression mode is 'infer' and\n",
      " |          `fname` is path-like, then detect compression from the following\n",
      " |          extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
      " |          compression). If dict and compression mode is one of {'zip',\n",
      " |          'gzip', 'bz2'}, or inferred as one of the above, other entries\n",
      " |          passed as additional compression options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_string(self, buf: 'FilePathOrBuffer[str] | None' = None, columns: 'Sequence[str] | None' = None, col_space: 'int | None' = None, header: 'bool | Sequence[str]' = True, index: 'bool' = True, na_rep: 'str' = 'NaN', formatters: 'fmt.FormattersType | None' = None, float_format: 'fmt.FloatFormatType | None' = None, sparsify: 'bool | None' = None, index_names: 'bool' = True, justify: 'str | None' = None, max_rows: 'int | None' = None, min_rows: 'int | None' = None, max_cols: 'int | None' = None, show_dimensions: 'bool' = False, decimal: 'str' = '.', line_width: 'int | None' = None, max_colwidth: 'int | None' = None, encoding: 'str | None' = None) -> 'str | None'\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : sequence, optional, default None\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, list or dict of int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or sequence, optional\n",
      " |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names.\n",
      " |      index : bool, optional, default True\n",
      " |          Whether to print index (row) labels.\n",
      " |      na_rep : str, optional, default 'NaN'\n",
      " |          String representation of ``NaN`` to use.\n",
      " |      formatters : list, tuple or dict of one-param. functions, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name.\n",
      " |          The result of each function must be a unicode string.\n",
      " |          List/tuple must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional, default None\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats. This function must return a unicode string and will be\n",
      " |          applied only to the non-``NaN`` elements, with ``NaN`` being\n",
      " |          handled by ``na_rep``.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |      sparsify : bool, optional, default True\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row.\n",
      " |      index_names : bool, optional, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      justify : str, default None\n",
      " |          How to justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box. Valid values are\n",
      " |      \n",
      " |          * left\n",
      " |          * right\n",
      " |          * center\n",
      " |          * justify\n",
      " |          * justify-all\n",
      " |          * start\n",
      " |          * end\n",
      " |          * inherit\n",
      " |          * match-parent\n",
      " |          * initial\n",
      " |          * unset.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to display in the console.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in the console in a truncated repr\n",
      " |          (when number of rows is above `max_rows`).\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to display in the console.\n",
      " |      show_dimensions : bool, default False\n",
      " |          Display DataFrame dimensions (number of rows by number of columns).\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      \n",
      " |      line_width : int, optional\n",
      " |          Width to wrap a line in characters.\n",
      " |      max_colwidth : int, optional\n",
      " |          Max width to truncate each column in characters. By default, no limit.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      encoding : str, default \"utf-8\"\n",
      " |          Set character encoding.\n",
      " |      \n",
      " |          .. versionadded:: 1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_html : Convert DataFrame to HTML.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> print(df.to_string())\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     5\n",
      " |      2     3     6\n",
      " |  \n",
      " |  to_timestamp(self, freq: 'Frequency | None' = None, how: 'str' = 'start', axis: 'Axis' = 0, copy: 'bool' = True) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to convert (the index by default).\n",
      " |      copy : bool, default True\n",
      " |          If False then underlying input data is not copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  to_xml(self, path_or_buffer: 'FilePathOrBuffer | None' = None, index: 'bool' = True, root_name: 'str | None' = 'data', row_name: 'str | None' = 'row', na_rep: 'str | None' = None, attr_cols: 'str | list[str] | None' = None, elem_cols: 'str | list[str] | None' = None, namespaces: 'dict[str | None, str] | None' = None, prefix: 'str | None' = None, encoding: 'str' = 'utf-8', xml_declaration: 'bool | None' = True, pretty_print: 'bool | None' = True, parser: 'str | None' = 'lxml', stylesheet: 'FilePathOrBuffer | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Render a DataFrame to an XML document.\n",
      " |      \n",
      " |      .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buffer : str, path object or file-like object, optional\n",
      " |          File to write output to. If None, the output is returned as a\n",
      " |          string.\n",
      " |      index : bool, default True\n",
      " |          Whether to include index in XML document.\n",
      " |      root_name : str, default 'data'\n",
      " |          The name of root element in XML document.\n",
      " |      row_name : str, default 'row'\n",
      " |          The name of row element in XML document.\n",
      " |      na_rep : str, optional\n",
      " |          Missing data representation.\n",
      " |      attr_cols : list-like, optional\n",
      " |          List of columns to write as attributes in row element.\n",
      " |          Hierarchical columns will be flattened with underscore\n",
      " |          delimiting the different levels.\n",
      " |      elem_cols : list-like, optional\n",
      " |          List of columns to write as children in row element. By default,\n",
      " |          all columns output as children of row element. Hierarchical\n",
      " |          columns will be flattened with underscore delimiting the\n",
      " |          different levels.\n",
      " |      namespaces : dict, optional\n",
      " |          All namespaces to be defined in root element. Keys of dict\n",
      " |          should be prefix names and values of dict corresponding URIs.\n",
      " |          Default namespaces should be given empty string key. For\n",
      " |          example, ::\n",
      " |      \n",
      " |              namespaces = {\"\": \"https://example.com\"}\n",
      " |      \n",
      " |      prefix : str, optional\n",
      " |          Namespace prefix to be used for every element and/or attribute\n",
      " |          in document. This should be one of the keys in ``namespaces``\n",
      " |          dict.\n",
      " |      encoding : str, default 'utf-8'\n",
      " |          Encoding of the resulting document.\n",
      " |      xml_declaration : bool, default True\n",
      " |          Whether to include the XML declaration at start of document.\n",
      " |      pretty_print : bool, default True\n",
      " |          Whether output should be pretty printed with indentation and\n",
      " |          line breaks.\n",
      " |      parser : {'lxml','etree'}, default 'lxml'\n",
      " |          Parser module to use for building of tree. Only 'lxml' and\n",
      " |          'etree' are supported. With 'lxml', the ability to use XSLT\n",
      " |          stylesheet is supported.\n",
      " |      stylesheet : str, path object or file-like object, optional\n",
      " |          A URL, file-like object, or a raw string containing an XSLT\n",
      " |          script used to transform the raw XML output. Script should use\n",
      " |          layout of elements and attributes from original output. This\n",
      " |          argument requires ``lxml`` to be installed. Only XSLT 1.0\n",
      " |          scripts and not later versions is currently supported.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
      " |          For on-the-fly decompression of on-disk data. If 'infer', then use\n",
      " |          gzip, bz2, zip or xz if path_or_buffer is a string ending in\n",
      " |          '.gz', '.bz2', '.zip', or 'xz', respectively, and no decompression\n",
      " |          otherwise. If using 'zip', the ZIP file must contain only one data\n",
      " |          file to be read in. Set to None for no decompression.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If ``io`` is None, returns the resulting XML format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_json : Convert the pandas object to a JSON string.\n",
      " |      to_html : Convert DataFrame to a html.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],\n",
      " |      ...                    'degrees': [360, 360, 180],\n",
      " |      ...                    'sides': [4, np.nan, 3]})\n",
      " |      \n",
      " |      >>> df.to_xml()  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row>\n",
      " |          <index>0</index>\n",
      " |          <shape>square</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides>4.0</sides>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>1</index>\n",
      " |          <shape>circle</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides/>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>2</index>\n",
      " |          <shape>triangle</shape>\n",
      " |          <degrees>180</degrees>\n",
      " |          <sides>3.0</sides>\n",
      " |        </row>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(attr_cols=[\n",
      " |      ...           'index', 'shape', 'degrees', 'sides'\n",
      " |      ...           ])  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
      " |        <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\n",
      " |        <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
      " |      </data>\n",
      " |      \n",
      " |      >>> df.to_xml(namespaces={\"doc\": \"https://example.com\"},\n",
      " |      ...           prefix=\"doc\")  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <doc:data xmlns:doc=\"https://example.com\">\n",
      " |        <doc:row>\n",
      " |          <doc:index>0</doc:index>\n",
      " |          <doc:shape>square</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides>4.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>1</doc:index>\n",
      " |          <doc:shape>circle</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides/>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>2</doc:index>\n",
      " |          <doc:shape>triangle</doc:shape>\n",
      " |          <doc:degrees>180</doc:degrees>\n",
      " |          <doc:sides>3.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |      </doc:data>\n",
      " |  \n",
      " |  transform(self, func: 'AggFuncType', axis: 'Axis' = 0, *args, **kwargs) -> 'DataFrame'\n",
      " |      Call ``func`` on self producing a DataFrame with transformed values.\n",
      " |      \n",
      " |      Produced DataFrame will have same axis length as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list-like or dict-like\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a DataFrame or when passed to DataFrame.apply. If func\n",
      " |          is both list-like and dict-like, dict-like behavior takes precedence.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list-like of functions and/or function names, e.g. ``[np.exp, 'sqrt']``\n",
      " |          - dict-like of axis labels -> functions, function names or list-like of such.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |              If 0 or 'index': apply function to each column.\n",
      " |              If 1 or 'columns': apply function to each row.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A DataFrame that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned DataFrame has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.agg : Only perform aggregating type operations.\n",
      " |      DataFrame.apply : Invoke function on a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting DataFrame must have the same length as the\n",
      " |      input DataFrame, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |      \n",
      " |      You can call transform on a GroupBy object:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"Date\": [\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\",\n",
      " |      ...         \"2015-05-08\", \"2015-05-07\", \"2015-05-06\", \"2015-05-05\"],\n",
      " |      ...     \"Data\": [5, 8, 6, 1, 50, 100, 60, 120],\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |               Date  Data\n",
      " |      0  2015-05-08     5\n",
      " |      1  2015-05-07     8\n",
      " |      2  2015-05-06     6\n",
      " |      3  2015-05-05     1\n",
      " |      4  2015-05-08    50\n",
      " |      5  2015-05-07   100\n",
      " |      6  2015-05-06    60\n",
      " |      7  2015-05-05   120\n",
      " |      >>> df.groupby('Date')['Data'].transform('sum')\n",
      " |      0     55\n",
      " |      1    108\n",
      " |      2     66\n",
      " |      3    121\n",
      " |      4     55\n",
      " |      5    108\n",
      " |      6     66\n",
      " |      7    121\n",
      " |      Name: Data, dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     \"c\": [1, 1, 1, 2, 2, 2, 2],\n",
      " |      ...     \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |         c type\n",
      " |      0  1    m\n",
      " |      1  1    n\n",
      " |      2  1    o\n",
      " |      3  2    m\n",
      " |      4  2    m\n",
      " |      5  2    n\n",
      " |      6  2    n\n",
      " |      >>> df['size'] = df.groupby('c')['type'].transform(len)\n",
      " |      >>> df\n",
      " |         c type size\n",
      " |      0  1    m    3\n",
      " |      1  1    n    3\n",
      " |      2  1    o    3\n",
      " |      3  2    m    4\n",
      " |      4  2    m    4\n",
      " |      5  2    n    4\n",
      " |      6  2    n    4\n",
      " |  \n",
      " |  transpose(self, *args, copy: 'bool' = False) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |      \n",
      " |      Reflect the DataFrame over its main diagonal by writing rows as columns\n",
      " |      and vice-versa. The property :attr:`.T` is an accessor to the method\n",
      " |      :meth:`transpose`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : tuple, optional\n",
      " |          Accepted for compatibility with NumPy.\n",
      " |      copy : bool, default False\n",
      " |          Whether to copy the data after transposing, even for DataFrames\n",
      " |          with a single dtype.\n",
      " |      \n",
      " |          Note that a copy is always required for mixed dtype DataFrames,\n",
      " |          or for DataFrames with any extension types.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The transposed DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.transpose : Permute the dimensions of a given array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Transposing a DataFrame with mixed dtypes will result in a homogeneous\n",
      " |      DataFrame with the `object` dtype. In such a case, a copy of the data\n",
      " |      is always made.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Square DataFrame with homogeneous dtype**\n",
      " |      \n",
      " |      >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df1 = pd.DataFrame(data=d1)\n",
      " |      >>> df1\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |      \n",
      " |      >>> df1_transposed = df1.T # or df1.transpose()\n",
      " |      >>> df1_transposed\n",
      " |            0  1\n",
      " |      col1  1  2\n",
      " |      col2  3  4\n",
      " |      \n",
      " |      When the dtype is homogeneous in the original DataFrame, we get a\n",
      " |      transposed DataFrame with the same dtype:\n",
      " |      \n",
      " |      >>> df1.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      >>> df1_transposed.dtypes\n",
      " |      0    int64\n",
      " |      1    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **Non-square DataFrame with mixed dtypes**\n",
      " |      \n",
      " |      >>> d2 = {'name': ['Alice', 'Bob'],\n",
      " |      ...       'score': [9.5, 8],\n",
      " |      ...       'employed': [False, True],\n",
      " |      ...       'kids': [0, 0]}\n",
      " |      >>> df2 = pd.DataFrame(data=d2)\n",
      " |      >>> df2\n",
      " |          name  score  employed  kids\n",
      " |      0  Alice    9.5     False     0\n",
      " |      1    Bob    8.0      True     0\n",
      " |      \n",
      " |      >>> df2_transposed = df2.T # or df2.transpose()\n",
      " |      >>> df2_transposed\n",
      " |                    0     1\n",
      " |      name      Alice   Bob\n",
      " |      score       9.5   8.0\n",
      " |      employed  False  True\n",
      " |      kids          0     0\n",
      " |      \n",
      " |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with\n",
      " |      the `object` dtype:\n",
      " |      \n",
      " |      >>> df2.dtypes\n",
      " |      name         object\n",
      " |      score       float64\n",
      " |      employed       bool\n",
      " |      kids          int64\n",
      " |      dtype: object\n",
      " |      >>> df2_transposed.dtypes\n",
      " |      0    object\n",
      " |      1    object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value\n",
      " |      for missing data in one of the inputs. With reverse version, `rtruediv`.\n",
      " |      \n",
      " |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to\n",
      " |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, or DataFrame\n",
      " |          Any single or multiple element data structure, or list-like object.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}\n",
      " |          Whether to compare by the index (0 or 'index') or columns\n",
      " |          (1 or 'columns'). For Series input, axis to match Series index on.\n",
      " |      level : int or label\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : float or None, default None\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful DataFrame alignment, with this value before computation.\n",
      " |          If data in both corresponding DataFrame locations is missing\n",
      " |          the result will be missing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Result of the arithmetic operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add DataFrames.\n",
      " |      DataFrame.sub : Subtract DataFrames.\n",
      " |      DataFrame.mul : Multiply DataFrames.\n",
      " |      DataFrame.div : Divide DataFrames (float division).\n",
      " |      DataFrame.truediv : Divide DataFrames (float division).\n",
      " |      DataFrame.floordiv : Divide DataFrames (integer division).\n",
      " |      DataFrame.mod : Calculate modulo (remainder after division).\n",
      " |      DataFrame.pow : Calculate exponential power.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'angles': [0, 3, 4],\n",
      " |      ...                    'degrees': [360, 180, 360]},\n",
      " |      ...                   index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> df\n",
      " |                 angles  degrees\n",
      " |      circle          0      360\n",
      " |      triangle        3      180\n",
      " |      rectangle       4      360\n",
      " |      \n",
      " |      Add a scalar with operator version which return the same\n",
      " |      results.\n",
      " |      \n",
      " |      >>> df + 1\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      >>> df.add(1)\n",
      " |                 angles  degrees\n",
      " |      circle          1      361\n",
      " |      triangle        4      181\n",
      " |      rectangle       5      361\n",
      " |      \n",
      " |      Divide by constant with reverse version.\n",
      " |      \n",
      " |      >>> df.div(10)\n",
      " |                 angles  degrees\n",
      " |      circle        0.0     36.0\n",
      " |      triangle      0.3     18.0\n",
      " |      rectangle     0.4     36.0\n",
      " |      \n",
      " |      >>> df.rdiv(10)\n",
      " |                   angles   degrees\n",
      " |      circle          inf  0.027778\n",
      " |      triangle   3.333333  0.055556\n",
      " |      rectangle  2.500000  0.027778\n",
      " |      \n",
      " |      Subtract a list and Series by axis with operator version.\n",
      " |      \n",
      " |      >>> df - [1, 2]\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub([1, 2], axis='columns')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      358\n",
      " |      triangle        2      178\n",
      " |      rectangle       3      358\n",
      " |      \n",
      " |      >>> df.sub(pd.Series([1, 1, 1], index=['circle', 'triangle', 'rectangle']),\n",
      " |      ...        axis='index')\n",
      " |                 angles  degrees\n",
      " |      circle         -1      359\n",
      " |      triangle        2      179\n",
      " |      rectangle       3      359\n",
      " |      \n",
      " |      Multiply a DataFrame of different shape with operator version.\n",
      " |      \n",
      " |      >>> other = pd.DataFrame({'angles': [0, 3, 4]},\n",
      " |      ...                      index=['circle', 'triangle', 'rectangle'])\n",
      " |      >>> other\n",
      " |                 angles\n",
      " |      circle          0\n",
      " |      triangle        3\n",
      " |      rectangle       4\n",
      " |      \n",
      " |      >>> df * other\n",
      " |                 angles  degrees\n",
      " |      circle          0      NaN\n",
      " |      triangle        9      NaN\n",
      " |      rectangle      16      NaN\n",
      " |      \n",
      " |      >>> df.mul(other, fill_value=0)\n",
      " |                 angles  degrees\n",
      " |      circle          0      0.0\n",
      " |      triangle        9      0.0\n",
      " |      rectangle      16      0.0\n",
      " |      \n",
      " |      Divide by a MultiIndex by level.\n",
      " |      \n",
      " |      >>> df_multindex = pd.DataFrame({'angles': [0, 3, 4, 4, 5, 6],\n",
      " |      ...                              'degrees': [360, 180, 360, 360, 540, 720]},\n",
      " |      ...                             index=[['A', 'A', 'A', 'B', 'B', 'B'],\n",
      " |      ...                                    ['circle', 'triangle', 'rectangle',\n",
      " |      ...                                     'square', 'pentagon', 'hexagon']])\n",
      " |      >>> df_multindex\n",
      " |                   angles  degrees\n",
      " |      A circle          0      360\n",
      " |        triangle        3      180\n",
      " |        rectangle       4      360\n",
      " |      B square          4      360\n",
      " |        pentagon        5      540\n",
      " |        hexagon         6      720\n",
      " |      \n",
      " |      >>> df.div(df_multindex, level=1, fill_value=0)\n",
      " |                   angles  degrees\n",
      " |      A circle        NaN      1.0\n",
      " |        triangle      1.0      1.0\n",
      " |        rectangle     1.0      1.0\n",
      " |      B square        0.0      0.0\n",
      " |        pentagon      0.0      0.0\n",
      " |        hexagon       0.0      0.0\n",
      " |  \n",
      " |  unstack(self, level: 'Level' = -1, fill_value=None)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |      \n",
      " |      Returns a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels.\n",
      " |      \n",
      " |      If the index is not a MultiIndex, the output will be a Series\n",
      " |      (the analogue of stack when the columns are not a MultiIndex).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name.\n",
      " |      fill_value : int, str or dict\n",
      " |          Replace NaN with this value if the unstack produces missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1.0\n",
      " |           b   2.0\n",
      " |      two  a   3.0\n",
      " |           b   4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1.0  2.0\n",
      " |      two  3.0  4.0\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1.0   3.0\n",
      " |      b  2.0   4.0\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.0\n",
      " |           b  2.0\n",
      " |      two  a  3.0\n",
      " |           b  4.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  update(self, other, join: 'str' = 'left', overwrite: 'bool' = True, filter_func=None, errors: 'str' = 'ignore') -> 'None'\n",
      " |      Modify in place using non-NA values from another DataFrame.\n",
      " |      \n",
      " |      Aligns on indices. There is no return value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |          Should have at least one matching index/column label\n",
      " |          with the original DataFrame. If a Series is passed,\n",
      " |          its name attribute must be set, and that will be\n",
      " |          used as the column name to align with the original DataFrame.\n",
      " |      join : {'left'}, default 'left'\n",
      " |          Only left join is implemented, keeping the index and columns of the\n",
      " |          original object.\n",
      " |      overwrite : bool, default True\n",
      " |          How to handle non-NA values for overlapping keys:\n",
      " |      \n",
      " |          * True: overwrite original DataFrame's values\n",
      " |            with values from `other`.\n",
      " |          * False: only update values that are NA in\n",
      " |            the original DataFrame.\n",
      " |      \n",
      " |      filter_func : callable(1d-array) -> bool 1d-array, optional\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated.\n",
      " |      errors : {'raise', 'ignore'}, default 'ignore'\n",
      " |          If 'raise', will raise a ValueError if the DataFrame and `other`\n",
      " |          both contain non-NA data in the same place.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None : method directly changes calling object\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * When `errors='raise'` and there's overlapping non-NA data.\n",
      " |          * When `errors` is not either `'ignore'` or `'raise'`\n",
      " |      NotImplementedError\n",
      " |          * If `join != 'left'`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      dict.update : Similar method for dictionaries.\n",
      " |      DataFrame.merge : For column(s)-on-column(s) operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, 5, 6],\n",
      " |      ...                        'C': [7, 8, 9]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  4\n",
      " |      1  2  5\n",
      " |      2  3  6\n",
      " |      \n",
      " |      The DataFrame's length does not increase as a result of the update,\n",
      " |      only values at matching index/column labels are updated.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  e\n",
      " |      2  c  f\n",
      " |      \n",
      " |      For Series, its name attribute must be set.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_column = pd.Series(['d', 'e'], name='B', index=[0, 2])\n",
      " |      >>> df.update(new_column)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  d\n",
      " |      1  b  y\n",
      " |      2  c  e\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\n",
      " |      ...                    'B': ['x', 'y', 'z']})\n",
      " |      >>> new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2])\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  x\n",
      " |      1  b  d\n",
      " |      2  c  e\n",
      " |      \n",
      " |      If `other` contains NaNs the corresponding values are not updated\n",
      " |      in the original dataframe.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3],\n",
      " |      ...                    'B': [400, 500, 600]})\n",
      " |      >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\n",
      " |      >>> df.update(new_df)\n",
      " |      >>> df\n",
      " |         A      B\n",
      " |      0  1    4.0\n",
      " |      1  2  500.0\n",
      " |      2  3    6.0\n",
      " |  \n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True)\n",
      " |      Return a Series containing counts of unique rows in the DataFrame.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : list-like, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don’t include counts of rows that contain NA values.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column. By default, rows that contain any NA values are omitted from\n",
      " |      the result. By default, the resulting Series will be in descending\n",
      " |      order so that the first element is the most frequently-occurring row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      2         2            0.25\n",
      " |      6         0            0.25\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      With `dropna` set to `False` we can also count rows with NA values.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
      " |      ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
      " |      >>> df\n",
      " |        first_name middle_name\n",
      " |      0       John       Smith\n",
      " |      1       Anne        <NA>\n",
      " |      2       John        <NA>\n",
      " |      3       Beth      Louise\n",
      " |      \n",
      " |      >>> df.value_counts()\n",
      " |      first_name  middle_name\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.value_counts(dropna=False)\n",
      " |      first_name  middle_name\n",
      " |      Anne        NaN            1\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |                  NaN            1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a Series.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame (if level specified)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the\n",
      " |      default `ddof=1`)\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=<no_default>)\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default None\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |          .. deprecated:: 1.3.0\n",
      " |              Manually cast back if necessary.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      >>> s.mask(s > 1, 10)\n",
      " |      0     0\n",
      " |      1     1\n",
      " |      2    10\n",
      " |      3    10\n",
      " |      4    10\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_dict(data, orient: 'str' = 'columns', dtype: 'Dtype | None' = None, columns=None) -> 'DataFrame' from builtins.type\n",
      " |      Construct DataFrame from dict of array-like or dicts.\n",
      " |      \n",
      " |      Creates DataFrame object from dictionary by columns or by index\n",
      " |      allowing dtype specification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          Of the form {field : array-like} or {field : dict}.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |      dtype : dtype, default None\n",
      " |          Data type to force, otherwise infer.\n",
      " |      columns : list, default None\n",
      " |          Column labels to use when ``orient='index'``. Raises a ValueError\n",
      " |          if used with ``orient='columns'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_records : DataFrame from structured ndarray, sequence\n",
      " |          of tuples or dicts, or DataFrame.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default the keys of the dict become the DataFrame columns:\n",
      " |      \n",
      " |      >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Specify ``orient='index'`` to create the DataFrame using dictionary\n",
      " |      keys as rows:\n",
      " |      \n",
      " |      >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index')\n",
      " |             0  1  2  3\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |      \n",
      " |      When using the 'index' orientation, the column names can be\n",
      " |      specified manually:\n",
      " |      \n",
      " |      >>> pd.DataFrame.from_dict(data, orient='index',\n",
      " |      ...                        columns=['A', 'B', 'C', 'D'])\n",
      " |             A  B  C  D\n",
      " |      row_1  3  2  1  0\n",
      " |      row_2  a  b  c  d\n",
      " |  \n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float: 'bool' = False, nrows: 'int | None' = None) -> 'DataFrame' from builtins.type\n",
      " |      Convert structured or record ndarray to DataFrame.\n",
      " |      \n",
      " |      Creates a DataFrame object from a structured ndarray, sequence of\n",
      " |      tuples or dicts, or DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : structured ndarray, sequence of tuples or dicts, or DataFrame\n",
      " |          Structured input data.\n",
      " |      index : str, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use.\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude.\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns).\n",
      " |      coerce_float : bool, default False\n",
      " |          Attempt to convert values of non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      " |      nrows : int, default None\n",
      " |          Number of rows to read if data is an iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.\n",
      " |      DataFrame : DataFrame object creation using constructor.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Data can be provided as a structured ndarray:\n",
      " |      \n",
      " |      >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\n",
      " |      ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of dicts:\n",
      " |      \n",
      " |      >>> data = [{'col_1': 3, 'col_2': 'a'},\n",
      " |      ...         {'col_1': 2, 'col_2': 'b'},\n",
      " |      ...         {'col_1': 1, 'col_2': 'c'},\n",
      " |      ...         {'col_1': 0, 'col_2': 'd'}]\n",
      " |      >>> pd.DataFrame.from_records(data)\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |      \n",
      " |      Data can be provided as a list of tuples with corresponding columns:\n",
      " |      \n",
      " |      >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\n",
      " |      >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\n",
      " |         col_1 col_2\n",
      " |      0      3     a\n",
      " |      1      2     b\n",
      " |      2      1     c\n",
      " |      3      0     d\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  T\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list representing the axes of the DataFrame.\n",
      " |      \n",
      " |      It has the row axis labels and column axis labels as the only members.\n",
      " |      They are returned in that order.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.axes\n",
      " |      [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\n",
      " |      dtype='object')]\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.shape : Tuple of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.shape\n",
      " |      (2, 2)\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\n",
      " |      ...                    'col3': [5, 6]})\n",
      " |      >>> df.shape\n",
      " |      (2, 3)\n",
      " |  \n",
      " |  style\n",
      " |      Returns a Styler object.\n",
      " |      \n",
      " |      Contains methods for building a styled HTML representation of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      io.formats.style.Styler : Helps style a DataFrame or Series according to the\n",
      " |          data with HTML and CSS.\n",
      " |  \n",
      " |  values\n",
      " |      Return a Numpy representation of the DataFrame.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :meth:`DataFrame.to_numpy` instead.\n",
      " |      \n",
      " |      Only the values in the DataFrame will be returned, the axes labels\n",
      " |      will be removed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values of the DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_numpy : Recommended alternative to this method.\n",
      " |      DataFrame.index : Retrieve the index labels.\n",
      " |      DataFrame.columns : Retrieving the column names.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcast to\n",
      " |      int32. By :func:`numpy.find_common_type` convention, mixing int64\n",
      " |      and uint64 will result in a float64 dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A DataFrame where all columns are the same type (e.g., int64) results\n",
      " |      in an array of the same type.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age':    [ 3,  29],\n",
      " |      ...                    'height': [94, 170],\n",
      " |      ...                    'weight': [31, 115]})\n",
      " |      >>> df\n",
      " |         age  height  weight\n",
      " |      0    3      94      31\n",
      " |      1   29     170     115\n",
      " |      >>> df.dtypes\n",
      " |      age       int64\n",
      " |      height    int64\n",
      " |      weight    int64\n",
      " |      dtype: object\n",
      " |      >>> df.values\n",
      " |      array([[  3,  94,  31],\n",
      " |             [ 29, 170, 115]])\n",
      " |      \n",
      " |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)\n",
      " |      results in an ndarray of the broadest type that accommodates these\n",
      " |      mixed types (e.g., object).\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\n",
      " |      ...                     ('lion',     80.5, 1),\n",
      " |      ...                     ('monkey', np.nan, None)],\n",
      " |      ...                   columns=('name', 'max_speed', 'rank'))\n",
      " |      >>> df2.dtypes\n",
      " |      name          object\n",
      " |      max_speed    float64\n",
      " |      rank          object\n",
      " |      dtype: object\n",
      " |      >>> df2.values\n",
      " |      array([['parrot', 24.0, 'second'],\n",
      " |             ['lion', 80.5, 1],\n",
      " |             ['monkey', nan, None]], dtype=object)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  columns\n",
      " |      The column labels of the DataFrame.\n",
      " |  \n",
      " |  index\n",
      " |      The index (row labels) of the DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_AXIS_TO_AXIS_NUMBER': 'dict[Axis, int]', '_access...\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot (DataFrame only)\n",
      " |          - 'hexbin' : hexbin plot (DataFrame only)\n",
      " |      ax : matplotlib axes object, default None\n",
      " |          An axes of the current figure.\n",
      " |      subplots : bool, default False\n",
      " |          Make separate subplots for each column.\n",
      " |      sharex : bool, default True if ax is None else False\n",
      " |          In case ``subplots=True``, share x axis and set some x axis labels\n",
      " |          to invisible; defaults to True if ax is None otherwise False if\n",
      " |          an ax is passed in; Be aware, that passing in both an ax and\n",
      " |          ``sharex=True`` will alter all x axis labels for all axis in a figure.\n",
      " |      sharey : bool, default False\n",
      " |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.\n",
      " |      layout : tuple, optional\n",
      " |          (rows, columns) for the layout of subplots.\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |          Size of a figure object.\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |          Set the x limits of the current axes.\n",
      " |      ylim : 2-tuple/list\n",
      " |          Set the y limits of the current axes.\n",
      " |      xlabel : label, optional\n",
      " |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the\n",
      " |          x-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      ylabel : label, optional\n",
      " |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the\n",
      " |          y-column name for planar plots.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Now applicable to planar plots (`scatter`, `hexbin`).\n",
      " |      \n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      stacked : bool, default False in line and bar plots, and True in area plot\n",
      " |          If True, create stacked plot.\n",
      " |      sort_columns : bool, default False\n",
      " |          Sort column names to determine plot ordering.\n",
      " |      secondary_y : bool or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis if a list/tuple, which\n",
      " |          columns to plot on secondary y-axis.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseFrameAccesso...\n",
      " |      DataFrame accessor for sparse data.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: 'FrameOrSeries') -> 'FrameOrSeries'\n",
      " |  \n",
      " |  __array__(self, dtype: 'NpDtype | None' = None) -> 'np.ndarray'\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any')\n",
      " |  \n",
      " |  __array_wrap__(self, result: 'np.ndarray', context: 'tuple[Callable, tuple[Any, ...], int] | None' = None)\n",
      " |      Gets called after a ufunc and other functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      result: np.ndarray\n",
      " |          The result of the ufunc or other function called on the NumPy array\n",
      " |          returned by __array__\n",
      " |      context: tuple of (func, tuple, int)\n",
      " |          This parameter is returned by ufuncs as a 3-element tuple: (name of the\n",
      " |          ufunc, arguments of the ufunc, domain of the ufunc), but is not set by\n",
      " |          other numpy functions.q\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series implements __array_ufunc_ so this not called for ufunc on Series.\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key) -> 'bool_t'\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: 'FrameOrSeries', deep: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |  \n",
      " |  __deepcopy__(self: 'FrameOrSeries', memo=None) -> 'FrameOrSeries'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: 'FrameOrSeries', other, method: 'str | None' = None, **kwargs) -> 'FrameOrSeries'\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where ``__finalize__``\n",
      " |          was called.\n",
      " |      \n",
      " |          .. warning::\n",
      " |      \n",
      " |             The value passed as `method` are not currently considered\n",
      " |             stable across pandas releases.\n",
      " |  \n",
      " |  __getattr__(self, name: 'str')\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> 'dict[str, Any]'\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __iand__(self, other)\n",
      " |  \n",
      " |  __ifloordiv__(self, other)\n",
      " |  \n",
      " |  __imod__(self, other)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __ior__(self, other)\n",
      " |  \n",
      " |  __ipow__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over info axis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |          Info axis as iterator.\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __ixor__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self: 'FrameOrSeries', decimals: 'int' = 0) -> 'FrameOrSeries'\n",
      " |  \n",
      " |  __setattr__(self, name: 'str', value) -> 'None'\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self: 'FrameOrSeries') -> 'FrameOrSeries'\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: 'FrameOrSeries', prefix: 'str') -> 'FrameOrSeries'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: 'FrameOrSeries', suffix: 'str') -> 'FrameOrSeries'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                               a   b\n",
      " |      2018-02-27 09:03:30   30.0 NaN\n",
      " |      2018-02-27 09:04:30   40.0 NaN\n",
      " |  \n",
      " |  astype(self: 'FrameOrSeries', dtype, copy: 'bool_t' = True, errors: 'str' = 'raise') -> 'FrameOrSeries'\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: 1.3.0\n",
      " |      \n",
      " |          Using ``astype`` to convert from timezone-naive dtype to\n",
      " |          timezone-aware dtype is deprecated and will raise in a\n",
      " |          future version.  Use :meth:`Series.dt.tz_localize` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> from pandas.api.types import CategoricalDtype\n",
      " |      >>> cat_dtype = CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1, 2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Create a series of dates:\n",
      " |      \n",
      " |      >>> ser_date = pd.Series(pd.date_range('20200101', periods=3))\n",
      " |      >>> ser_date\n",
      " |      0   2020-01-01\n",
      " |      1   2020-01-02\n",
      " |      2   2020-01-03\n",
      " |      dtype: datetime64[ns]\n",
      " |  \n",
      " |  at_time(self: 'FrameOrSeries', time, asof: 'bool_t' = False, axis=None) -> 'FrameOrSeries'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  backfill = bfill(self: 'FrameOrSeries', axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast=None) -> 'FrameOrSeries | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  between_time(self: 'FrameOrSeries', start_time, end_time, include_start: 'bool_t' = True, include_end: 'bool_t' = True, axis=None) -> 'FrameOrSeries'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      include_start : bool, default True\n",
      " |          Whether the start time needs to be included in the result.\n",
      " |      include_end : bool, default True\n",
      " |          Whether the end time needs to be included in the result.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element Series or DataFrame.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False. It will raise a\n",
      " |      ValueError if the Series or DataFrame does not have exactly 1 element, or that\n",
      " |      element is not boolean (integer values 0 and 1 will also raise an exception).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          The value in the Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.astype : Change the data type of a Series, including to boolean.\n",
      " |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.\n",
      " |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      The method will only work for single element objects with a boolean value:\n",
      " |      \n",
      " |      >>> pd.Series([True]).bool()\n",
      " |      True\n",
      " |      >>> pd.Series([False]).bool()\n",
      " |      False\n",
      " |      \n",
      " |      >>> pd.DataFrame({'col': [True]}).bool()\n",
      " |      True\n",
      " |      >>> pd.DataFrame({'col': [False]}).bool()\n",
      " |      False\n",
      " |  \n",
      " |  convert_dtypes(self: 'FrameOrSeries', infer_objects: 'bool_t' = True, convert_string: 'bool_t' = True, convert_integer: 'bool_t' = True, convert_boolean: 'bool_t' = True, convert_floating: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      convert_floating : bool, defaults True\n",
      " |          Whether, if possible, conversion can be done to floating extension types.\n",
      " |          If `convert_integer` is also True, preference will be give to integer\n",
      " |          dtypes if the floats can be faithfully casted to integers.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and\n",
      " |      ``convert_boolean``, it is possible to turn off individual conversions\n",
      " |      to ``StringDtype``, the integer extension types, ``BooleanDtype``\n",
      " |      or floating extension types, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer\n",
      " |      or floating extension type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type. Otherwise, convert to an\n",
      " |      appropriate floating extension type.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2\n",
      " |          Starting with pandas 1.2, this method also converts float columns\n",
      " |          to the nullable floating extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10   <NA>\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a      Int32\n",
      " |      b     string\n",
      " |      c    boolean\n",
      " |      d     string\n",
      " |      e      Int64\n",
      " |      f    Float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: 'FrameOrSeries', deep: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: 'FrameOrSeries', percentiles=None, include=None, exclude=None, datetime_is_numeric=False) -> 'FrameOrSeries'\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      datetime_is_numeric : bool, default False\n",
      " |          Whether to treat datetime dtypes as numeric. This affects statistics\n",
      " |          calculated for the column. For DataFrame input, this also\n",
      " |          controls whether datetime columns are included by default.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe(datetime_is_numeric=True)\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: 'FrameOrSeries', level, axis=0) -> 'FrameOrSeries'\n",
      " |      Return Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis along which the level(s) is removed:\n",
      " |      \n",
      " |          * 0 or 'index': remove level(s) in column.\n",
      " |          * 1 or 'columns': remove level(s) in row.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame\n",
      " |          Series/DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...     ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level_2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other: 'object') -> 'bool_t'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal.\n",
      " |      \n",
      " |      The row/column index do not need to have the same type, as long\n",
      " |      as the values are considered equal. Corresponding columns must be of\n",
      " |      the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool_t' = True, ignore_na: 'bool_t' = False, axis: 'Axis' = 0, times: 'str | np.ndarray | FrameOrSeries | None' = None) -> 'ExponentialMovingWindow'\n",
      " |      Provide exponential weighted (EW) functions.\n",
      " |      \n",
      " |      Available EW functions: ``mean()``, ``var()``, ``std()``, ``corr()``, ``cov()``.\n",
      " |      \n",
      " |      Exactly one parameter: ``com``, ``span``, ``halflife``, or ``alpha`` must be\n",
      " |      provided.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com)`, for :math:`com \\geq 0`.\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1)`, for :math:`span \\geq 1`.\n",
      " |      halflife : float, str, timedelta, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - \\exp\\left(-\\ln(2) / halflife\\right)`, for\n",
      " |          :math:`halflife > 0`.\n",
      " |      \n",
      " |          If ``times`` is specified, the time unit (str or timedelta) over which an\n",
      " |          observation decays to half its value. Only applicable to ``mean()``\n",
      " |          and halflife value will not apply to the other functions.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings (viewing EWMA as a moving average).\n",
      " |      \n",
      " |          - When ``adjust=True`` (default), the EW function is calculated using weights\n",
      " |            :math:`w_i = (1 - \\alpha)^i`. For example, the EW moving average of the series\n",
      " |            [:math:`x_0, x_1, ..., x_t`] would be:\n",
      " |      \n",
      " |          .. math::\n",
      " |              y_t = \\frac{x_t + (1 - \\alpha)x_{t-1} + (1 - \\alpha)^2 x_{t-2} + ... + (1 -\n",
      " |              \\alpha)^t x_0}{1 + (1 - \\alpha) + (1 - \\alpha)^2 + ... + (1 - \\alpha)^t}\n",
      " |      \n",
      " |          - When ``adjust=False``, the exponentially weighted function is calculated\n",
      " |            recursively:\n",
      " |      \n",
      " |          .. math::\n",
      " |              \\begin{split}\n",
      " |                  y_0 &= x_0\\\\\n",
      " |                  y_t &= (1 - \\alpha) y_{t-1} + \\alpha x_t,\n",
      " |              \\end{split}\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights; specify ``True`` to reproduce\n",
      " |          pre-0.15.0 behavior.\n",
      " |      \n",
      " |          - When ``ignore_na=False`` (default), weights are based on absolute positions.\n",
      " |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating\n",
      " |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are\n",
      " |            :math:`(1-\\alpha)^2` and :math:`1` if ``adjust=True``, and\n",
      " |            :math:`(1-\\alpha)^2` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      \n",
      " |          - When ``ignore_na=True`` (reproducing pre-0.15.0 behavior), weights are based\n",
      " |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`\n",
      " |            used in calculating the final weighted average of\n",
      " |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\\alpha` and :math:`1` if\n",
      " |            ``adjust=True``, and :math:`1-\\alpha` and :math:`\\alpha` if ``adjust=False``.\n",
      " |      axis : {0, 1}, default 0\n",
      " |          The axis to use. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      times : str, np.ndarray, Series, default None\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |          Times corresponding to the observations. Must be monotonically increasing and\n",
      " |          ``datetime64[ns]`` dtype.\n",
      " |      \n",
      " |          If str, the name of the column in the DataFrame representing the times.\n",
      " |      \n",
      " |          If 1-D array like, a sequence with the same shape as the observations.\n",
      " |      \n",
      " |          Only applicable to ``mean()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A Window sub-classed for the particular operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      More details can be found at:\n",
      " |      :ref:`Exponentially weighted windows <window.exponentially_weighted>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |      \n",
      " |      Specifying ``times`` with a timedelta ``halflife`` when computing mean.\n",
      " |      \n",
      " |      >>> times = ['2020-01-01', '2020-01-03', '2020-01-10', '2020-01-15', '2020-01-17']\n",
      " |      >>> df.ewm(halflife='4 days', times=pd.DatetimeIndex(times)).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.585786\n",
      " |      2  1.523889\n",
      " |      3  1.523889\n",
      " |      4  3.233686\n",
      " |  \n",
      " |  expanding(self, min_periods: 'int' = 1, center: 'bool_t | None' = None, axis: 'Axis' = 0, method: 'str' = 'single') -> 'Expanding'\n",
      " |      Provide expanding transformations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or str, default 0\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"B\": [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  filter(self: 'FrameOrSeries', items=None, like: 'str | None' = None, regex: 'str | None' = None, axis=None) -> 'FrameOrSeries'\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      >>> df\n",
      " |              one  two  three\n",
      " |      mouse     1    2      3\n",
      " |      rabbit    4    5      6\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: 'FrameOrSeries', offset) -> 'FrameOrSeries'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      When having a DataFrame with dates as index, this function can\n",
      " |      select the first few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset or dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '1M' will display all the rows having their index within the first month.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calendar days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for first non-NA value or None, if no NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : same type as items contained in object\n",
      " |  \n",
      " |  head(self: 'FrameOrSeries', n: 'int' = 5) -> 'FrameOrSeries'\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `n` rows, equivalent to ``df[:-n]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: 'FrameOrSeries') -> 'FrameOrSeries'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get the 'info axis' (see Indexing for more).\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Info axis.\n",
      " |  \n",
      " |  last(self: 'FrameOrSeries', offset) -> 'FrameOrSeries'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      For a DataFrame with a sorted DatetimeIndex, this function\n",
      " |      selects the last few rows based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |          The offset length of the data that will be selected. For instance,\n",
      " |          '3D' will display all the rows having their index within the last 3 days.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A subset of the caller.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calendar days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self) -> 'Hashable | None'\n",
      " |      Return index for last non-NA value or None, if no NA value is found.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  pad = ffill(self: 'FrameOrSeries', axis: 'None | Axis' = None, inplace: 'bool_t' = False, limit: 'None | int' = None, downcast=None) -> 'FrameOrSeries | None'\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series/DataFrame or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  pct_change(self: 'FrameOrSeries', periods=1, fill_method='pad', limit=None, freq=None, **kwargs) -> 'FrameOrSeries'\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns', periods=-1)\n",
      " |                2016      2015  2014\n",
      " |      GOOG  0.179241  0.094112   NaN\n",
      " |      APPL -0.252395 -0.011860   NaN\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      Series.map : Apply a mapping correspondence on a\n",
      " |          :class:`~pandas.Series`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(func, arg2=b, arg3=c)\n",
      " |      ... )  # doctest: +SKIP\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((func, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )  # doctest: +SKIP\n",
      " |  \n",
      " |  rank(self: 'FrameOrSeries', axis=0, method: 'str' = 'average', numeric_only: 'bool_t | None' = None, na_option: 'str' = 'keep', ascending: 'bool_t' = True, pct: 'bool_t' = False) -> 'FrameOrSeries'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, optional\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.GroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: 'FrameOrSeries', other, method: 'str | None' = None, copy: 'bool_t' = True, limit=None, tolerance=None) -> 'FrameOrSeries'\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False)\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |          Note that the ``columns`` parameter is not allowed if the\n",
      " |          object is a Series. This parameter only apply for DataFrame\n",
      " |          type objects.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  rolling(self, window: 'int | timedelta | BaseOffset | BaseIndexer', min_periods: 'int | None' = None, center: 'bool_t' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis' = 0, closed: 'str | None' = None, method: 'str' = 'single')\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |      \n",
      " |          If a BaseIndexer subclass is passed, calculates the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely `min_periods`, `center`, and\n",
      " |          `closed` will be passed to `get_window_bounds`.\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          `min_periods` will default to 1. Otherwise, `min_periods` will default\n",
      " |          to the size of the window.\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : str, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a datetime-like column or Index level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      axis : int or str, default 0\n",
      " |      closed : str, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints. Defaults to 'right'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              The closed parameter with fixed windows is now supported.\n",
      " |      method : str {'single', 'table'}, default 'single'\n",
      " |          Execute the rolling operation per single column or row (``'single'``)\n",
      " |          or over the entire object (``'table'``).\n",
      " |      \n",
      " |          This argument is only implemented when specifying ``engine='numba'``\n",
      " |          in the method call.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      If ``win_type=None``, all points are evenly weighted; otherwise, ``win_type``\n",
      " |      can accept a string of any `scipy.signal window function\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows>`__.\n",
      " |      \n",
      " |      Certain Scipy window types require additional parameters to be passed\n",
      " |      in the aggregation function. The additional parameters must match\n",
      " |      the keywords specified in the Scipy window type method signature.\n",
      " |      Please see the third example below on how to add the additional parameters.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  0.5\n",
      " |      2  1.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'gaussian'\n",
      " |      window type (note how we need to specify std).\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Same as above, but with forward-looking windows\n",
      " |      \n",
      " |      >>> indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
      " |      >>> df.rolling(window=indexer, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  1.0\n",
      " |      1  3.0\n",
      " |      2  2.0\n",
      " |      3  4.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |  \n",
      " |  sample(self: 'FrameOrSeries', n=None, frac: 'float | None' = None, replace: 'bool_t' = False, weights=None, random_state=None, axis: 'Axis | None' = None, ignore_index: 'bool_t' = False) -> 'FrameOrSeries'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, optional\n",
      " |          If int, array-like, or BitGenerator (NumPy>=1.17), seed for\n",
      " |          random number generator\n",
      " |          If np.random.RandomState, use as numpy RandomState object.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |              array-like and BitGenerator (for NumPy>=1.17) object now passed to\n",
      " |              np.random.RandomState() as seed\n",
      " |      \n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames).\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting index will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.3.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      " |          DataFrame object.\n",
      " |      SeriesGroupBy.sample: Generates random samples from each group of a\n",
      " |          Series object.\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  set_flags(self: 'FrameOrSeries', *, copy: 'bool_t' = False, allows_duplicate_labels: 'bool_t | None' = None) -> 'FrameOrSeries'\n",
      " |      Return a new object with updated flags.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      allows_duplicate_labels : bool, optional\n",
      " |          Whether the returned object allows duplicate labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          The same type as the caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method returns a new object that's a view on the same data\n",
      " |      as the input. Mutating the input or the output values will be reflected\n",
      " |      in the other.\n",
      " |      \n",
      " |      This method is intended to be used in method chains.\n",
      " |      \n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df2 = df.set_flags(allows_duplicate_labels=False)\n",
      " |      >>> df2.flags.allows_duplicate_labels\n",
      " |      False\n",
      " |  \n",
      " |  slice_shift(self: 'FrameOrSeries', periods: 'int' = 1, axis=0) -> 'FrameOrSeries'\n",
      " |      Equivalent to `shift` without copying data.\n",
      " |      The shifted data will not include the dropped periods and the\n",
      " |      shifted axis will be smaller than the original.\n",
      " |      \n",
      " |      .. deprecated:: 1.2.0\n",
      " |          slice_shift is deprecated,\n",
      " |          use DataFrame/Series.shift instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: 'FrameOrSeries', axis1, axis2, copy=True) -> 'FrameOrSeries'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self: 'FrameOrSeries', n: 'int' = 5) -> 'FrameOrSeries'\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `n` rows, equivalent to ``df[n:]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  take(self: 'FrameOrSeries', indices, axis=0, is_copy: 'bool_t | None' = None, **kwargs) -> 'FrameOrSeries'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_clipboard(self, excel: 'bool_t' = True, sep: 'str | None' = None, **kwargs) -> 'None'\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',')  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)  # doctest: +SKIP\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: 'FilePathOrBuffer[AnyStr] | None' = None, sep: 'str' = ',', na_rep: 'str' = '', float_format: 'str | None' = None, columns: 'Sequence[Hashable] | None' = None, header: 'bool_t | list[str]' = True, index: 'bool_t' = True, index_label: 'IndexLabel | None' = None, mode: 'str' = 'w', encoding: 'str | None' = None, compression: 'CompressionOptions' = 'infer', quoting: 'int | None' = None, quotechar: 'str' = '\"', line_terminator: 'str | None' = None, chunksize: 'int | None' = None, date_format: 'str | None' = None, doublequote: 'bool_t' = True, escapechar: 'str | None' = None, decimal: 'str' = '.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.  If a non-binary file object is passed, it should be opened\n",
      " |          with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |             Support for binary file objects was introduced.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, default None\n",
      " |          Format string for floating point numbers.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          If str, represents compression mode. If dict, value at 'method' is\n",
      " |          the compression mode. Compression mode may be any of the following\n",
      " |          possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
      " |          compression mode is 'infer' and `path_or_buf` is path-like, then\n",
      " |          detect compression mode from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
      " |          and mode is one of {'zip', 'gzip', 'bz2'}, or inferred as\n",
      " |          one of the above, other entries passed as\n",
      " |          additional compression options.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      \n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip' and 'bz2'\n",
      " |             as well as 'zip'.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Compression is supported for binary file objects.\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |      \n",
      " |              Previous versions forwarded dict entries for 'gzip' to\n",
      " |              `gzip.open` instead of `gzip.GzipFile` which prevented\n",
      " |              setting `mtime`.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      line_terminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name: 'str' = 'Sheet1', na_rep: 'str' = '', float_format: 'str | None' = None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : path-like, file-like, or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      \n",
      " |          .. deprecated:: 1.2.0\n",
      " |      \n",
      " |              As the `xlwt <https://pypi.org/project/xlwt/>`__ package is no longer\n",
      " |              maintained, the ``xlwt`` engine will be removed in a future version\n",
      " |              of pandas.\n",
      " |      \n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      verbose : bool, default True\n",
      " |          Display more information in the error logs.\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible to write further\n",
      " |      data without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key: 'str', mode: 'str' = 'a', complevel: 'int | None' = None, complib: 'str | None' = None, append: 'bool_t' = False, format: 'str | None' = None, index: 'bool_t' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool_t | None' = None, data_columns: 'bool_t | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,\n",
      " |         but the type of the subclass is lost upon storing.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\"\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a SQL table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf: 'FilePathOrBuffer | None' = None, orient: 'str | None' = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'str' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t' = True, indent: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line-delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not\n",
      " |          list-like.\n",
      " |      \n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}\n",
      " |      \n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename. By default, the\n",
      " |          compression is inferred from the filename.\n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |         .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json : Convert a JSON string to pandas object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      " |      This stores the version of `pandas` used in the latest revision of the\n",
      " |      schema.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import json\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      " |      ...     index=[\"row 1\", \"row 2\"],\n",
      " |      ...     columns=[\"col 1\", \"col 2\"],\n",
      " |      ... )\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"split\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"columns\": [\n",
      " |              \"col 1\",\n",
      " |              \"col 2\"\n",
      " |          ],\n",
      " |          \"index\": [\n",
      " |              \"row 1\",\n",
      " |              \"row 2\"\n",
      " |          ],\n",
      " |          \"data\": [\n",
      " |              [\n",
      " |                  \"a\",\n",
      " |                  \"b\"\n",
      " |              ],\n",
      " |              [\n",
      " |                  \"c\",\n",
      " |                  \"d\"\n",
      " |              ]\n",
      " |          ]\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"records\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"index\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"row 1\": {\n",
      " |              \"col 1\": \"a\",\n",
      " |              \"col 2\": \"b\"\n",
      " |          },\n",
      " |          \"row 2\": {\n",
      " |              \"col 1\": \"c\",\n",
      " |              \"col 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"columns\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"col 1\": {\n",
      " |              \"row 1\": \"a\",\n",
      " |              \"row 2\": \"c\"\n",
      " |          },\n",
      " |          \"col 2\": {\n",
      " |              \"row 1\": \"b\",\n",
      " |              \"row 2\": \"d\"\n",
      " |          }\n",
      " |      }\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"values\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      [\n",
      " |          [\n",
      " |              \"a\",\n",
      " |              \"b\"\n",
      " |          ],\n",
      " |          [\n",
      " |              \"c\",\n",
      " |              \"d\"\n",
      " |          ]\n",
      " |      ]\n",
      " |      \n",
      " |      Encoding with Table Schema:\n",
      " |      \n",
      " |      >>> result = df.to_json(orient=\"table\")\n",
      " |      >>> parsed = json.loads(result)\n",
      " |      >>> json.dumps(parsed, indent=4)  # doctest: +SKIP\n",
      " |      {\n",
      " |          \"schema\": {\n",
      " |              \"fields\": [\n",
      " |                  {\n",
      " |                      \"name\": \"index\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 1\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  },\n",
      " |                  {\n",
      " |                      \"name\": \"col 2\",\n",
      " |                      \"type\": \"string\"\n",
      " |                  }\n",
      " |              ],\n",
      " |              \"primaryKey\": [\n",
      " |                  \"index\"\n",
      " |              ],\n",
      " |              \"pandas_version\": \"0.20.0\"\n",
      " |          },\n",
      " |          \"data\": [\n",
      " |              {\n",
      " |                  \"index\": \"row 1\",\n",
      " |                  \"col 1\": \"a\",\n",
      " |                  \"col 2\": \"b\"\n",
      " |              },\n",
      " |              {\n",
      " |                  \"index\": \"row 2\",\n",
      " |                  \"col 1\": \"c\",\n",
      " |                  \"col 2\": \"d\"\n",
      " |              }\n",
      " |          ]\n",
      " |      }\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table/tabular.\n",
      " |      \n",
      " |      Requires ``\\usepackage{booktabs}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{table.tex}``.\n",
      " |      \n",
      " |      .. versionchanged:: 1.0.0\n",
      " |         Added caption and label arguments.\n",
      " |      \n",
      " |      .. versionchanged:: 1.2.0\n",
      " |         Added position argument, changed meaning of caption argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {str: function}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{:0.2f}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      multirow : bool, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{multirow} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module.\n",
      " |      caption : str or tuple, optional\n",
      " |          Tuple (full_caption, short_caption),\n",
      " |          which results in ``\\caption[short_caption]{full_caption}``;\n",
      " |          if a single string is passed, no short caption will be set.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |          .. versionchanged:: 1.2.0\n",
      " |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{}`` in the output.\n",
      " |          This is used with ``\\ref{}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      position : str, optional\n",
      " |          The LaTeX positional argument for tables, to be placed after\n",
      " |          ``\\begin{}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              str or None\n",
      " |                  If buf is None, returns the result as a string. Otherwise returns\n",
      " |                  None.\n",
      " |          \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(dict(name=['Raphael', 'Donatello'],\n",
      " |      ...                   mask=['red', 'purple'],\n",
      " |      ...                   weapon=['sai', 'bo staff']))\n",
      " |      >>> print(df.to_latex(index=False))  # doctest: +NORMALIZE_WHITESPACE\n",
      " |      \\begin{tabular}{lll}\n",
      " |       \\toprule\n",
      " |             name &    mask &    weapon \\\\\n",
      " |       \\midrule\n",
      " |          Raphael &     red &       sai \\\\\n",
      " |        Donatello &  purple &  bo staff \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path, compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |          Compression mode may be any of the following possible\n",
      " |          values: {‘infer’, ‘gzip’, ‘bz2’, ‘zip’, ‘xz’, None}. If compression\n",
      " |          mode is ‘infer’ and path_or_buf is path-like, then detect\n",
      " |          compression mode from the following extensions:\n",
      " |          ‘.gz’, ‘.bz2’, ‘.zip’ or ‘.xz’. (otherwise no compression).\n",
      " |          If dict given and mode is ‘zip’ or inferred as ‘zip’, other entries\n",
      " |          passed as additional compression options.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |      \n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib`` as header options. For other URLs (e.g.\n",
      " |          starting with \"s3://\", and \"gcs://\") the key-value pairs are forwarded to\n",
      " |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.\n",
      " |      \n",
      " |          .. versionadded:: 1.2.0\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name: 'str', con, schema=None, if_exists: 'str' = 'fail', index: 'bool_t' = True, index_label=None, chunksize=None, dtype: 'DtypeArg | None' = None, method=None) -> 'None'\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      An `sqlalchemy.engine.Connection` can also be passed to `con`:\n",
      " |      \n",
      " |      >>> with engine.begin() as connection:\n",
      " |      ...     df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      ...     df1.to_sql('users', con=connection, if_exists='append')\n",
      " |      \n",
      " |      This is allowed to support operations that require that the same\n",
      " |      DBAPI connection is used for the entire operation.\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame({'name' : ['User 6', 'User 7']})\n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5'), (0, 'User 6'),\n",
      " |       (1, 'User 7')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df2``.\n",
      " |      \n",
      " |      >>> df2.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 6'), (1, 'User 7')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <https://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (animal: 2, date: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: 'FrameOrSeries', before=None, after=None, axis=None, copy: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self: 'FrameOrSeries', periods: 'int' = 1, freq=None, axis: 'Axis' = 0) -> 'FrameOrSeries'\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      .. deprecated:: 1.1.0\n",
      " |          Use `shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  tz_convert(self: 'FrameOrSeries', tz, axis=0, level=None, copy: 'bool_t' = True) -> 'FrameOrSeries'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      {klass}\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self: 'FrameOrSeries', tz, axis=0, level=None, copy: 'bool_t' = True, ambiguous='raise', nonexistent: 'str' = 'raise') -> 'FrameOrSeries'\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backward with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backward'`.\n",
      " |      \n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level: 'bool_t' = True)\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog'))\n",
      " |                  num_legs  num_wings\n",
      " |      locomotion\n",
      " |      walks              4          0\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in the DataFrame.\n",
      " |      \n",
      " |      This returns a Series with the data type of each column.\n",
      " |      The result's index is the original DataFrame's columns. Columns\n",
      " |      with mixed types are stored with the ``object`` dtype. See\n",
      " |      :ref:`the User Guide <basics.dtypes>` for more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series\n",
      " |          The data type of each column.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'float': [1.0],\n",
      " |      ...                    'int': [1],\n",
      " |      ...                    'datetime': [pd.Timestamp('20180310')],\n",
      " |      ...                    'string': ['foo']})\n",
      " |      >>> df.dtypes\n",
      " |      float              float64\n",
      " |      int                  int64\n",
      " |      datetime    datetime64[ns]\n",
      " |      string              object\n",
      " |      dtype: object\n",
      " |  \n",
      " |  empty\n",
      " |      Indicator whether DataFrame is empty.\n",
      " |      \n",
      " |      True if DataFrame is entirely empty (no items), meaning any of the\n",
      " |      axes are of length 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If DataFrame is empty, return True, if not return False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      " |          where (all or any) data are missing.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If DataFrame contains only NaNs, it is still not considered empty. See\n",
      " |      the example below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example of an actual empty DataFrame. Notice the index is empty:\n",
      " |      \n",
      " |      >>> df_empty = pd.DataFrame({'A' : []})\n",
      " |      >>> df_empty\n",
      " |      Empty DataFrame\n",
      " |      Columns: [A]\n",
      " |      Index: []\n",
      " |      >>> df_empty.empty\n",
      " |      True\n",
      " |      \n",
      " |      If we only have NaNs in our DataFrame, it is not considered empty! We\n",
      " |      will need to drop the NaNs to make the DataFrame empty:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : [np.nan]})\n",
      " |      >>> df\n",
      " |          A\n",
      " |      0 NaN\n",
      " |      >>> df.empty\n",
      " |      False\n",
      " |      >>> df.dropna().empty\n",
      " |      True\n",
      " |  \n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |      \n",
      " |      The available flags are\n",
      " |      \n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |      \n",
      " |      Flags can be get or set using ``.``\n",
      " |      \n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |      \n",
      " |      Or by slicing with a key\n",
      " |      \n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |  \n",
      " |  ndim\n",
      " |      Return an int representing the number of axes / array dimensions.\n",
      " |      \n",
      " |      Return 1 if Series. Otherwise return 2 if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.ndim : Number of array dimensions.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.ndim\n",
      " |      2\n",
      " |  \n",
      " |  size\n",
      " |      Return an int representing the number of elements in this object.\n",
      " |      \n",
      " |      Return the number of rows if Series. Otherwise return the number of\n",
      " |      rows times number of columns if DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      ndarray.size : Number of elements in the array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.size\n",
      " |      4\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes of this dataset.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.flags : Global flags applying to this object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If 'label' does not exist in DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      Series.at : Access a single value using a label.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - An alignable boolean Series. The index of the key will be aligned before\n",
      " |        masking.\n",
      " |      - An alignable Index. The Index of the returned selection will be the input.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      IndexingError\n",
      " |          If an indexed key is passed and its index is unalignable to the frame index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Alignable boolean Series:\n",
      " |      \n",
      " |      >>> df.loc[pd.Series([False, True, False],\n",
      " |      ...        index=['viper', 'sidewinder', 'cobra'])]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Index (same behavior as ``df.reindex``)\n",
      " |      \n",
      " |      >>> df.loc[pd.Index([\"cobra\", \"viper\"], name=\"foo\")]\n",
      " |             max_speed  shield\n",
      " |      foo\n",
      " |      cobra          1       2\n",
      " |      viper          4       5\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __floordiv__(self, other)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rand__(self, other)\n",
      " |  \n",
      " |  __rfloordiv__(self, other)\n",
      " |  \n",
      " |  __rmod__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __ror__(self, other)\n",
      " |  \n",
      " |  __rpow__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __rxor__(self, other)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series, DataFrames, and CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:12.686662Z",
     "iopub.status.idle": "2021-08-31T21:47:12.687125Z"
    }
   },
   "outputs": [],
   "source": [
    "# main datatypes  series and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:30.407833Z",
     "iopub.status.busy": "2021-08-31T21:47:30.407146Z",
     "iopub.status.idle": "2021-08-31T21:47:30.418133Z",
     "shell.execute_reply": "2021-08-31T21:47:30.416813Z",
     "shell.execute_reply.started": "2021-08-31T21:47:30.407771Z"
    }
   },
   "outputs": [],
   "source": [
    "series = pd.Series(['BMW', 'Toyta', 'Honda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:30.90038Z",
     "iopub.status.busy": "2021-08-31T21:47:30.899679Z",
     "iopub.status.idle": "2021-08-31T21:47:31.044339Z",
     "shell.execute_reply": "2021-08-31T21:47:31.043149Z",
     "shell.execute_reply.started": "2021-08-31T21:47:30.900318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      BMW\n",
       "1    Toyta\n",
       "2    Honda\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series \n",
    "#series are 1 dimensional (aka a single column of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:31.507347Z",
     "iopub.status.busy": "2021-08-31T21:47:31.506702Z",
     "iopub.status.idle": "2021-08-31T21:47:31.515908Z",
     "shell.execute_reply": "2021-08-31T21:47:31.515114Z",
     "shell.execute_reply.started": "2021-08-31T21:47:31.507289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Red\n",
       "1     Blue\n",
       "2    White\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = pd.Series(['Red', 'Blue', 'White'])\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:32.466393Z",
     "iopub.status.busy": "2021-08-31T21:47:32.465728Z",
     "iopub.status.idle": "2021-08-31T21:47:32.494002Z",
     "shell.execute_reply": "2021-08-31T21:47:32.492554Z",
     "shell.execute_reply.started": "2021-08-31T21:47:32.466353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Make</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toyta</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Car Make  Color\n",
       "0      BMW    Red\n",
       "1    Toyta   Blue\n",
       "2    Honda  White"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframes are 2 dimensional and far more common\n",
    "df = pd.DataFrame({'Car Make': series, 'Color': colors})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:33.315737Z",
     "iopub.status.busy": "2021-08-31T21:47:33.315258Z",
     "iopub.status.idle": "2021-08-31T21:47:33.34077Z",
     "shell.execute_reply": "2021-08-31T21:47:33.339607Z",
     "shell.execute_reply.started": "2021-08-31T21:47:33.315696Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/JW_car-sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b7dedf073f10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/JW_car-sales.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_cuda110\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/JW_car-sales.csv'"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('./data/JW_car-sales.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {
    "4198aef5-008d-4785-a1e5-9434c9f7fea8.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:4198aef5-008d-4785-a1e5-9434c9f7fea8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:34.221586Z",
     "iopub.status.busy": "2021-08-31T21:47:34.221116Z",
     "iopub.status.idle": "2021-08-31T21:47:34.266317Z",
     "shell.execute_reply": "2021-08-31T21:47:34.263887Z",
     "shell.execute_reply.started": "2021-08-31T21:47:34.22154Z"
    }
   },
   "outputs": [],
   "source": [
    "#exporting a dataframe\n",
    "df.to_csv('/kaggle/input/section17pandas/data/JW_car_sales_exported2.csv', index = False)\n",
    "#when exporting the data pandas will also export the index column\n",
    "#setting index = False won't include the index in the outputted csv file\n",
    "#when the index is valuable information we need to keep index = True\n",
    "#when the index is the standard 0-n numerical values we can set index = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:47:35.130895Z",
     "iopub.status.busy": "2021-08-31T21:47:35.130435Z",
     "iopub.status.idle": "2021-08-31T21:47:55.235982Z",
     "shell.execute_reply": "2021-08-31T21:47:55.230141Z",
     "shell.execute_reply.started": "2021-08-31T21:47:35.130859Z"
    }
   },
   "outputs": [],
   "source": [
    "heart_disease = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe Data w/ Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.237337Z",
     "iopub.status.idle": "2021-08-31T21:47:55.237881Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.23978Z",
     "iopub.status.idle": "2021-08-31T21:47:55.240517Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "#dtypes is an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.24244Z",
     "iopub.status.idle": "2021-08-31T21:47:55.243189Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns\n",
    "car_columns = df.columns\n",
    "print(car_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.24493Z",
     "iopub.status.idle": "2021-08-31T21:47:55.245643Z"
    }
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.2472Z",
     "iopub.status.idle": "2021-08-31T21:47:55.247945Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "#gives some statistical datda about our numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.250054Z",
     "iopub.status.idle": "2021-08-31T21:47:55.250869Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.252652Z",
     "iopub.status.idle": "2021-08-31T21:47:55.253219Z"
    }
   },
   "outputs": [],
   "source": [
    "df.mean()\n",
    "#returns mean values of numerical columns\n",
    "#can also call mean() method on individual series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.254149Z",
     "iopub.status.idle": "2021-08-31T21:47:55.254599Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sum()\n",
    "#sum up all the values for each column\n",
    "#not really useful calling it on the whole dataframe\n",
    "# we could, instead, call it on a specific column\n",
    "df['Odometer (KM)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.255452Z",
     "iopub.status.idle": "2021-08-31T21:47:55.255933Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df)\n",
    "#get the overall length of the df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting and Viewing Data w/ Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.25677Z",
     "iopub.status.idle": "2021-08-31T21:47:55.257252Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.259064Z",
     "iopub.status.idle": "2021-08-31T21:47:55.259525Z"
    }
   },
   "outputs": [],
   "source": [
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.260601Z",
     "iopub.status.idle": "2021-08-31T21:47:55.261105Z"
    }
   },
   "outputs": [],
   "source": [
    "animals = pd.Series(['cat', 'dog', 'bird', 'panda', 'snake'],\n",
    "                   index = [0, 3, 9, 8, 3])\n",
    "animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.262208Z",
     "iopub.status.idle": "2021-08-31T21:47:55.262667Z"
    }
   },
   "outputs": [],
   "source": [
    "animals.loc[3]\n",
    "#returns values that have index values of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.263763Z",
     "iopub.status.idle": "2021-08-31T21:47:55.264236Z"
    }
   },
   "outputs": [],
   "source": [
    "animals.loc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.265454Z",
     "iopub.status.idle": "2021-08-31T21:47:55.266013Z"
    }
   },
   "outputs": [],
   "source": [
    "animals.iloc[3]\n",
    "#returns whatever value is in the 3rd index location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.267063Z",
     "iopub.status.idle": "2021-08-31T21:47:55.267584Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.268572Z",
     "iopub.status.idle": "2021-08-31T21:47:55.269136Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.270204Z",
     "iopub.status.idle": "2021-08-31T21:47:55.27071Z"
    }
   },
   "outputs": [],
   "source": [
    "#can also use slicing with .loc[] and .iloc[]\n",
    "animals.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.271786Z",
     "iopub.status.idle": "2021-08-31T21:47:55.272284Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-31T21:47:55.27336Z",
     "iopub.status.idle": "2021-08-31T21:47:55.273892Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:48:05.945118Z",
     "iopub.status.busy": "2021-08-31T21:48:05.944585Z",
     "iopub.status.idle": "2021-08-31T21:48:05.956469Z",
     "shell.execute_reply": "2021-08-31T21:48:05.954598Z",
     "shell.execute_reply.started": "2021-08-31T21:48:05.945031Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['Make'])\n",
    "print(df.Make)  #these are both the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:50:04.383382Z",
     "iopub.status.busy": "2021-08-31T21:50:04.382929Z",
     "iopub.status.idle": "2021-08-31T21:50:04.399519Z",
     "shell.execute_reply": "2021-08-31T21:50:04.398263Z",
     "shell.execute_reply.started": "2021-08-31T21:50:04.383346Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['Make'] == 'Toyota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T21:50:26.27231Z",
     "iopub.status.busy": "2021-08-31T21:50:26.271857Z",
     "iopub.status.idle": "2021-08-31T21:50:26.305462Z",
     "shell.execute_reply": "2021-08-31T21:50:26.304592Z",
     "shell.execute_reply.started": "2021-08-31T21:50:26.272277Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['Odometer (KM)'] > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:03:16.9607Z",
     "iopub.status.busy": "2021-08-31T22:03:16.960262Z",
     "iopub.status.idle": "2021-08-31T22:03:16.995849Z",
     "shell.execute_reply": "2021-08-31T22:03:16.994238Z",
     "shell.execute_reply.started": "2021-08-31T22:03:16.960664Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df['Make'], df['Doors'])\n",
    "#great way to compare 2 columns\n",
    "#honda has 3 cars all with 4 doors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:05:46.18036Z",
     "iopub.status.busy": "2021-08-31T22:05:46.179555Z",
     "iopub.status.idle": "2021-08-31T22:05:46.199309Z",
     "shell.execute_reply": "2021-08-31T22:05:46.198016Z",
     "shell.execute_reply.started": "2021-08-31T22:05:46.180286Z"
    }
   },
   "outputs": [],
   "source": [
    "#comparing multiple columns\n",
    "df.groupby(['Make']).mean()\n",
    "#this will calculate the mean for all numeric columns for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:44:21.081927Z",
     "iopub.status.busy": "2021-08-31T22:44:21.081435Z",
     "iopub.status.idle": "2021-08-31T22:44:21.329836Z",
     "shell.execute_reply": "2021-08-31T22:44:21.328372Z",
     "shell.execute_reply.started": "2021-08-31T22:44:21.081888Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Odometer (KM)'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:44:33.032468Z",
     "iopub.status.busy": "2021-08-31T22:44:33.032028Z",
     "iopub.status.idle": "2021-08-31T22:44:33.250882Z",
     "shell.execute_reply": "2021-08-31T22:44:33.249352Z",
     "shell.execute_reply.started": "2021-08-31T22:44:33.032434Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Odometer (KM)'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:48:53.575432Z",
     "iopub.status.busy": "2021-08-31T22:48:53.574731Z",
     "iopub.status.idle": "2021-08-31T22:48:53.584784Z",
     "shell.execute_reply": "2021-08-31T22:48:53.583529Z",
     "shell.execute_reply.started": "2021-08-31T22:48:53.575386Z"
    }
   },
   "outputs": [],
   "source": [
    "#notice how price wasn't included in the about mean() method\n",
    "#this is because its text, not numeric\n",
    "print(df['Price'].dtype)\n",
    "df['Price'] = df['Price'].str.replace('[\\$\\,]', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:48:58.661493Z",
     "iopub.status.busy": "2021-08-31T22:48:58.660863Z",
     "iopub.status.idle": "2021-08-31T22:48:58.670669Z",
     "shell.execute_reply": "2021-08-31T22:48:58.669418Z",
     "shell.execute_reply.started": "2021-08-31T22:48:58.661451Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:49:03.74521Z",
     "iopub.status.busy": "2021-08-31T22:49:03.744371Z",
     "iopub.status.idle": "2021-08-31T22:49:03.76635Z",
     "shell.execute_reply": "2021-08-31T22:49:03.764582Z",
     "shell.execute_reply.started": "2021-08-31T22:49:03.74514Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:56:32.463133Z",
     "iopub.status.busy": "2021-08-31T22:56:32.461241Z",
     "iopub.status.idle": "2021-08-31T22:56:32.480819Z",
     "shell.execute_reply": "2021-08-31T22:56:32.479866Z",
     "shell.execute_reply.started": "2021-08-31T22:56:32.462989Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Make'] = df['Make'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:57:49.5302Z",
     "iopub.status.busy": "2021-08-31T22:57:49.529482Z",
     "iopub.status.idle": "2021-08-31T22:57:49.56191Z",
     "shell.execute_reply": "2021-08-31T22:57:49.560663Z",
     "shell.execute_reply.started": "2021-08-31T22:57:49.530138Z"
    }
   },
   "outputs": [],
   "source": [
    "df_missing = pd.read_csv('../input/section17pandas/data/JW_car-sales-missing-data.csv')\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T22:59:25.061506Z",
     "iopub.status.busy": "2021-08-31T22:59:25.060803Z",
     "iopub.status.idle": "2021-08-31T22:59:25.08233Z",
     "shell.execute_reply": "2021-08-31T22:59:25.081281Z",
     "shell.execute_reply.started": "2021-08-31T22:59:25.061461Z"
    }
   },
   "outputs": [],
   "source": [
    "#fill missing values in odometer column\n",
    "df_missing['Odometer'].fillna(df_missing['Odometer'].mean(), inplace = True)\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T23:15:03.656102Z",
     "iopub.status.busy": "2021-08-31T23:15:03.655335Z",
     "iopub.status.idle": "2021-08-31T23:15:03.68082Z",
     "shell.execute_reply": "2021-08-31T23:15:03.679587Z",
     "shell.execute_reply.started": "2021-08-31T23:15:03.656034Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove rows with missing values\n",
    "df_missing.dropna(axis = 0, inplace = True)\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-31T23:16:31.437341Z",
     "iopub.status.busy": "2021-08-31T23:16:31.436869Z",
     "iopub.status.idle": "2021-08-31T23:16:31.455471Z",
     "shell.execute_reply": "2021-08-31T23:16:31.453935Z",
     "shell.execute_reply.started": "2021-08-31T23:16:31.437302Z"
    }
   },
   "outputs": [],
   "source": [
    "df_missing = pd.read_csv('../input/section17pandas/data/JW_car-sales-missing-data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
